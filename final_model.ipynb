{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\johnn\\\\玉山資料'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from scipy.special import boxcox\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import (train_test_split,learning_curve,cross_val_score,\n",
    "                                     KFold,TimeSeriesSplit,GridSearchCV)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (f1_score,roc_auc_score,make_scorer,precision_score,\n",
    "                             recall_score,classification_report,confusion_matrix,\n",
    "                             fbeta_score,average_precision_score,precision_recall_curve)\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import (RandomForestClassifier,GradientBoostingClassifier,\n",
    "                              GradientBoostingRegressor,RandomForestRegressor,\n",
    "                              AdaBoostClassifier)\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE,ADASYN,BorderlineSMOTE\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from time import time\n",
    "import lightgbm as light\n",
    "import catboost as cat\n",
    "import xgboost as xgb\n",
    "import data_processing\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "%matplotlib inline\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')\n",
    "submit = pd.read_csv('./data/submission_test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without feature engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'flbmk', 'flg_3dsmk', 'insfg', 'ovrlt' 此三個變數因資料型態須預處理，故在此捨棄這四個變數，以下步驟為預先不處理資料，純塞行衡量其表現"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0,inplace=True)\n",
    "test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.196619\ttraining's f1: 0.598451\tvalid_1's binary_logloss: 0.199128\tvalid_1's f1: 0.597073\n",
      "[2]\ttraining's binary_logloss: 0.195377\ttraining's f1: 0.598391\tvalid_1's binary_logloss: 0.198034\tvalid_1's f1: 0.596756\n",
      "[3]\ttraining's binary_logloss: 0.191719\ttraining's f1: 0.598215\tvalid_1's binary_logloss: 0.194367\tvalid_1's f1: 0.596546\n",
      "[4]\ttraining's binary_logloss: 0.187749\ttraining's f1: 0.59822\tvalid_1's binary_logloss: 0.190558\tvalid_1's f1: 0.596344\n",
      "[5]\ttraining's binary_logloss: 0.185229\ttraining's f1: 0.598142\tvalid_1's binary_logloss: 0.188139\tvalid_1's f1: 0.59603\n",
      "[6]\ttraining's binary_logloss: 0.182544\ttraining's f1: 0.598961\tvalid_1's binary_logloss: 0.18555\tvalid_1's f1: 0.596755\n",
      "[7]\ttraining's binary_logloss: 0.179712\ttraining's f1: 0.599861\tvalid_1's binary_logloss: 0.182853\tvalid_1's f1: 0.597691\n",
      "[8]\ttraining's binary_logloss: 0.176276\ttraining's f1: 0.601549\tvalid_1's binary_logloss: 0.17959\tvalid_1's f1: 0.599263\n",
      "[9]\ttraining's binary_logloss: 0.17362\ttraining's f1: 0.60233\tvalid_1's binary_logloss: 0.1769\tvalid_1's f1: 0.600186\n",
      "[10]\ttraining's binary_logloss: 0.170815\ttraining's f1: 0.603636\tvalid_1's binary_logloss: 0.174252\tvalid_1's f1: 0.60125\n",
      "[11]\ttraining's binary_logloss: 0.168567\ttraining's f1: 0.604699\tvalid_1's binary_logloss: 0.172034\tvalid_1's f1: 0.602039\n",
      "[12]\ttraining's binary_logloss: 0.166147\ttraining's f1: 0.605704\tvalid_1's binary_logloss: 0.169705\tvalid_1's f1: 0.603008\n",
      "[13]\ttraining's binary_logloss: 0.163985\ttraining's f1: 0.606827\tvalid_1's binary_logloss: 0.167616\tvalid_1's f1: 0.603874\n",
      "[14]\ttraining's binary_logloss: 0.162124\ttraining's f1: 0.607707\tvalid_1's binary_logloss: 0.16581\tvalid_1's f1: 0.604713\n",
      "[15]\ttraining's binary_logloss: 0.160218\ttraining's f1: 0.608733\tvalid_1's binary_logloss: 0.164007\tvalid_1's f1: 0.605507\n",
      "[16]\ttraining's binary_logloss: 0.158457\ttraining's f1: 0.609812\tvalid_1's binary_logloss: 0.162267\tvalid_1's f1: 0.606345\n",
      "[17]\ttraining's binary_logloss: 0.156888\ttraining's f1: 0.610532\tvalid_1's binary_logloss: 0.160741\tvalid_1's f1: 0.607107\n",
      "[18]\ttraining's binary_logloss: 0.155239\ttraining's f1: 0.611387\tvalid_1's binary_logloss: 0.159115\tvalid_1's f1: 0.607878\n",
      "[19]\ttraining's binary_logloss: 0.153682\ttraining's f1: 0.61202\tvalid_1's binary_logloss: 0.157684\tvalid_1's f1: 0.608428\n",
      "[20]\ttraining's binary_logloss: 0.152467\ttraining's f1: 0.613109\tvalid_1's binary_logloss: 0.156531\tvalid_1's f1: 0.609411\n",
      "[21]\ttraining's binary_logloss: 0.15089\ttraining's f1: 0.614307\tvalid_1's binary_logloss: 0.154998\tvalid_1's f1: 0.610269\n",
      "[22]\ttraining's binary_logloss: 0.149549\ttraining's f1: 0.615143\tvalid_1's binary_logloss: 0.153744\tvalid_1's f1: 0.610741\n",
      "[23]\ttraining's binary_logloss: 0.148343\ttraining's f1: 0.615892\tvalid_1's binary_logloss: 0.152538\tvalid_1's f1: 0.611488\n",
      "[24]\ttraining's binary_logloss: 0.147115\ttraining's f1: 0.616551\tvalid_1's binary_logloss: 0.151399\tvalid_1's f1: 0.612257\n",
      "[25]\ttraining's binary_logloss: 0.146138\ttraining's f1: 0.617379\tvalid_1's binary_logloss: 0.150451\tvalid_1's f1: 0.61288\n",
      "[26]\ttraining's binary_logloss: 0.144554\ttraining's f1: 0.618152\tvalid_1's binary_logloss: 0.148968\tvalid_1's f1: 0.61355\n",
      "[27]\ttraining's binary_logloss: 0.143548\ttraining's f1: 0.618916\tvalid_1's binary_logloss: 0.148008\tvalid_1's f1: 0.614109\n",
      "[28]\ttraining's binary_logloss: 0.142154\ttraining's f1: 0.619567\tvalid_1's binary_logloss: 0.146717\tvalid_1's f1: 0.614667\n",
      "[29]\ttraining's binary_logloss: 0.141026\ttraining's f1: 0.620284\tvalid_1's binary_logloss: 0.145719\tvalid_1's f1: 0.615033\n",
      "[30]\ttraining's binary_logloss: 0.139756\ttraining's f1: 0.621355\tvalid_1's binary_logloss: 0.144518\tvalid_1's f1: 0.615844\n",
      "[31]\ttraining's binary_logloss: 0.13892\ttraining's f1: 0.621893\tvalid_1's binary_logloss: 0.143737\tvalid_1's f1: 0.616485\n",
      "[32]\ttraining's binary_logloss: 0.13771\ttraining's f1: 0.622868\tvalid_1's binary_logloss: 0.142555\tvalid_1's f1: 0.617466\n",
      "[33]\ttraining's binary_logloss: 0.136516\ttraining's f1: 0.623933\tvalid_1's binary_logloss: 0.141356\tvalid_1's f1: 0.618327\n",
      "[34]\ttraining's binary_logloss: 0.135632\ttraining's f1: 0.62479\tvalid_1's binary_logloss: 0.14055\tvalid_1's f1: 0.619018\n",
      "[35]\ttraining's binary_logloss: 0.13477\ttraining's f1: 0.625553\tvalid_1's binary_logloss: 0.139748\tvalid_1's f1: 0.619428\n",
      "[36]\ttraining's binary_logloss: 0.133728\ttraining's f1: 0.6264\tvalid_1's binary_logloss: 0.138783\tvalid_1's f1: 0.620013\n",
      "[37]\ttraining's binary_logloss: 0.132882\ttraining's f1: 0.627297\tvalid_1's binary_logloss: 0.137967\tvalid_1's f1: 0.620775\n",
      "[38]\ttraining's binary_logloss: 0.131781\ttraining's f1: 0.628286\tvalid_1's binary_logloss: 0.136943\tvalid_1's f1: 0.621504\n",
      "[39]\ttraining's binary_logloss: 0.131049\ttraining's f1: 0.628924\tvalid_1's binary_logloss: 0.136267\tvalid_1's f1: 0.622115\n",
      "[40]\ttraining's binary_logloss: 0.130216\ttraining's f1: 0.629767\tvalid_1's binary_logloss: 0.135499\tvalid_1's f1: 0.622797\n",
      "[41]\ttraining's binary_logloss: 0.129534\ttraining's f1: 0.630453\tvalid_1's binary_logloss: 0.134877\tvalid_1's f1: 0.623215\n",
      "[42]\ttraining's binary_logloss: 0.128839\ttraining's f1: 0.630958\tvalid_1's binary_logloss: 0.134206\tvalid_1's f1: 0.623551\n",
      "[43]\ttraining's binary_logloss: 0.128054\ttraining's f1: 0.631661\tvalid_1's binary_logloss: 0.133489\tvalid_1's f1: 0.624086\n",
      "[44]\ttraining's binary_logloss: 0.127245\ttraining's f1: 0.632514\tvalid_1's binary_logloss: 0.132749\tvalid_1's f1: 0.624789\n",
      "[45]\ttraining's binary_logloss: 0.126485\ttraining's f1: 0.633162\tvalid_1's binary_logloss: 0.132033\tvalid_1's f1: 0.625285\n",
      "[46]\ttraining's binary_logloss: 0.125806\ttraining's f1: 0.633711\tvalid_1's binary_logloss: 0.131468\tvalid_1's f1: 0.625883\n",
      "[47]\ttraining's binary_logloss: 0.125018\ttraining's f1: 0.634393\tvalid_1's binary_logloss: 0.130711\tvalid_1's f1: 0.626408\n",
      "[48]\ttraining's binary_logloss: 0.124127\ttraining's f1: 0.63532\tvalid_1's binary_logloss: 0.129929\tvalid_1's f1: 0.627058\n",
      "[49]\ttraining's binary_logloss: 0.123606\ttraining's f1: 0.635709\tvalid_1's binary_logloss: 0.129437\tvalid_1's f1: 0.627411\n",
      "[50]\ttraining's binary_logloss: 0.123044\ttraining's f1: 0.636368\tvalid_1's binary_logloss: 0.128919\tvalid_1's f1: 0.627882\n",
      "[51]\ttraining's binary_logloss: 0.122138\ttraining's f1: 0.637397\tvalid_1's binary_logloss: 0.128065\tvalid_1's f1: 0.628632\n",
      "[52]\ttraining's binary_logloss: 0.121297\ttraining's f1: 0.638701\tvalid_1's binary_logloss: 0.12729\tvalid_1's f1: 0.629672\n",
      "[53]\ttraining's binary_logloss: 0.12063\ttraining's f1: 0.639193\tvalid_1's binary_logloss: 0.126698\tvalid_1's f1: 0.63012\n",
      "[54]\ttraining's binary_logloss: 0.120069\ttraining's f1: 0.639677\tvalid_1's binary_logloss: 0.126163\tvalid_1's f1: 0.630463\n",
      "[55]\ttraining's binary_logloss: 0.119185\ttraining's f1: 0.640574\tvalid_1's binary_logloss: 0.125306\tvalid_1's f1: 0.631178\n",
      "[56]\ttraining's binary_logloss: 0.118671\ttraining's f1: 0.641078\tvalid_1's binary_logloss: 0.124854\tvalid_1's f1: 0.631585\n",
      "[57]\ttraining's binary_logloss: 0.118092\ttraining's f1: 0.641681\tvalid_1's binary_logloss: 0.124313\tvalid_1's f1: 0.632031\n",
      "[58]\ttraining's binary_logloss: 0.117333\ttraining's f1: 0.642474\tvalid_1's binary_logloss: 0.12361\tvalid_1's f1: 0.63266\n",
      "[59]\ttraining's binary_logloss: 0.116519\ttraining's f1: 0.643682\tvalid_1's binary_logloss: 0.12285\tvalid_1's f1: 0.633916\n",
      "[60]\ttraining's binary_logloss: 0.11584\ttraining's f1: 0.644678\tvalid_1's binary_logloss: 0.122235\tvalid_1's f1: 0.634555\n",
      "[61]\ttraining's binary_logloss: 0.114986\ttraining's f1: 0.645493\tvalid_1's binary_logloss: 0.121426\tvalid_1's f1: 0.635363\n",
      "[62]\ttraining's binary_logloss: 0.114668\ttraining's f1: 0.645868\tvalid_1's binary_logloss: 0.121145\tvalid_1's f1: 0.63546\n",
      "[63]\ttraining's binary_logloss: 0.114049\ttraining's f1: 0.646507\tvalid_1's binary_logloss: 0.12054\tvalid_1's f1: 0.636007\n",
      "[64]\ttraining's binary_logloss: 0.113435\ttraining's f1: 0.647187\tvalid_1's binary_logloss: 0.119988\tvalid_1's f1: 0.636678\n",
      "[65]\ttraining's binary_logloss: 0.112697\ttraining's f1: 0.648283\tvalid_1's binary_logloss: 0.119326\tvalid_1's f1: 0.637488\n",
      "[66]\ttraining's binary_logloss: 0.112004\ttraining's f1: 0.649277\tvalid_1's binary_logloss: 0.118693\tvalid_1's f1: 0.638314\n",
      "[67]\ttraining's binary_logloss: 0.111279\ttraining's f1: 0.650013\tvalid_1's binary_logloss: 0.118039\tvalid_1's f1: 0.638851\n",
      "[68]\ttraining's binary_logloss: 0.110867\ttraining's f1: 0.65035\tvalid_1's binary_logloss: 0.117666\tvalid_1's f1: 0.639004\n",
      "[69]\ttraining's binary_logloss: 0.110332\ttraining's f1: 0.651075\tvalid_1's binary_logloss: 0.117198\tvalid_1's f1: 0.639862\n",
      "[70]\ttraining's binary_logloss: 0.109532\ttraining's f1: 0.652101\tvalid_1's binary_logloss: 0.116413\tvalid_1's f1: 0.640517\n",
      "[71]\ttraining's binary_logloss: 0.108885\ttraining's f1: 0.652855\tvalid_1's binary_logloss: 0.115816\tvalid_1's f1: 0.641146\n",
      "[72]\ttraining's binary_logloss: 0.1084\ttraining's f1: 0.653479\tvalid_1's binary_logloss: 0.115388\tvalid_1's f1: 0.641607\n",
      "[73]\ttraining's binary_logloss: 0.10796\ttraining's f1: 0.653939\tvalid_1's binary_logloss: 0.114986\tvalid_1's f1: 0.642059\n",
      "[74]\ttraining's binary_logloss: 0.107622\ttraining's f1: 0.654217\tvalid_1's binary_logloss: 0.114675\tvalid_1's f1: 0.642407\n",
      "[75]\ttraining's binary_logloss: 0.106946\ttraining's f1: 0.655186\tvalid_1's binary_logloss: 0.114046\tvalid_1's f1: 0.64327\n",
      "[76]\ttraining's binary_logloss: 0.106342\ttraining's f1: 0.656058\tvalid_1's binary_logloss: 0.113501\tvalid_1's f1: 0.643747\n",
      "[77]\ttraining's binary_logloss: 0.105848\ttraining's f1: 0.656716\tvalid_1's binary_logloss: 0.113016\tvalid_1's f1: 0.644257\n",
      "[78]\ttraining's binary_logloss: 0.105389\ttraining's f1: 0.657157\tvalid_1's binary_logloss: 0.112624\tvalid_1's f1: 0.64447\n",
      "[79]\ttraining's binary_logloss: 0.105096\ttraining's f1: 0.65741\tvalid_1's binary_logloss: 0.112384\tvalid_1's f1: 0.644707\n",
      "[80]\ttraining's binary_logloss: 0.104691\ttraining's f1: 0.657894\tvalid_1's binary_logloss: 0.112013\tvalid_1's f1: 0.645048\n",
      "[81]\ttraining's binary_logloss: 0.104066\ttraining's f1: 0.658807\tvalid_1's binary_logloss: 0.111452\tvalid_1's f1: 0.64573\n",
      "[82]\ttraining's binary_logloss: 0.103557\ttraining's f1: 0.659685\tvalid_1's binary_logloss: 0.110989\tvalid_1's f1: 0.646582\n",
      "[83]\ttraining's binary_logloss: 0.102987\ttraining's f1: 0.660625\tvalid_1's binary_logloss: 0.110478\tvalid_1's f1: 0.647259\n",
      "[84]\ttraining's binary_logloss: 0.102469\ttraining's f1: 0.661289\tvalid_1's binary_logloss: 0.109996\tvalid_1's f1: 0.647707\n",
      "[85]\ttraining's binary_logloss: 0.102149\ttraining's f1: 0.661535\tvalid_1's binary_logloss: 0.109693\tvalid_1's f1: 0.647791\n",
      "[86]\ttraining's binary_logloss: 0.101765\ttraining's f1: 0.662149\tvalid_1's binary_logloss: 0.109333\tvalid_1's f1: 0.648316\n",
      "[87]\ttraining's binary_logloss: 0.101397\ttraining's f1: 0.662468\tvalid_1's binary_logloss: 0.108981\tvalid_1's f1: 0.648595\n",
      "[88]\ttraining's binary_logloss: 0.10088\ttraining's f1: 0.663257\tvalid_1's binary_logloss: 0.108531\tvalid_1's f1: 0.649087\n",
      "[89]\ttraining's binary_logloss: 0.100347\ttraining's f1: 0.664264\tvalid_1's binary_logloss: 0.108003\tvalid_1's f1: 0.64991\n",
      "[90]\ttraining's binary_logloss: 0.0997034\ttraining's f1: 0.664899\tvalid_1's binary_logloss: 0.107423\tvalid_1's f1: 0.650448\n",
      "[91]\ttraining's binary_logloss: 0.0993686\ttraining's f1: 0.665402\tvalid_1's binary_logloss: 0.107107\tvalid_1's f1: 0.650809\n",
      "[92]\ttraining's binary_logloss: 0.0989634\ttraining's f1: 0.666003\tvalid_1's binary_logloss: 0.106732\tvalid_1's f1: 0.651153\n",
      "[93]\ttraining's binary_logloss: 0.0982019\ttraining's f1: 0.666965\tvalid_1's binary_logloss: 0.106019\tvalid_1's f1: 0.652096\n",
      "[94]\ttraining's binary_logloss: 0.0979145\ttraining's f1: 0.667277\tvalid_1's binary_logloss: 0.105757\tvalid_1's f1: 0.652293\n",
      "[95]\ttraining's binary_logloss: 0.0975659\ttraining's f1: 0.667648\tvalid_1's binary_logloss: 0.105452\tvalid_1's f1: 0.65263\n",
      "[96]\ttraining's binary_logloss: 0.0970715\ttraining's f1: 0.668679\tvalid_1's binary_logloss: 0.104994\tvalid_1's f1: 0.653551\n",
      "[97]\ttraining's binary_logloss: 0.0967548\ttraining's f1: 0.669116\tvalid_1's binary_logloss: 0.10471\tvalid_1's f1: 0.653968\n",
      "[98]\ttraining's binary_logloss: 0.0964108\ttraining's f1: 0.669573\tvalid_1's binary_logloss: 0.10444\tvalid_1's f1: 0.654207\n",
      "[99]\ttraining's binary_logloss: 0.0961388\ttraining's f1: 0.66992\tvalid_1's binary_logloss: 0.104195\tvalid_1's f1: 0.654393\n",
      "[100]\ttraining's binary_logloss: 0.0955343\ttraining's f1: 0.670971\tvalid_1's binary_logloss: 0.103648\tvalid_1's f1: 0.655296\n",
      "[101]\ttraining's binary_logloss: 0.0949745\ttraining's f1: 0.672016\tvalid_1's binary_logloss: 0.103128\tvalid_1's f1: 0.656023\n",
      "[102]\ttraining's binary_logloss: 0.0946401\ttraining's f1: 0.672446\tvalid_1's binary_logloss: 0.102844\tvalid_1's f1: 0.656127\n",
      "[103]\ttraining's binary_logloss: 0.0943915\ttraining's f1: 0.672745\tvalid_1's binary_logloss: 0.102639\tvalid_1's f1: 0.65634\n",
      "[104]\ttraining's binary_logloss: 0.093974\ttraining's f1: 0.673547\tvalid_1's binary_logloss: 0.102265\tvalid_1's f1: 0.656726\n",
      "[105]\ttraining's binary_logloss: 0.0937087\ttraining's f1: 0.673746\tvalid_1's binary_logloss: 0.102013\tvalid_1's f1: 0.656811\n",
      "[106]\ttraining's binary_logloss: 0.0934187\ttraining's f1: 0.674116\tvalid_1's binary_logloss: 0.101722\tvalid_1's f1: 0.657161\n",
      "[107]\ttraining's binary_logloss: 0.0928262\ttraining's f1: 0.675109\tvalid_1's binary_logloss: 0.101159\tvalid_1's f1: 0.658024\n",
      "[108]\ttraining's binary_logloss: 0.0922246\ttraining's f1: 0.676327\tvalid_1's binary_logloss: 0.100592\tvalid_1's f1: 0.658961\n",
      "[109]\ttraining's binary_logloss: 0.0917081\ttraining's f1: 0.677167\tvalid_1's binary_logloss: 0.100116\tvalid_1's f1: 0.659484\n",
      "[110]\ttraining's binary_logloss: 0.0912783\ttraining's f1: 0.677696\tvalid_1's binary_logloss: 0.0997465\tvalid_1's f1: 0.659851\n",
      "[111]\ttraining's binary_logloss: 0.0910766\ttraining's f1: 0.677991\tvalid_1's binary_logloss: 0.0995567\tvalid_1's f1: 0.659999\n",
      "[112]\ttraining's binary_logloss: 0.0905785\ttraining's f1: 0.679086\tvalid_1's binary_logloss: 0.0990679\tvalid_1's f1: 0.660918\n",
      "[113]\ttraining's binary_logloss: 0.0902778\ttraining's f1: 0.679464\tvalid_1's binary_logloss: 0.0987938\tvalid_1's f1: 0.661215\n",
      "[114]\ttraining's binary_logloss: 0.0898991\ttraining's f1: 0.679975\tvalid_1's binary_logloss: 0.0984433\tvalid_1's f1: 0.661514\n",
      "[115]\ttraining's binary_logloss: 0.0895459\ttraining's f1: 0.680665\tvalid_1's binary_logloss: 0.0981353\tvalid_1's f1: 0.661985\n",
      "[116]\ttraining's binary_logloss: 0.0891262\ttraining's f1: 0.68127\tvalid_1's binary_logloss: 0.0977653\tvalid_1's f1: 0.662374\n",
      "[117]\ttraining's binary_logloss: 0.0888168\ttraining's f1: 0.681746\tvalid_1's binary_logloss: 0.0975034\tvalid_1's f1: 0.662601\n",
      "[118]\ttraining's binary_logloss: 0.088615\ttraining's f1: 0.682167\tvalid_1's binary_logloss: 0.0973364\tvalid_1's f1: 0.662809\n",
      "[119]\ttraining's binary_logloss: 0.0882865\ttraining's f1: 0.682571\tvalid_1's binary_logloss: 0.0970281\tvalid_1's f1: 0.663084\n",
      "[120]\ttraining's binary_logloss: 0.0879932\ttraining's f1: 0.682944\tvalid_1's binary_logloss: 0.0968038\tvalid_1's f1: 0.663503\n",
      "[121]\ttraining's binary_logloss: 0.0877715\ttraining's f1: 0.683196\tvalid_1's binary_logloss: 0.0966011\tvalid_1's f1: 0.663682\n",
      "[122]\ttraining's binary_logloss: 0.087464\ttraining's f1: 0.683634\tvalid_1's binary_logloss: 0.0963274\tvalid_1's f1: 0.663972\n",
      "[123]\ttraining's binary_logloss: 0.0872392\ttraining's f1: 0.683802\tvalid_1's binary_logloss: 0.0961183\tvalid_1's f1: 0.664157\n",
      "[124]\ttraining's binary_logloss: 0.086924\ttraining's f1: 0.68445\tvalid_1's binary_logloss: 0.0958358\tvalid_1's f1: 0.664779\n",
      "[125]\ttraining's binary_logloss: 0.0863715\ttraining's f1: 0.685782\tvalid_1's binary_logloss: 0.0953165\tvalid_1's f1: 0.665876\n",
      "[126]\ttraining's binary_logloss: 0.0859711\ttraining's f1: 0.686636\tvalid_1's binary_logloss: 0.0949524\tvalid_1's f1: 0.666482\n",
      "[127]\ttraining's binary_logloss: 0.085578\ttraining's f1: 0.68743\tvalid_1's binary_logloss: 0.09459\tvalid_1's f1: 0.666971\n",
      "[128]\ttraining's binary_logloss: 0.0852098\ttraining's f1: 0.688129\tvalid_1's binary_logloss: 0.0942592\tvalid_1's f1: 0.667439\n",
      "[129]\ttraining's binary_logloss: 0.0847777\ttraining's f1: 0.688818\tvalid_1's binary_logloss: 0.0938887\tvalid_1's f1: 0.668084\n",
      "[130]\ttraining's binary_logloss: 0.0843965\ttraining's f1: 0.689637\tvalid_1's binary_logloss: 0.0935559\tvalid_1's f1: 0.668452\n",
      "[131]\ttraining's binary_logloss: 0.0841384\ttraining's f1: 0.690031\tvalid_1's binary_logloss: 0.0933178\tvalid_1's f1: 0.668645\n",
      "[132]\ttraining's binary_logloss: 0.0839211\ttraining's f1: 0.690489\tvalid_1's binary_logloss: 0.0931222\tvalid_1's f1: 0.668925\n",
      "[133]\ttraining's binary_logloss: 0.083539\ttraining's f1: 0.690986\tvalid_1's binary_logloss: 0.0927806\tvalid_1's f1: 0.669406\n",
      "[134]\ttraining's binary_logloss: 0.0832335\ttraining's f1: 0.691518\tvalid_1's binary_logloss: 0.0925127\tvalid_1's f1: 0.669697\n",
      "[135]\ttraining's binary_logloss: 0.0828875\ttraining's f1: 0.691978\tvalid_1's binary_logloss: 0.0922207\tvalid_1's f1: 0.670329\n",
      "[136]\ttraining's binary_logloss: 0.0825719\ttraining's f1: 0.692547\tvalid_1's binary_logloss: 0.091942\tvalid_1's f1: 0.670926\n",
      "[137]\ttraining's binary_logloss: 0.0821958\ttraining's f1: 0.693074\tvalid_1's binary_logloss: 0.0916111\tvalid_1's f1: 0.671452\n",
      "[138]\ttraining's binary_logloss: 0.0819641\ttraining's f1: 0.693416\tvalid_1's binary_logloss: 0.0914151\tvalid_1's f1: 0.671743\n",
      "[139]\ttraining's binary_logloss: 0.0818089\ttraining's f1: 0.693603\tvalid_1's binary_logloss: 0.0912827\tvalid_1's f1: 0.671981\n",
      "[140]\ttraining's binary_logloss: 0.0813462\ttraining's f1: 0.694524\tvalid_1's binary_logloss: 0.0908801\tvalid_1's f1: 0.672682\n",
      "[141]\ttraining's binary_logloss: 0.081126\ttraining's f1: 0.694871\tvalid_1's binary_logloss: 0.0906943\tvalid_1's f1: 0.672836\n",
      "[142]\ttraining's binary_logloss: 0.080989\ttraining's f1: 0.695072\tvalid_1's binary_logloss: 0.0905929\tvalid_1's f1: 0.672954\n",
      "[143]\ttraining's binary_logloss: 0.0806664\ttraining's f1: 0.695824\tvalid_1's binary_logloss: 0.0902992\tvalid_1's f1: 0.673478\n",
      "[144]\ttraining's binary_logloss: 0.0804573\ttraining's f1: 0.696159\tvalid_1's binary_logloss: 0.090106\tvalid_1's f1: 0.673727\n",
      "[145]\ttraining's binary_logloss: 0.0800666\ttraining's f1: 0.697037\tvalid_1's binary_logloss: 0.0897454\tvalid_1's f1: 0.674368\n",
      "[146]\ttraining's binary_logloss: 0.0798693\ttraining's f1: 0.697382\tvalid_1's binary_logloss: 0.0895838\tvalid_1's f1: 0.674544\n",
      "[147]\ttraining's binary_logloss: 0.0794898\ttraining's f1: 0.698182\tvalid_1's binary_logloss: 0.0892395\tvalid_1's f1: 0.675104\n",
      "[148]\ttraining's binary_logloss: 0.0790809\ttraining's f1: 0.698979\tvalid_1's binary_logloss: 0.0888703\tvalid_1's f1: 0.675601\n",
      "[149]\ttraining's binary_logloss: 0.0788614\ttraining's f1: 0.699357\tvalid_1's binary_logloss: 0.0886745\tvalid_1's f1: 0.675705\n",
      "[150]\ttraining's binary_logloss: 0.078751\ttraining's f1: 0.69954\tvalid_1's binary_logloss: 0.0886015\tvalid_1's f1: 0.675876\n",
      "[151]\ttraining's binary_logloss: 0.0785973\ttraining's f1: 0.699743\tvalid_1's binary_logloss: 0.0884609\tvalid_1's f1: 0.676023\n",
      "[152]\ttraining's binary_logloss: 0.0783288\ttraining's f1: 0.700044\tvalid_1's binary_logloss: 0.0881979\tvalid_1's f1: 0.676517\n",
      "[153]\ttraining's binary_logloss: 0.0780704\ttraining's f1: 0.700473\tvalid_1's binary_logloss: 0.087972\tvalid_1's f1: 0.676938\n",
      "[154]\ttraining's binary_logloss: 0.0777916\ttraining's f1: 0.701067\tvalid_1's binary_logloss: 0.0877291\tvalid_1's f1: 0.677043\n",
      "[155]\ttraining's binary_logloss: 0.0775532\ttraining's f1: 0.701572\tvalid_1's binary_logloss: 0.0875225\tvalid_1's f1: 0.67745\n",
      "[156]\ttraining's binary_logloss: 0.0772877\ttraining's f1: 0.702036\tvalid_1's binary_logloss: 0.0872749\tvalid_1's f1: 0.677675\n",
      "[157]\ttraining's binary_logloss: 0.0770812\ttraining's f1: 0.702485\tvalid_1's binary_logloss: 0.0870856\tvalid_1's f1: 0.677916\n",
      "[158]\ttraining's binary_logloss: 0.0767289\ttraining's f1: 0.70308\tvalid_1's binary_logloss: 0.0867694\tvalid_1's f1: 0.678285\n",
      "[159]\ttraining's binary_logloss: 0.076434\ttraining's f1: 0.703729\tvalid_1's binary_logloss: 0.0865039\tvalid_1's f1: 0.678781\n",
      "[160]\ttraining's binary_logloss: 0.0760162\ttraining's f1: 0.704857\tvalid_1's binary_logloss: 0.0861418\tvalid_1's f1: 0.67951\n",
      "[161]\ttraining's binary_logloss: 0.075846\ttraining's f1: 0.705166\tvalid_1's binary_logloss: 0.0860074\tvalid_1's f1: 0.679722\n",
      "[162]\ttraining's binary_logloss: 0.0755879\ttraining's f1: 0.705685\tvalid_1's binary_logloss: 0.085774\tvalid_1's f1: 0.680124\n",
      "[163]\ttraining's binary_logloss: 0.0753382\ttraining's f1: 0.706331\tvalid_1's binary_logloss: 0.0855556\tvalid_1's f1: 0.680527\n",
      "[164]\ttraining's binary_logloss: 0.0751396\ttraining's f1: 0.706709\tvalid_1's binary_logloss: 0.0853778\tvalid_1's f1: 0.680879\n",
      "[165]\ttraining's binary_logloss: 0.0747999\ttraining's f1: 0.707606\tvalid_1's binary_logloss: 0.0850762\tvalid_1's f1: 0.681484\n",
      "[166]\ttraining's binary_logloss: 0.0745856\ttraining's f1: 0.707848\tvalid_1's binary_logloss: 0.0848778\tvalid_1's f1: 0.681788\n",
      "[167]\ttraining's binary_logloss: 0.0743666\ttraining's f1: 0.708378\tvalid_1's binary_logloss: 0.084675\tvalid_1's f1: 0.682162\n",
      "[168]\ttraining's binary_logloss: 0.0740831\ttraining's f1: 0.709005\tvalid_1's binary_logloss: 0.0844206\tvalid_1's f1: 0.682731\n",
      "[169]\ttraining's binary_logloss: 0.073617\ttraining's f1: 0.710682\tvalid_1's binary_logloss: 0.0839864\tvalid_1's f1: 0.683951\n",
      "[170]\ttraining's binary_logloss: 0.0734616\ttraining's f1: 0.711006\tvalid_1's binary_logloss: 0.0838442\tvalid_1's f1: 0.684219\n",
      "[171]\ttraining's binary_logloss: 0.0731259\ttraining's f1: 0.7117\tvalid_1's binary_logloss: 0.0835547\tvalid_1's f1: 0.684674\n",
      "[172]\ttraining's binary_logloss: 0.0729014\ttraining's f1: 0.712237\tvalid_1's binary_logloss: 0.0833672\tvalid_1's f1: 0.68498\n",
      "[173]\ttraining's binary_logloss: 0.0726652\ttraining's f1: 0.712578\tvalid_1's binary_logloss: 0.083175\tvalid_1's f1: 0.685177\n",
      "[174]\ttraining's binary_logloss: 0.0725642\ttraining's f1: 0.712723\tvalid_1's binary_logloss: 0.0830842\tvalid_1's f1: 0.685259\n",
      "[175]\ttraining's binary_logloss: 0.0723791\ttraining's f1: 0.713149\tvalid_1's binary_logloss: 0.0829093\tvalid_1's f1: 0.685494\n",
      "[176]\ttraining's binary_logloss: 0.072171\ttraining's f1: 0.713692\tvalid_1's binary_logloss: 0.0827301\tvalid_1's f1: 0.685774\n",
      "[177]\ttraining's binary_logloss: 0.0718806\ttraining's f1: 0.714257\tvalid_1's binary_logloss: 0.0824871\tvalid_1's f1: 0.686083\n",
      "[178]\ttraining's binary_logloss: 0.0716874\ttraining's f1: 0.714625\tvalid_1's binary_logloss: 0.0823153\tvalid_1's f1: 0.686499\n",
      "[179]\ttraining's binary_logloss: 0.0713571\ttraining's f1: 0.715407\tvalid_1's binary_logloss: 0.0820502\tvalid_1's f1: 0.687031\n",
      "[180]\ttraining's binary_logloss: 0.0709908\ttraining's f1: 0.716122\tvalid_1's binary_logloss: 0.081695\tvalid_1's f1: 0.687575\n",
      "[181]\ttraining's binary_logloss: 0.0707249\ttraining's f1: 0.716556\tvalid_1's binary_logloss: 0.0814727\tvalid_1's f1: 0.687749\n",
      "[182]\ttraining's binary_logloss: 0.0705086\ttraining's f1: 0.717034\tvalid_1's binary_logloss: 0.0812806\tvalid_1's f1: 0.687872\n",
      "[183]\ttraining's binary_logloss: 0.0703945\ttraining's f1: 0.717259\tvalid_1's binary_logloss: 0.0811925\tvalid_1's f1: 0.688111\n",
      "[184]\ttraining's binary_logloss: 0.0702859\ttraining's f1: 0.717518\tvalid_1's binary_logloss: 0.0810992\tvalid_1's f1: 0.688331\n",
      "[185]\ttraining's binary_logloss: 0.0701101\ttraining's f1: 0.717909\tvalid_1's binary_logloss: 0.080944\tvalid_1's f1: 0.688635\n",
      "[186]\ttraining's binary_logloss: 0.0698634\ttraining's f1: 0.718603\tvalid_1's binary_logloss: 0.080718\tvalid_1's f1: 0.689084\n",
      "[187]\ttraining's binary_logloss: 0.0697469\ttraining's f1: 0.718762\tvalid_1's binary_logloss: 0.0806199\tvalid_1's f1: 0.689099\n",
      "[188]\ttraining's binary_logloss: 0.069537\ttraining's f1: 0.719216\tvalid_1's binary_logloss: 0.0804319\tvalid_1's f1: 0.689293\n",
      "[189]\ttraining's binary_logloss: 0.0693791\ttraining's f1: 0.719481\tvalid_1's binary_logloss: 0.0802884\tvalid_1's f1: 0.689537\n",
      "[190]\ttraining's binary_logloss: 0.068951\ttraining's f1: 0.720796\tvalid_1's binary_logloss: 0.0798965\tvalid_1's f1: 0.690498\n",
      "[191]\ttraining's binary_logloss: 0.0687399\ttraining's f1: 0.721383\tvalid_1's binary_logloss: 0.0797147\tvalid_1's f1: 0.690818\n",
      "[192]\ttraining's binary_logloss: 0.0685706\ttraining's f1: 0.72169\tvalid_1's binary_logloss: 0.079564\tvalid_1's f1: 0.690957\n",
      "[193]\ttraining's binary_logloss: 0.0682626\ttraining's f1: 0.722367\tvalid_1's binary_logloss: 0.0792828\tvalid_1's f1: 0.691439\n",
      "[194]\ttraining's binary_logloss: 0.068154\ttraining's f1: 0.722498\tvalid_1's binary_logloss: 0.0791811\tvalid_1's f1: 0.691647\n",
      "[195]\ttraining's binary_logloss: 0.0679594\ttraining's f1: 0.722976\tvalid_1's binary_logloss: 0.0790155\tvalid_1's f1: 0.692053\n",
      "[196]\ttraining's binary_logloss: 0.0677297\ttraining's f1: 0.723516\tvalid_1's binary_logloss: 0.0788102\tvalid_1's f1: 0.692482\n",
      "[197]\ttraining's binary_logloss: 0.0674367\ttraining's f1: 0.724251\tvalid_1's binary_logloss: 0.0785442\tvalid_1's f1: 0.693027\n",
      "[198]\ttraining's binary_logloss: 0.0671073\ttraining's f1: 0.724986\tvalid_1's binary_logloss: 0.0782341\tvalid_1's f1: 0.693653\n",
      "[199]\ttraining's binary_logloss: 0.0669299\ttraining's f1: 0.725309\tvalid_1's binary_logloss: 0.0780831\tvalid_1's f1: 0.693768\n",
      "[200]\ttraining's binary_logloss: 0.0668079\ttraining's f1: 0.725508\tvalid_1's binary_logloss: 0.077998\tvalid_1's f1: 0.69395\n",
      "[201]\ttraining's binary_logloss: 0.0666739\ttraining's f1: 0.725714\tvalid_1's binary_logloss: 0.0778812\tvalid_1's f1: 0.694136\n",
      "[202]\ttraining's binary_logloss: 0.0664285\ttraining's f1: 0.726315\tvalid_1's binary_logloss: 0.0776663\tvalid_1's f1: 0.694489\n",
      "[203]\ttraining's binary_logloss: 0.0663302\ttraining's f1: 0.72648\tvalid_1's binary_logloss: 0.0775898\tvalid_1's f1: 0.694639\n",
      "[204]\ttraining's binary_logloss: 0.0661489\ttraining's f1: 0.726865\tvalid_1's binary_logloss: 0.0774314\tvalid_1's f1: 0.694913\n",
      "[205]\ttraining's binary_logloss: 0.066036\ttraining's f1: 0.727193\tvalid_1's binary_logloss: 0.0773376\tvalid_1's f1: 0.695169\n",
      "[206]\ttraining's binary_logloss: 0.0655977\ttraining's f1: 0.728342\tvalid_1's binary_logloss: 0.0769458\tvalid_1's f1: 0.696014\n",
      "[207]\ttraining's binary_logloss: 0.0654306\ttraining's f1: 0.728619\tvalid_1's binary_logloss: 0.076796\tvalid_1's f1: 0.69606\n",
      "[208]\ttraining's binary_logloss: 0.0653215\ttraining's f1: 0.728776\tvalid_1's binary_logloss: 0.0767046\tvalid_1's f1: 0.696199\n",
      "[209]\ttraining's binary_logloss: 0.0651798\ttraining's f1: 0.729085\tvalid_1's binary_logloss: 0.0765765\tvalid_1's f1: 0.696448\n",
      "[210]\ttraining's binary_logloss: 0.0649009\ttraining's f1: 0.729705\tvalid_1's binary_logloss: 0.0763299\tvalid_1's f1: 0.697022\n",
      "[211]\ttraining's binary_logloss: 0.0647832\ttraining's f1: 0.729938\tvalid_1's binary_logloss: 0.0762262\tvalid_1's f1: 0.697089\n",
      "[212]\ttraining's binary_logloss: 0.0644234\ttraining's f1: 0.730761\tvalid_1's binary_logloss: 0.0759017\tvalid_1's f1: 0.697535\n",
      "[213]\ttraining's binary_logloss: 0.0641136\ttraining's f1: 0.731885\tvalid_1's binary_logloss: 0.0756223\tvalid_1's f1: 0.698287\n",
      "[214]\ttraining's binary_logloss: 0.0638827\ttraining's f1: 0.732563\tvalid_1's binary_logloss: 0.0754135\tvalid_1's f1: 0.698816\n",
      "[215]\ttraining's binary_logloss: 0.063782\ttraining's f1: 0.732732\tvalid_1's binary_logloss: 0.0753232\tvalid_1's f1: 0.698881\n",
      "[216]\ttraining's binary_logloss: 0.0635654\ttraining's f1: 0.733382\tvalid_1's binary_logloss: 0.0751235\tvalid_1's f1: 0.699494\n",
      "[217]\ttraining's binary_logloss: 0.0633667\ttraining's f1: 0.733852\tvalid_1's binary_logloss: 0.0749603\tvalid_1's f1: 0.699568\n",
      "[218]\ttraining's binary_logloss: 0.0632096\ttraining's f1: 0.734275\tvalid_1's binary_logloss: 0.0748221\tvalid_1's f1: 0.699948\n",
      "[219]\ttraining's binary_logloss: 0.0630594\ttraining's f1: 0.734674\tvalid_1's binary_logloss: 0.0746825\tvalid_1's f1: 0.700177\n",
      "[220]\ttraining's binary_logloss: 0.0629514\ttraining's f1: 0.734866\tvalid_1's binary_logloss: 0.0745943\tvalid_1's f1: 0.700315\n",
      "[221]\ttraining's binary_logloss: 0.0626569\ttraining's f1: 0.735638\tvalid_1's binary_logloss: 0.0743238\tvalid_1's f1: 0.701232\n",
      "[222]\ttraining's binary_logloss: 0.0625242\ttraining's f1: 0.736021\tvalid_1's binary_logloss: 0.0742239\tvalid_1's f1: 0.701329\n",
      "[223]\ttraining's binary_logloss: 0.0622643\ttraining's f1: 0.736749\tvalid_1's binary_logloss: 0.0740034\tvalid_1's f1: 0.70184\n",
      "[224]\ttraining's binary_logloss: 0.0621238\ttraining's f1: 0.736985\tvalid_1's binary_logloss: 0.0738892\tvalid_1's f1: 0.702024\n",
      "[225]\ttraining's binary_logloss: 0.0618462\ttraining's f1: 0.737715\tvalid_1's binary_logloss: 0.0736475\tvalid_1's f1: 0.702338\n",
      "[226]\ttraining's binary_logloss: 0.0616067\ttraining's f1: 0.73833\tvalid_1's binary_logloss: 0.0734497\tvalid_1's f1: 0.702764\n",
      "[227]\ttraining's binary_logloss: 0.0613599\ttraining's f1: 0.739315\tvalid_1's binary_logloss: 0.0732268\tvalid_1's f1: 0.703191\n",
      "[228]\ttraining's binary_logloss: 0.0612836\ttraining's f1: 0.739425\tvalid_1's binary_logloss: 0.0731598\tvalid_1's f1: 0.703265\n",
      "[229]\ttraining's binary_logloss: 0.0610148\ttraining's f1: 0.740074\tvalid_1's binary_logloss: 0.0729189\tvalid_1's f1: 0.703855\n",
      "[230]\ttraining's binary_logloss: 0.0608639\ttraining's f1: 0.740542\tvalid_1's binary_logloss: 0.0727892\tvalid_1's f1: 0.704294\n",
      "[231]\ttraining's binary_logloss: 0.060692\ttraining's f1: 0.741033\tvalid_1's binary_logloss: 0.0726328\tvalid_1's f1: 0.704744\n",
      "[232]\ttraining's binary_logloss: 0.0605297\ttraining's f1: 0.741432\tvalid_1's binary_logloss: 0.0724816\tvalid_1's f1: 0.70512\n",
      "[233]\ttraining's binary_logloss: 0.0603372\ttraining's f1: 0.7419\tvalid_1's binary_logloss: 0.0723218\tvalid_1's f1: 0.705412\n",
      "[234]\ttraining's binary_logloss: 0.0601859\ttraining's f1: 0.7424\tvalid_1's binary_logloss: 0.0721982\tvalid_1's f1: 0.705623\n",
      "[235]\ttraining's binary_logloss: 0.0600405\ttraining's f1: 0.742881\tvalid_1's binary_logloss: 0.0720723\tvalid_1's f1: 0.705883\n",
      "[236]\ttraining's binary_logloss: 0.0597808\ttraining's f1: 0.743768\tvalid_1's binary_logloss: 0.0718371\tvalid_1's f1: 0.706487\n",
      "[237]\ttraining's binary_logloss: 0.0597293\ttraining's f1: 0.743869\tvalid_1's binary_logloss: 0.0717906\tvalid_1's f1: 0.706476\n",
      "[238]\ttraining's binary_logloss: 0.0595966\ttraining's f1: 0.74414\tvalid_1's binary_logloss: 0.0716718\tvalid_1's f1: 0.70664\n",
      "[239]\ttraining's binary_logloss: 0.0594786\ttraining's f1: 0.744472\tvalid_1's binary_logloss: 0.0715811\tvalid_1's f1: 0.706876\n",
      "[240]\ttraining's binary_logloss: 0.0593514\ttraining's f1: 0.744573\tvalid_1's binary_logloss: 0.0714691\tvalid_1's f1: 0.706789\n",
      "[241]\ttraining's binary_logloss: 0.059122\ttraining's f1: 0.745432\tvalid_1's binary_logloss: 0.0712793\tvalid_1's f1: 0.70724\n",
      "[242]\ttraining's binary_logloss: 0.0588746\ttraining's f1: 0.746167\tvalid_1's binary_logloss: 0.0710678\tvalid_1's f1: 0.70772\n",
      "[243]\ttraining's binary_logloss: 0.0587932\ttraining's f1: 0.746322\tvalid_1's binary_logloss: 0.0710017\tvalid_1's f1: 0.707797\n",
      "[244]\ttraining's binary_logloss: 0.0586001\ttraining's f1: 0.746852\tvalid_1's binary_logloss: 0.0708554\tvalid_1's f1: 0.708041\n",
      "[245]\ttraining's binary_logloss: 0.0584366\ttraining's f1: 0.747151\tvalid_1's binary_logloss: 0.0707218\tvalid_1's f1: 0.708191\n",
      "[246]\ttraining's binary_logloss: 0.0582026\ttraining's f1: 0.747774\tvalid_1's binary_logloss: 0.0705291\tvalid_1's f1: 0.708709\n",
      "[247]\ttraining's binary_logloss: 0.0578976\ttraining's f1: 0.749177\tvalid_1's binary_logloss: 0.0702503\tvalid_1's f1: 0.709841\n",
      "[248]\ttraining's binary_logloss: 0.0577846\ttraining's f1: 0.749327\tvalid_1's binary_logloss: 0.0701514\tvalid_1's f1: 0.710021\n",
      "[249]\ttraining's binary_logloss: 0.0575135\ttraining's f1: 0.750155\tvalid_1's binary_logloss: 0.0699071\tvalid_1's f1: 0.710829\n",
      "[250]\ttraining's binary_logloss: 0.0573393\ttraining's f1: 0.750636\tvalid_1's binary_logloss: 0.0697716\tvalid_1's f1: 0.710994\n",
      "[251]\ttraining's binary_logloss: 0.0572395\ttraining's f1: 0.750805\tvalid_1's binary_logloss: 0.06969\tvalid_1's f1: 0.71113\n",
      "[252]\ttraining's binary_logloss: 0.0571196\ttraining's f1: 0.75115\tvalid_1's binary_logloss: 0.0695923\tvalid_1's f1: 0.711301\n",
      "[253]\ttraining's binary_logloss: 0.0569795\ttraining's f1: 0.751592\tvalid_1's binary_logloss: 0.0694702\tvalid_1's f1: 0.711413\n",
      "[254]\ttraining's binary_logloss: 0.0568897\ttraining's f1: 0.751841\tvalid_1's binary_logloss: 0.0694045\tvalid_1's f1: 0.711613\n",
      "[255]\ttraining's binary_logloss: 0.0566865\ttraining's f1: 0.752285\tvalid_1's binary_logloss: 0.0692145\tvalid_1's f1: 0.712009\n",
      "[256]\ttraining's binary_logloss: 0.056622\ttraining's f1: 0.752373\tvalid_1's binary_logloss: 0.0691529\tvalid_1's f1: 0.712028\n",
      "[257]\ttraining's binary_logloss: 0.0564835\ttraining's f1: 0.752731\tvalid_1's binary_logloss: 0.0690613\tvalid_1's f1: 0.712299\n",
      "[258]\ttraining's binary_logloss: 0.0562632\ttraining's f1: 0.75342\tvalid_1's binary_logloss: 0.0688629\tvalid_1's f1: 0.712789\n",
      "[259]\ttraining's binary_logloss: 0.0562019\ttraining's f1: 0.753533\tvalid_1's binary_logloss: 0.0688113\tvalid_1's f1: 0.712813\n",
      "[260]\ttraining's binary_logloss: 0.0560988\ttraining's f1: 0.753795\tvalid_1's binary_logloss: 0.0687261\tvalid_1's f1: 0.712942\n",
      "[261]\ttraining's binary_logloss: 0.0559449\ttraining's f1: 0.754259\tvalid_1's binary_logloss: 0.0686062\tvalid_1's f1: 0.7132\n",
      "[262]\ttraining's binary_logloss: 0.0558669\ttraining's f1: 0.754475\tvalid_1's binary_logloss: 0.0685491\tvalid_1's f1: 0.713265\n",
      "[263]\ttraining's binary_logloss: 0.0556616\ttraining's f1: 0.755164\tvalid_1's binary_logloss: 0.0683991\tvalid_1's f1: 0.714026\n",
      "[264]\ttraining's binary_logloss: 0.0554278\ttraining's f1: 0.755894\tvalid_1's binary_logloss: 0.0681847\tvalid_1's f1: 0.714622\n",
      "[265]\ttraining's binary_logloss: 0.0553699\ttraining's f1: 0.756046\tvalid_1's binary_logloss: 0.0681343\tvalid_1's f1: 0.714551\n",
      "[266]\ttraining's binary_logloss: 0.0552634\ttraining's f1: 0.756279\tvalid_1's binary_logloss: 0.0680579\tvalid_1's f1: 0.714731\n",
      "[267]\ttraining's binary_logloss: 0.0551443\ttraining's f1: 0.756747\tvalid_1's binary_logloss: 0.0679566\tvalid_1's f1: 0.715044\n",
      "[268]\ttraining's binary_logloss: 0.0549693\ttraining's f1: 0.757312\tvalid_1's binary_logloss: 0.0677893\tvalid_1's f1: 0.715566\n",
      "[269]\ttraining's binary_logloss: 0.0548011\ttraining's f1: 0.757875\tvalid_1's binary_logloss: 0.0676476\tvalid_1's f1: 0.71587\n",
      "[270]\ttraining's binary_logloss: 0.0547492\ttraining's f1: 0.757976\tvalid_1's binary_logloss: 0.067614\tvalid_1's f1: 0.715874\n",
      "[271]\ttraining's binary_logloss: 0.0546725\ttraining's f1: 0.75815\tvalid_1's binary_logloss: 0.0675514\tvalid_1's f1: 0.715842\n",
      "[272]\ttraining's binary_logloss: 0.0544345\ttraining's f1: 0.758914\tvalid_1's binary_logloss: 0.0673605\tvalid_1's f1: 0.716437\n",
      "[273]\ttraining's binary_logloss: 0.0542089\ttraining's f1: 0.759824\tvalid_1's binary_logloss: 0.0671523\tvalid_1's f1: 0.716939\n",
      "[274]\ttraining's binary_logloss: 0.0541133\ttraining's f1: 0.760083\tvalid_1's binary_logloss: 0.0670794\tvalid_1's f1: 0.717019\n",
      "[275]\ttraining's binary_logloss: 0.0539562\ttraining's f1: 0.760553\tvalid_1's binary_logloss: 0.0669538\tvalid_1's f1: 0.717351\n",
      "[276]\ttraining's binary_logloss: 0.0538754\ttraining's f1: 0.76074\tvalid_1's binary_logloss: 0.0668851\tvalid_1's f1: 0.717571\n",
      "[277]\ttraining's binary_logloss: 0.0538153\ttraining's f1: 0.760887\tvalid_1's binary_logloss: 0.0668397\tvalid_1's f1: 0.71774\n",
      "[278]\ttraining's binary_logloss: 0.0537493\ttraining's f1: 0.76102\tvalid_1's binary_logloss: 0.0667892\tvalid_1's f1: 0.717884\n",
      "[279]\ttraining's binary_logloss: 0.0535588\ttraining's f1: 0.761587\tvalid_1's binary_logloss: 0.0666415\tvalid_1's f1: 0.718388\n",
      "[280]\ttraining's binary_logloss: 0.0534242\ttraining's f1: 0.76184\tvalid_1's binary_logloss: 0.0665211\tvalid_1's f1: 0.718546\n",
      "[281]\ttraining's binary_logloss: 0.0533246\ttraining's f1: 0.761988\tvalid_1's binary_logloss: 0.0664391\tvalid_1's f1: 0.718716\n",
      "[282]\ttraining's binary_logloss: 0.0531457\ttraining's f1: 0.762579\tvalid_1's binary_logloss: 0.0662874\tvalid_1's f1: 0.719032\n",
      "[283]\ttraining's binary_logloss: 0.052911\ttraining's f1: 0.763472\tvalid_1's binary_logloss: 0.0660889\tvalid_1's f1: 0.719567\n",
      "[284]\ttraining's binary_logloss: 0.0527229\ttraining's f1: 0.764079\tvalid_1's binary_logloss: 0.0659327\tvalid_1's f1: 0.719919\n",
      "[285]\ttraining's binary_logloss: 0.0526505\ttraining's f1: 0.764265\tvalid_1's binary_logloss: 0.0658727\tvalid_1's f1: 0.720107\n",
      "[286]\ttraining's binary_logloss: 0.0525539\ttraining's f1: 0.764512\tvalid_1's binary_logloss: 0.0657862\tvalid_1's f1: 0.720245\n",
      "[287]\ttraining's binary_logloss: 0.05233\ttraining's f1: 0.765614\tvalid_1's binary_logloss: 0.0655804\tvalid_1's f1: 0.720939\n",
      "[288]\ttraining's binary_logloss: 0.0522421\ttraining's f1: 0.76594\tvalid_1's binary_logloss: 0.0655134\tvalid_1's f1: 0.721019\n",
      "[289]\ttraining's binary_logloss: 0.0521908\ttraining's f1: 0.766021\tvalid_1's binary_logloss: 0.0654704\tvalid_1's f1: 0.721103\n",
      "[290]\ttraining's binary_logloss: 0.0520655\ttraining's f1: 0.766368\tvalid_1's binary_logloss: 0.0653415\tvalid_1's f1: 0.721252\n",
      "[291]\ttraining's binary_logloss: 0.0519296\ttraining's f1: 0.766669\tvalid_1's binary_logloss: 0.0652261\tvalid_1's f1: 0.721535\n",
      "[292]\ttraining's binary_logloss: 0.0517122\ttraining's f1: 0.767567\tvalid_1's binary_logloss: 0.0650177\tvalid_1's f1: 0.722127\n",
      "[293]\ttraining's binary_logloss: 0.0514185\ttraining's f1: 0.76878\tvalid_1's binary_logloss: 0.0647387\tvalid_1's f1: 0.722948\n",
      "[294]\ttraining's binary_logloss: 0.0513088\ttraining's f1: 0.769149\tvalid_1's binary_logloss: 0.0646489\tvalid_1's f1: 0.722968\n",
      "[295]\ttraining's binary_logloss: 0.051196\ttraining's f1: 0.769482\tvalid_1's binary_logloss: 0.0645544\tvalid_1's f1: 0.723186\n",
      "[296]\ttraining's binary_logloss: 0.0511133\ttraining's f1: 0.769644\tvalid_1's binary_logloss: 0.0644929\tvalid_1's f1: 0.723205\n",
      "[297]\ttraining's binary_logloss: 0.0508871\ttraining's f1: 0.770565\tvalid_1's binary_logloss: 0.0642864\tvalid_1's f1: 0.723381\n",
      "[298]\ttraining's binary_logloss: 0.0508212\ttraining's f1: 0.770628\tvalid_1's binary_logloss: 0.0642299\tvalid_1's f1: 0.723534\n",
      "[299]\ttraining's binary_logloss: 0.0506613\ttraining's f1: 0.77098\tvalid_1's binary_logloss: 0.0640786\tvalid_1's f1: 0.723862\n",
      "[300]\ttraining's binary_logloss: 0.0505389\ttraining's f1: 0.77156\tvalid_1's binary_logloss: 0.063973\tvalid_1's f1: 0.724091\n",
      "[301]\ttraining's binary_logloss: 0.0504357\ttraining's f1: 0.771776\tvalid_1's binary_logloss: 0.0638966\tvalid_1's f1: 0.724296\n",
      "[302]\ttraining's binary_logloss: 0.0502614\ttraining's f1: 0.772349\tvalid_1's binary_logloss: 0.0637345\tvalid_1's f1: 0.72468\n",
      "[303]\ttraining's binary_logloss: 0.0501745\ttraining's f1: 0.772678\tvalid_1's binary_logloss: 0.0636772\tvalid_1's f1: 0.724873\n",
      "[304]\ttraining's binary_logloss: 0.0501273\ttraining's f1: 0.772726\tvalid_1's binary_logloss: 0.0636406\tvalid_1's f1: 0.724911\n",
      "[305]\ttraining's binary_logloss: 0.049997\ttraining's f1: 0.773126\tvalid_1's binary_logloss: 0.0635421\tvalid_1's f1: 0.724938\n",
      "[306]\ttraining's binary_logloss: 0.0499262\ttraining's f1: 0.77342\tvalid_1's binary_logloss: 0.0634796\tvalid_1's f1: 0.725057\n",
      "[307]\ttraining's binary_logloss: 0.0497999\ttraining's f1: 0.773918\tvalid_1's binary_logloss: 0.0633648\tvalid_1's f1: 0.725274\n",
      "[308]\ttraining's binary_logloss: 0.0496449\ttraining's f1: 0.774402\tvalid_1's binary_logloss: 0.0632342\tvalid_1's f1: 0.725804\n",
      "[309]\ttraining's binary_logloss: 0.0494727\ttraining's f1: 0.774844\tvalid_1's binary_logloss: 0.0630807\tvalid_1's f1: 0.726244\n",
      "[310]\ttraining's binary_logloss: 0.0493743\ttraining's f1: 0.775065\tvalid_1's binary_logloss: 0.0629985\tvalid_1's f1: 0.72656\n",
      "[311]\ttraining's binary_logloss: 0.049261\ttraining's f1: 0.775395\tvalid_1's binary_logloss: 0.0629019\tvalid_1's f1: 0.726624\n",
      "[312]\ttraining's binary_logloss: 0.0491866\ttraining's f1: 0.775585\tvalid_1's binary_logloss: 0.0628423\tvalid_1's f1: 0.726726\n",
      "[313]\ttraining's binary_logloss: 0.0490226\ttraining's f1: 0.776292\tvalid_1's binary_logloss: 0.062688\tvalid_1's f1: 0.727219\n",
      "[314]\ttraining's binary_logloss: 0.0489631\ttraining's f1: 0.776384\tvalid_1's binary_logloss: 0.0626389\tvalid_1's f1: 0.727298\n",
      "[315]\ttraining's binary_logloss: 0.0488185\ttraining's f1: 0.776898\tvalid_1's binary_logloss: 0.0625134\tvalid_1's f1: 0.727515\n",
      "[316]\ttraining's binary_logloss: 0.0486801\ttraining's f1: 0.77733\tvalid_1's binary_logloss: 0.0624015\tvalid_1's f1: 0.727694\n",
      "[317]\ttraining's binary_logloss: 0.0485285\ttraining's f1: 0.777737\tvalid_1's binary_logloss: 0.0622691\tvalid_1's f1: 0.728103\n",
      "[318]\ttraining's binary_logloss: 0.0483992\ttraining's f1: 0.778222\tvalid_1's binary_logloss: 0.0621547\tvalid_1's f1: 0.728487\n",
      "[319]\ttraining's binary_logloss: 0.0483443\ttraining's f1: 0.778299\tvalid_1's binary_logloss: 0.0621088\tvalid_1's f1: 0.728527\n",
      "[320]\ttraining's binary_logloss: 0.0482545\ttraining's f1: 0.778548\tvalid_1's binary_logloss: 0.0620465\tvalid_1's f1: 0.728576\n",
      "[321]\ttraining's binary_logloss: 0.0481289\ttraining's f1: 0.778985\tvalid_1's binary_logloss: 0.0619462\tvalid_1's f1: 0.728922\n",
      "[322]\ttraining's binary_logloss: 0.0480674\ttraining's f1: 0.779152\tvalid_1's binary_logloss: 0.0619137\tvalid_1's f1: 0.728945\n",
      "[323]\ttraining's binary_logloss: 0.0479412\ttraining's f1: 0.779507\tvalid_1's binary_logloss: 0.0617867\tvalid_1's f1: 0.72905\n",
      "[324]\ttraining's binary_logloss: 0.047859\ttraining's f1: 0.779741\tvalid_1's binary_logloss: 0.0617233\tvalid_1's f1: 0.729277\n",
      "[325]\ttraining's binary_logloss: 0.0477662\ttraining's f1: 0.779931\tvalid_1's binary_logloss: 0.0616478\tvalid_1's f1: 0.729383\n",
      "[326]\ttraining's binary_logloss: 0.0476241\ttraining's f1: 0.780428\tvalid_1's binary_logloss: 0.0615494\tvalid_1's f1: 0.729564\n",
      "[327]\ttraining's binary_logloss: 0.047517\ttraining's f1: 0.78068\tvalid_1's binary_logloss: 0.0614505\tvalid_1's f1: 0.729955\n",
      "[328]\ttraining's binary_logloss: 0.0474302\ttraining's f1: 0.780882\tvalid_1's binary_logloss: 0.0613808\tvalid_1's f1: 0.730062\n",
      "[329]\ttraining's binary_logloss: 0.0472673\ttraining's f1: 0.7818\tvalid_1's binary_logloss: 0.0612426\tvalid_1's f1: 0.730667\n",
      "[330]\ttraining's binary_logloss: 0.04717\ttraining's f1: 0.78198\tvalid_1's binary_logloss: 0.0611607\tvalid_1's f1: 0.730745\n",
      "[331]\ttraining's binary_logloss: 0.0470408\ttraining's f1: 0.782411\tvalid_1's binary_logloss: 0.0610478\tvalid_1's f1: 0.731192\n",
      "[332]\ttraining's binary_logloss: 0.0468878\ttraining's f1: 0.782836\tvalid_1's binary_logloss: 0.0609118\tvalid_1's f1: 0.731518\n",
      "[333]\ttraining's binary_logloss: 0.0468166\ttraining's f1: 0.782996\tvalid_1's binary_logloss: 0.0608695\tvalid_1's f1: 0.731489\n",
      "[334]\ttraining's binary_logloss: 0.0467769\ttraining's f1: 0.783075\tvalid_1's binary_logloss: 0.0608378\tvalid_1's f1: 0.731529\n",
      "[335]\ttraining's binary_logloss: 0.0466607\ttraining's f1: 0.783389\tvalid_1's binary_logloss: 0.0607443\tvalid_1's f1: 0.731747\n",
      "[336]\ttraining's binary_logloss: 0.0465566\ttraining's f1: 0.783834\tvalid_1's binary_logloss: 0.0606614\tvalid_1's f1: 0.731892\n",
      "[337]\ttraining's binary_logloss: 0.046378\ttraining's f1: 0.784522\tvalid_1's binary_logloss: 0.0605208\tvalid_1's f1: 0.732258\n",
      "[338]\ttraining's binary_logloss: 0.0462292\ttraining's f1: 0.784965\tvalid_1's binary_logloss: 0.0604072\tvalid_1's f1: 0.732695\n",
      "[339]\ttraining's binary_logloss: 0.0460794\ttraining's f1: 0.785757\tvalid_1's binary_logloss: 0.0602809\tvalid_1's f1: 0.733149\n",
      "[340]\ttraining's binary_logloss: 0.0459427\ttraining's f1: 0.786145\tvalid_1's binary_logloss: 0.0601622\tvalid_1's f1: 0.733453\n",
      "[341]\ttraining's binary_logloss: 0.0458531\ttraining's f1: 0.786337\tvalid_1's binary_logloss: 0.0600978\tvalid_1's f1: 0.733437\n",
      "[342]\ttraining's binary_logloss: 0.0457214\ttraining's f1: 0.786983\tvalid_1's binary_logloss: 0.0599952\tvalid_1's f1: 0.733851\n",
      "[343]\ttraining's binary_logloss: 0.0456102\ttraining's f1: 0.787287\tvalid_1's binary_logloss: 0.0599009\tvalid_1's f1: 0.734143\n",
      "[344]\ttraining's binary_logloss: 0.0454914\ttraining's f1: 0.787797\tvalid_1's binary_logloss: 0.0598079\tvalid_1's f1: 0.734114\n",
      "[345]\ttraining's binary_logloss: 0.0454087\ttraining's f1: 0.788067\tvalid_1's binary_logloss: 0.0597451\tvalid_1's f1: 0.734168\n",
      "[346]\ttraining's binary_logloss: 0.0453183\ttraining's f1: 0.78839\tvalid_1's binary_logloss: 0.0596704\tvalid_1's f1: 0.734265\n",
      "[347]\ttraining's binary_logloss: 0.0451067\ttraining's f1: 0.789294\tvalid_1's binary_logloss: 0.0595046\tvalid_1's f1: 0.73481\n",
      "[348]\ttraining's binary_logloss: 0.0450254\ttraining's f1: 0.7894\tvalid_1's binary_logloss: 0.0594343\tvalid_1's f1: 0.734865\n",
      "[349]\ttraining's binary_logloss: 0.0449148\ttraining's f1: 0.789768\tvalid_1's binary_logloss: 0.0593423\tvalid_1's f1: 0.735187\n",
      "[350]\ttraining's binary_logloss: 0.044765\ttraining's f1: 0.790268\tvalid_1's binary_logloss: 0.0592149\tvalid_1's f1: 0.735623\n",
      "[351]\ttraining's binary_logloss: 0.0447071\ttraining's f1: 0.790351\tvalid_1's binary_logloss: 0.0591788\tvalid_1's f1: 0.735679\n",
      "[352]\ttraining's binary_logloss: 0.0445974\ttraining's f1: 0.790739\tvalid_1's binary_logloss: 0.059072\tvalid_1's f1: 0.736018\n",
      "[353]\ttraining's binary_logloss: 0.0445515\ttraining's f1: 0.790865\tvalid_1's binary_logloss: 0.0590375\tvalid_1's f1: 0.736017\n",
      "[354]\ttraining's binary_logloss: 0.0444394\ttraining's f1: 0.79132\tvalid_1's binary_logloss: 0.0589339\tvalid_1's f1: 0.736201\n",
      "[355]\ttraining's binary_logloss: 0.0443161\ttraining's f1: 0.791813\tvalid_1's binary_logloss: 0.0588512\tvalid_1's f1: 0.736328\n",
      "[356]\ttraining's binary_logloss: 0.0442555\ttraining's f1: 0.792114\tvalid_1's binary_logloss: 0.058799\tvalid_1's f1: 0.736384\n",
      "[357]\ttraining's binary_logloss: 0.0440709\ttraining's f1: 0.792827\tvalid_1's binary_logloss: 0.0586305\tvalid_1's f1: 0.736997\n",
      "[358]\ttraining's binary_logloss: 0.043891\ttraining's f1: 0.793579\tvalid_1's binary_logloss: 0.0584852\tvalid_1's f1: 0.737354\n",
      "[359]\ttraining's binary_logloss: 0.0438055\ttraining's f1: 0.793841\tvalid_1's binary_logloss: 0.0584121\tvalid_1's f1: 0.737569\n",
      "[360]\ttraining's binary_logloss: 0.0437096\ttraining's f1: 0.794213\tvalid_1's binary_logloss: 0.0583174\tvalid_1's f1: 0.738143\n",
      "[361]\ttraining's binary_logloss: 0.0435839\ttraining's f1: 0.794598\tvalid_1's binary_logloss: 0.058212\tvalid_1's f1: 0.73849\n",
      "[362]\ttraining's binary_logloss: 0.0435396\ttraining's f1: 0.794757\tvalid_1's binary_logloss: 0.0581793\tvalid_1's f1: 0.738605\n",
      "[363]\ttraining's binary_logloss: 0.0434996\ttraining's f1: 0.794788\tvalid_1's binary_logloss: 0.0581476\tvalid_1's f1: 0.738721\n",
      "[364]\ttraining's binary_logloss: 0.0434635\ttraining's f1: 0.79488\tvalid_1's binary_logloss: 0.0581245\tvalid_1's f1: 0.73875\n",
      "[365]\ttraining's binary_logloss: 0.0433223\ttraining's f1: 0.795347\tvalid_1's binary_logloss: 0.0580074\tvalid_1's f1: 0.738895\n",
      "[366]\ttraining's binary_logloss: 0.0432624\ttraining's f1: 0.79555\tvalid_1's binary_logloss: 0.0579611\tvalid_1's f1: 0.739068\n",
      "[367]\ttraining's binary_logloss: 0.043169\ttraining's f1: 0.795741\tvalid_1's binary_logloss: 0.0578811\tvalid_1's f1: 0.739286\n",
      "[368]\ttraining's binary_logloss: 0.0430338\ttraining's f1: 0.796129\tvalid_1's binary_logloss: 0.0577549\tvalid_1's f1: 0.739679\n",
      "[369]\ttraining's binary_logloss: 0.0429699\ttraining's f1: 0.79634\tvalid_1's binary_logloss: 0.057711\tvalid_1's f1: 0.739897\n",
      "[370]\ttraining's binary_logloss: 0.0427396\ttraining's f1: 0.79752\tvalid_1's binary_logloss: 0.0575083\tvalid_1's f1: 0.740659\n",
      "[371]\ttraining's binary_logloss: 0.0426766\ttraining's f1: 0.797863\tvalid_1's binary_logloss: 0.0574579\tvalid_1's f1: 0.740633\n",
      "[372]\ttraining's binary_logloss: 0.0425064\ttraining's f1: 0.798432\tvalid_1's binary_logloss: 0.0573019\tvalid_1's f1: 0.741237\n",
      "[373]\ttraining's binary_logloss: 0.0424281\ttraining's f1: 0.798746\tvalid_1's binary_logloss: 0.0572385\tvalid_1's f1: 0.741239\n",
      "[374]\ttraining's binary_logloss: 0.0423342\ttraining's f1: 0.798953\tvalid_1's binary_logloss: 0.0571549\tvalid_1's f1: 0.741445\n",
      "[375]\ttraining's binary_logloss: 0.0422634\ttraining's f1: 0.799186\tvalid_1's binary_logloss: 0.0571125\tvalid_1's f1: 0.741666\n",
      "[376]\ttraining's binary_logloss: 0.0422185\ttraining's f1: 0.799343\tvalid_1's binary_logloss: 0.05709\tvalid_1's f1: 0.741669\n",
      "[377]\ttraining's binary_logloss: 0.04211\ttraining's f1: 0.799646\tvalid_1's binary_logloss: 0.0570004\tvalid_1's f1: 0.742041\n",
      "[378]\ttraining's binary_logloss: 0.0420245\ttraining's f1: 0.799956\tvalid_1's binary_logloss: 0.0569237\tvalid_1's f1: 0.742266\n",
      "[379]\ttraining's binary_logloss: 0.0418337\ttraining's f1: 0.800965\tvalid_1's binary_logloss: 0.0567583\tvalid_1's f1: 0.742906\n",
      "[380]\ttraining's binary_logloss: 0.0417598\ttraining's f1: 0.801156\tvalid_1's binary_logloss: 0.0566983\tvalid_1's f1: 0.743102\n",
      "[381]\ttraining's binary_logloss: 0.0416115\ttraining's f1: 0.801935\tvalid_1's binary_logloss: 0.0565716\tvalid_1's f1: 0.743616\n",
      "[382]\ttraining's binary_logloss: 0.0415792\ttraining's f1: 0.801974\tvalid_1's binary_logloss: 0.0565488\tvalid_1's f1: 0.743645\n",
      "[383]\ttraining's binary_logloss: 0.0415074\ttraining's f1: 0.802153\tvalid_1's binary_logloss: 0.0564907\tvalid_1's f1: 0.743722\n",
      "[384]\ttraining's binary_logloss: 0.041355\ttraining's f1: 0.803105\tvalid_1's binary_logloss: 0.0563615\tvalid_1's f1: 0.744195\n",
      "[385]\ttraining's binary_logloss: 0.0412752\ttraining's f1: 0.803279\tvalid_1's binary_logloss: 0.0563001\tvalid_1's f1: 0.74427\n",
      "[386]\ttraining's binary_logloss: 0.0411253\ttraining's f1: 0.803848\tvalid_1's binary_logloss: 0.0561628\tvalid_1's f1: 0.744634\n",
      "[387]\ttraining's binary_logloss: 0.0410473\ttraining's f1: 0.804094\tvalid_1's binary_logloss: 0.0560964\tvalid_1's f1: 0.744939\n",
      "[388]\ttraining's binary_logloss: 0.0409574\ttraining's f1: 0.80436\tvalid_1's binary_logloss: 0.056032\tvalid_1's f1: 0.744956\n",
      "[389]\ttraining's binary_logloss: 0.0408968\ttraining's f1: 0.804575\tvalid_1's binary_logloss: 0.0559883\tvalid_1's f1: 0.744976\n",
      "[390]\ttraining's binary_logloss: 0.0407929\ttraining's f1: 0.804979\tvalid_1's binary_logloss: 0.0559032\tvalid_1's f1: 0.745179\n",
      "[391]\ttraining's binary_logloss: 0.0407324\ttraining's f1: 0.805207\tvalid_1's binary_logloss: 0.0558592\tvalid_1's f1: 0.745319\n",
      "[392]\ttraining's binary_logloss: 0.0406589\ttraining's f1: 0.805318\tvalid_1's binary_logloss: 0.0558048\tvalid_1's f1: 0.745471\n",
      "[393]\ttraining's binary_logloss: 0.0405642\ttraining's f1: 0.805718\tvalid_1's binary_logloss: 0.0557352\tvalid_1's f1: 0.745896\n",
      "[394]\ttraining's binary_logloss: 0.040418\ttraining's f1: 0.806334\tvalid_1's binary_logloss: 0.0556129\tvalid_1's f1: 0.746403\n",
      "[395]\ttraining's binary_logloss: 0.040343\ttraining's f1: 0.806604\tvalid_1's binary_logloss: 0.0555455\tvalid_1's f1: 0.746636\n",
      "[396]\ttraining's binary_logloss: 0.0402795\ttraining's f1: 0.806815\tvalid_1's binary_logloss: 0.0554984\tvalid_1's f1: 0.746854\n",
      "[397]\ttraining's binary_logloss: 0.0401186\ttraining's f1: 0.80743\tvalid_1's binary_logloss: 0.0553688\tvalid_1's f1: 0.747508\n",
      "[398]\ttraining's binary_logloss: 0.0400078\ttraining's f1: 0.808079\tvalid_1's binary_logloss: 0.0552702\tvalid_1's f1: 0.747652\n",
      "[399]\ttraining's binary_logloss: 0.0399572\ttraining's f1: 0.808292\tvalid_1's binary_logloss: 0.0552261\tvalid_1's f1: 0.747672\n",
      "[400]\ttraining's binary_logloss: 0.039876\ttraining's f1: 0.808512\tvalid_1's binary_logloss: 0.0551488\tvalid_1's f1: 0.747953\n",
      "[401]\ttraining's binary_logloss: 0.0397912\ttraining's f1: 0.808852\tvalid_1's binary_logloss: 0.0550712\tvalid_1's f1: 0.748173\n",
      "[402]\ttraining's binary_logloss: 0.039661\ttraining's f1: 0.809501\tvalid_1's binary_logloss: 0.0549522\tvalid_1's f1: 0.748684\n",
      "[403]\ttraining's binary_logloss: 0.0395508\ttraining's f1: 0.809836\tvalid_1's binary_logloss: 0.054878\tvalid_1's f1: 0.74894\n",
      "[404]\ttraining's binary_logloss: 0.0394092\ttraining's f1: 0.810806\tvalid_1's binary_logloss: 0.0547541\tvalid_1's f1: 0.749425\n",
      "[405]\ttraining's binary_logloss: 0.0393543\ttraining's f1: 0.811063\tvalid_1's binary_logloss: 0.0547038\tvalid_1's f1: 0.749646\n",
      "[406]\ttraining's binary_logloss: 0.0393205\ttraining's f1: 0.811184\tvalid_1's binary_logloss: 0.0546793\tvalid_1's f1: 0.749773\n",
      "[407]\ttraining's binary_logloss: 0.0391693\ttraining's f1: 0.811849\tvalid_1's binary_logloss: 0.0545601\tvalid_1's f1: 0.750217\n",
      "[408]\ttraining's binary_logloss: 0.0390347\ttraining's f1: 0.812837\tvalid_1's binary_logloss: 0.0544415\tvalid_1's f1: 0.750931\n",
      "[409]\ttraining's binary_logloss: 0.0389603\ttraining's f1: 0.81309\tvalid_1's binary_logloss: 0.0543824\tvalid_1's f1: 0.75108\n",
      "[410]\ttraining's binary_logloss: 0.0388516\ttraining's f1: 0.813673\tvalid_1's binary_logloss: 0.0542932\tvalid_1's f1: 0.751593\n",
      "[411]\ttraining's binary_logloss: 0.0388058\ttraining's f1: 0.813762\tvalid_1's binary_logloss: 0.0542615\tvalid_1's f1: 0.751737\n",
      "[412]\ttraining's binary_logloss: 0.0387424\ttraining's f1: 0.813962\tvalid_1's binary_logloss: 0.0542082\tvalid_1's f1: 0.751949\n",
      "[413]\ttraining's binary_logloss: 0.0386084\ttraining's f1: 0.81461\tvalid_1's binary_logloss: 0.054096\tvalid_1's f1: 0.75243\n",
      "[414]\ttraining's binary_logloss: 0.0385075\ttraining's f1: 0.815018\tvalid_1's binary_logloss: 0.0540214\tvalid_1's f1: 0.752591\n",
      "[415]\ttraining's binary_logloss: 0.0384689\ttraining's f1: 0.815115\tvalid_1's binary_logloss: 0.0539986\tvalid_1's f1: 0.752624\n",
      "[416]\ttraining's binary_logloss: 0.0384399\ttraining's f1: 0.815239\tvalid_1's binary_logloss: 0.0539819\tvalid_1's f1: 0.752533\n",
      "[417]\ttraining's binary_logloss: 0.0383717\ttraining's f1: 0.815434\tvalid_1's binary_logloss: 0.0539212\tvalid_1's f1: 0.752714\n",
      "[418]\ttraining's binary_logloss: 0.0383362\ttraining's f1: 0.815586\tvalid_1's binary_logloss: 0.0538945\tvalid_1's f1: 0.752766\n",
      "[419]\ttraining's binary_logloss: 0.0382176\ttraining's f1: 0.816115\tvalid_1's binary_logloss: 0.053791\tvalid_1's f1: 0.753094\n",
      "[420]\ttraining's binary_logloss: 0.0381257\ttraining's f1: 0.816401\tvalid_1's binary_logloss: 0.0537265\tvalid_1's f1: 0.753328\n",
      "[421]\ttraining's binary_logloss: 0.0380607\ttraining's f1: 0.816541\tvalid_1's binary_logloss: 0.0536833\tvalid_1's f1: 0.753462\n",
      "[422]\ttraining's binary_logloss: 0.0379511\ttraining's f1: 0.816995\tvalid_1's binary_logloss: 0.053599\tvalid_1's f1: 0.753748\n",
      "[423]\ttraining's binary_logloss: 0.0378326\ttraining's f1: 0.81736\tvalid_1's binary_logloss: 0.0534995\tvalid_1's f1: 0.754062\n",
      "[424]\ttraining's binary_logloss: 0.0377531\ttraining's f1: 0.817669\tvalid_1's binary_logloss: 0.0534409\tvalid_1's f1: 0.754144\n",
      "[425]\ttraining's binary_logloss: 0.0376875\ttraining's f1: 0.817866\tvalid_1's binary_logloss: 0.0533946\tvalid_1's f1: 0.754226\n",
      "[426]\ttraining's binary_logloss: 0.0376259\ttraining's f1: 0.818098\tvalid_1's binary_logloss: 0.0533467\tvalid_1's f1: 0.754525\n",
      "[427]\ttraining's binary_logloss: 0.037605\ttraining's f1: 0.818133\tvalid_1's binary_logloss: 0.0533371\tvalid_1's f1: 0.754529\n",
      "[428]\ttraining's binary_logloss: 0.0374614\ttraining's f1: 0.818847\tvalid_1's binary_logloss: 0.0532201\tvalid_1's f1: 0.754819\n",
      "[429]\ttraining's binary_logloss: 0.0373933\ttraining's f1: 0.819038\tvalid_1's binary_logloss: 0.0531639\tvalid_1's f1: 0.754972\n",
      "[430]\ttraining's binary_logloss: 0.0373396\ttraining's f1: 0.819194\tvalid_1's binary_logloss: 0.0531149\tvalid_1's f1: 0.754975\n",
      "[431]\ttraining's binary_logloss: 0.0372337\ttraining's f1: 0.819692\tvalid_1's binary_logloss: 0.0530229\tvalid_1's f1: 0.755206\n",
      "[432]\ttraining's binary_logloss: 0.0370848\ttraining's f1: 0.820426\tvalid_1's binary_logloss: 0.0528978\tvalid_1's f1: 0.755686\n",
      "[433]\ttraining's binary_logloss: 0.0369764\ttraining's f1: 0.820855\tvalid_1's binary_logloss: 0.0528091\tvalid_1's f1: 0.755694\n",
      "[434]\ttraining's binary_logloss: 0.0368697\ttraining's f1: 0.82135\tvalid_1's binary_logloss: 0.0527166\tvalid_1's f1: 0.756113\n",
      "[435]\ttraining's binary_logloss: 0.0367797\ttraining's f1: 0.821745\tvalid_1's binary_logloss: 0.052636\tvalid_1's f1: 0.756351\n",
      "[436]\ttraining's binary_logloss: 0.0367385\ttraining's f1: 0.821904\tvalid_1's binary_logloss: 0.052606\tvalid_1's f1: 0.756534\n",
      "[437]\ttraining's binary_logloss: 0.0366164\ttraining's f1: 0.822236\tvalid_1's binary_logloss: 0.0525167\tvalid_1's f1: 0.75653\n",
      "[438]\ttraining's binary_logloss: 0.0364447\ttraining's f1: 0.823097\tvalid_1's binary_logloss: 0.0523631\tvalid_1's f1: 0.756852\n",
      "[439]\ttraining's binary_logloss: 0.0363222\ttraining's f1: 0.823642\tvalid_1's binary_logloss: 0.0522588\tvalid_1's f1: 0.757495\n",
      "[440]\ttraining's binary_logloss: 0.0362515\ttraining's f1: 0.823933\tvalid_1's binary_logloss: 0.052201\tvalid_1's f1: 0.757789\n",
      "[441]\ttraining's binary_logloss: 0.0361287\ttraining's f1: 0.824291\tvalid_1's binary_logloss: 0.052091\tvalid_1's f1: 0.757966\n",
      "[442]\ttraining's binary_logloss: 0.0359947\ttraining's f1: 0.82503\tvalid_1's binary_logloss: 0.051969\tvalid_1's f1: 0.758428\n",
      "[443]\ttraining's binary_logloss: 0.0359372\ttraining's f1: 0.825243\tvalid_1's binary_logloss: 0.051924\tvalid_1's f1: 0.758563\n",
      "[444]\ttraining's binary_logloss: 0.0358055\ttraining's f1: 0.825942\tvalid_1's binary_logloss: 0.0518181\tvalid_1's f1: 0.759068\n",
      "[445]\ttraining's binary_logloss: 0.0357814\ttraining's f1: 0.826038\tvalid_1's binary_logloss: 0.0518015\tvalid_1's f1: 0.759153\n",
      "[446]\ttraining's binary_logloss: 0.0356774\ttraining's f1: 0.826689\tvalid_1's binary_logloss: 0.0517168\tvalid_1's f1: 0.759577\n",
      "[447]\ttraining's binary_logloss: 0.0355668\ttraining's f1: 0.827371\tvalid_1's binary_logloss: 0.05163\tvalid_1's f1: 0.760027\n",
      "[448]\ttraining's binary_logloss: 0.0355081\ttraining's f1: 0.82761\tvalid_1's binary_logloss: 0.0515866\tvalid_1's f1: 0.760221\n",
      "[449]\ttraining's binary_logloss: 0.0354529\ttraining's f1: 0.827893\tvalid_1's binary_logloss: 0.051556\tvalid_1's f1: 0.760207\n",
      "[450]\ttraining's binary_logloss: 0.0353677\ttraining's f1: 0.828109\tvalid_1's binary_logloss: 0.0514799\tvalid_1's f1: 0.760299\n",
      "[451]\ttraining's binary_logloss: 0.0351814\ttraining's f1: 0.828842\tvalid_1's binary_logloss: 0.0513205\tvalid_1's f1: 0.760802\n",
      "[452]\ttraining's binary_logloss: 0.0351527\ttraining's f1: 0.828887\tvalid_1's binary_logloss: 0.051296\tvalid_1's f1: 0.76079\n",
      "[453]\ttraining's binary_logloss: 0.0350965\ttraining's f1: 0.829202\tvalid_1's binary_logloss: 0.0512607\tvalid_1's f1: 0.760939\n",
      "[454]\ttraining's binary_logloss: 0.0350143\ttraining's f1: 0.829548\tvalid_1's binary_logloss: 0.0512086\tvalid_1's f1: 0.761148\n",
      "[455]\ttraining's binary_logloss: 0.0349358\ttraining's f1: 0.829865\tvalid_1's binary_logloss: 0.0511431\tvalid_1's f1: 0.761356\n",
      "[456]\ttraining's binary_logloss: 0.0348333\ttraining's f1: 0.830378\tvalid_1's binary_logloss: 0.0510499\tvalid_1's f1: 0.761558\n",
      "[457]\ttraining's binary_logloss: 0.0347108\ttraining's f1: 0.831083\tvalid_1's binary_logloss: 0.0509482\tvalid_1's f1: 0.761899\n",
      "[458]\ttraining's binary_logloss: 0.0346132\ttraining's f1: 0.831547\tvalid_1's binary_logloss: 0.0508619\tvalid_1's f1: 0.762294\n",
      "[459]\ttraining's binary_logloss: 0.0345542\ttraining's f1: 0.831745\tvalid_1's binary_logloss: 0.0508152\tvalid_1's f1: 0.762417\n",
      "[460]\ttraining's binary_logloss: 0.0344727\ttraining's f1: 0.832027\tvalid_1's binary_logloss: 0.0507489\tvalid_1's f1: 0.762597\n",
      "[461]\ttraining's binary_logloss: 0.0344418\ttraining's f1: 0.832088\tvalid_1's binary_logloss: 0.0507335\tvalid_1's f1: 0.762697\n",
      "[462]\ttraining's binary_logloss: 0.0343854\ttraining's f1: 0.832378\tvalid_1's binary_logloss: 0.0506943\tvalid_1's f1: 0.76289\n",
      "[463]\ttraining's binary_logloss: 0.0343221\ttraining's f1: 0.832585\tvalid_1's binary_logloss: 0.0506541\tvalid_1's f1: 0.763019\n",
      "[464]\ttraining's binary_logloss: 0.0342666\ttraining's f1: 0.83273\tvalid_1's binary_logloss: 0.05063\tvalid_1's f1: 0.76303\n",
      "[465]\ttraining's binary_logloss: 0.0342157\ttraining's f1: 0.832845\tvalid_1's binary_logloss: 0.0505941\tvalid_1's f1: 0.763247\n",
      "[466]\ttraining's binary_logloss: 0.0341966\ttraining's f1: 0.832891\tvalid_1's binary_logloss: 0.0505842\tvalid_1's f1: 0.763277\n",
      "[467]\ttraining's binary_logloss: 0.0341529\ttraining's f1: 0.833045\tvalid_1's binary_logloss: 0.0505486\tvalid_1's f1: 0.763371\n",
      "[468]\ttraining's binary_logloss: 0.0340403\ttraining's f1: 0.833706\tvalid_1's binary_logloss: 0.0504621\tvalid_1's f1: 0.763677\n",
      "[469]\ttraining's binary_logloss: 0.033969\ttraining's f1: 0.833999\tvalid_1's binary_logloss: 0.0504224\tvalid_1's f1: 0.763606\n",
      "[470]\ttraining's binary_logloss: 0.0338361\ttraining's f1: 0.834657\tvalid_1's binary_logloss: 0.0503067\tvalid_1's f1: 0.763914\n",
      "[471]\ttraining's binary_logloss: 0.0337594\ttraining's f1: 0.834827\tvalid_1's binary_logloss: 0.0502469\tvalid_1's f1: 0.76428\n",
      "[472]\ttraining's binary_logloss: 0.0336953\ttraining's f1: 0.834998\tvalid_1's binary_logloss: 0.0502051\tvalid_1's f1: 0.764163\n",
      "[473]\ttraining's binary_logloss: 0.0336395\ttraining's f1: 0.835238\tvalid_1's binary_logloss: 0.0501712\tvalid_1's f1: 0.764353\n",
      "[474]\ttraining's binary_logloss: 0.0335562\ttraining's f1: 0.835635\tvalid_1's binary_logloss: 0.0501166\tvalid_1's f1: 0.764555\n",
      "[475]\ttraining's binary_logloss: 0.0335244\ttraining's f1: 0.835721\tvalid_1's binary_logloss: 0.0500919\tvalid_1's f1: 0.76468\n",
      "[476]\ttraining's binary_logloss: 0.0334498\ttraining's f1: 0.835978\tvalid_1's binary_logloss: 0.0500262\tvalid_1's f1: 0.765055\n",
      "[477]\ttraining's binary_logloss: 0.0333685\ttraining's f1: 0.836361\tvalid_1's binary_logloss: 0.0499699\tvalid_1's f1: 0.765234\n",
      "[478]\ttraining's binary_logloss: 0.0333186\ttraining's f1: 0.836596\tvalid_1's binary_logloss: 0.049936\tvalid_1's f1: 0.765258\n",
      "[479]\ttraining's binary_logloss: 0.0332755\ttraining's f1: 0.836815\tvalid_1's binary_logloss: 0.0499016\tvalid_1's f1: 0.765271\n",
      "[480]\ttraining's binary_logloss: 0.0332186\ttraining's f1: 0.83698\tvalid_1's binary_logloss: 0.0498544\tvalid_1's f1: 0.765343\n",
      "[481]\ttraining's binary_logloss: 0.0331674\ttraining's f1: 0.83716\tvalid_1's binary_logloss: 0.049831\tvalid_1's f1: 0.765356\n",
      "[482]\ttraining's binary_logloss: 0.0331103\ttraining's f1: 0.837255\tvalid_1's binary_logloss: 0.0497988\tvalid_1's f1: 0.76534\n",
      "[483]\ttraining's binary_logloss: 0.0330609\ttraining's f1: 0.837428\tvalid_1's binary_logloss: 0.049757\tvalid_1's f1: 0.765501\n",
      "[484]\ttraining's binary_logloss: 0.0329087\ttraining's f1: 0.838176\tvalid_1's binary_logloss: 0.0496245\tvalid_1's f1: 0.765737\n",
      "[485]\ttraining's binary_logloss: 0.0327733\ttraining's f1: 0.838746\tvalid_1's binary_logloss: 0.0495183\tvalid_1's f1: 0.766228\n",
      "[486]\ttraining's binary_logloss: 0.0326094\ttraining's f1: 0.839883\tvalid_1's binary_logloss: 0.0493875\tvalid_1's f1: 0.766687\n",
      "[487]\ttraining's binary_logloss: 0.0325598\ttraining's f1: 0.840066\tvalid_1's binary_logloss: 0.0493543\tvalid_1's f1: 0.766862\n",
      "[488]\ttraining's binary_logloss: 0.0325298\ttraining's f1: 0.840114\tvalid_1's binary_logloss: 0.049331\tvalid_1's f1: 0.766771\n",
      "[489]\ttraining's binary_logloss: 0.0324917\ttraining's f1: 0.840218\tvalid_1's binary_logloss: 0.0493042\tvalid_1's f1: 0.766898\n",
      "[490]\ttraining's binary_logloss: 0.0324053\ttraining's f1: 0.840658\tvalid_1's binary_logloss: 0.049232\tvalid_1's f1: 0.766901\n",
      "[491]\ttraining's binary_logloss: 0.0323366\ttraining's f1: 0.841026\tvalid_1's binary_logloss: 0.0491755\tvalid_1's f1: 0.767017\n",
      "[492]\ttraining's binary_logloss: 0.0322223\ttraining's f1: 0.841621\tvalid_1's binary_logloss: 0.0490758\tvalid_1's f1: 0.76734\n",
      "[493]\ttraining's binary_logloss: 0.0321026\ttraining's f1: 0.842113\tvalid_1's binary_logloss: 0.0489714\tvalid_1's f1: 0.76761\n",
      "[494]\ttraining's binary_logloss: 0.0320768\ttraining's f1: 0.84221\tvalid_1's binary_logloss: 0.048957\tvalid_1's f1: 0.767606\n",
      "[495]\ttraining's binary_logloss: 0.0320523\ttraining's f1: 0.842315\tvalid_1's binary_logloss: 0.0489393\tvalid_1's f1: 0.767799\n",
      "[496]\ttraining's binary_logloss: 0.0320119\ttraining's f1: 0.842565\tvalid_1's binary_logloss: 0.0489171\tvalid_1's f1: 0.768089\n",
      "[497]\ttraining's binary_logloss: 0.0319389\ttraining's f1: 0.842906\tvalid_1's binary_logloss: 0.0488533\tvalid_1's f1: 0.768268\n",
      "[498]\ttraining's binary_logloss: 0.0318531\ttraining's f1: 0.843287\tvalid_1's binary_logloss: 0.0487737\tvalid_1's f1: 0.768551\n",
      "[499]\ttraining's binary_logloss: 0.0318102\ttraining's f1: 0.843368\tvalid_1's binary_logloss: 0.0487465\tvalid_1's f1: 0.768643\n",
      "[500]\ttraining's binary_logloss: 0.0317823\ttraining's f1: 0.843441\tvalid_1's binary_logloss: 0.0487297\tvalid_1's f1: 0.768651\n",
      "[501]\ttraining's binary_logloss: 0.0316767\ttraining's f1: 0.844077\tvalid_1's binary_logloss: 0.0486329\tvalid_1's f1: 0.769045\n",
      "[502]\ttraining's binary_logloss: 0.0315836\ttraining's f1: 0.844649\tvalid_1's binary_logloss: 0.0485577\tvalid_1's f1: 0.769267\n",
      "[503]\ttraining's binary_logloss: 0.0315344\ttraining's f1: 0.844763\tvalid_1's binary_logloss: 0.0485265\tvalid_1's f1: 0.769333\n",
      "[504]\ttraining's binary_logloss: 0.0314753\ttraining's f1: 0.845009\tvalid_1's binary_logloss: 0.0484832\tvalid_1's f1: 0.769555\n",
      "[505]\ttraining's binary_logloss: 0.0313746\ttraining's f1: 0.845526\tvalid_1's binary_logloss: 0.0483976\tvalid_1's f1: 0.769904\n",
      "[506]\ttraining's binary_logloss: 0.0313523\ttraining's f1: 0.845559\tvalid_1's binary_logloss: 0.0483818\tvalid_1's f1: 0.769989\n",
      "[507]\ttraining's binary_logloss: 0.0312454\ttraining's f1: 0.846012\tvalid_1's binary_logloss: 0.048302\tvalid_1's f1: 0.770286\n",
      "[508]\ttraining's binary_logloss: 0.031168\ttraining's f1: 0.8464\tvalid_1's binary_logloss: 0.0482413\tvalid_1's f1: 0.770422\n",
      "[509]\ttraining's binary_logloss: 0.031139\ttraining's f1: 0.846532\tvalid_1's binary_logloss: 0.0482185\tvalid_1's f1: 0.770616\n",
      "[510]\ttraining's binary_logloss: 0.0310941\ttraining's f1: 0.84669\tvalid_1's binary_logloss: 0.0481823\tvalid_1's f1: 0.77067\n",
      "[511]\ttraining's binary_logloss: 0.0309984\ttraining's f1: 0.847038\tvalid_1's binary_logloss: 0.048106\tvalid_1's f1: 0.770776\n",
      "[512]\ttraining's binary_logloss: 0.0309556\ttraining's f1: 0.847203\tvalid_1's binary_logloss: 0.0480789\tvalid_1's f1: 0.771022\n",
      "[513]\ttraining's binary_logloss: 0.0309334\ttraining's f1: 0.847237\tvalid_1's binary_logloss: 0.0480654\tvalid_1's f1: 0.771052\n",
      "[514]\ttraining's binary_logloss: 0.030859\ttraining's f1: 0.847552\tvalid_1's binary_logloss: 0.047999\tvalid_1's f1: 0.771381\n",
      "[515]\ttraining's binary_logloss: 0.030773\ttraining's f1: 0.848068\tvalid_1's binary_logloss: 0.0479258\tvalid_1's f1: 0.771596\n",
      "[516]\ttraining's binary_logloss: 0.0307334\ttraining's f1: 0.848194\tvalid_1's binary_logloss: 0.0478946\tvalid_1's f1: 0.771728\n",
      "[517]\ttraining's binary_logloss: 0.0306604\ttraining's f1: 0.848536\tvalid_1's binary_logloss: 0.0478345\tvalid_1's f1: 0.771973\n",
      "[518]\ttraining's binary_logloss: 0.0306062\ttraining's f1: 0.848862\tvalid_1's binary_logloss: 0.0477898\tvalid_1's f1: 0.772035\n",
      "[519]\ttraining's binary_logloss: 0.0305162\ttraining's f1: 0.849206\tvalid_1's binary_logloss: 0.0477219\tvalid_1's f1: 0.772052\n",
      "[520]\ttraining's binary_logloss: 0.0304641\ttraining's f1: 0.84934\tvalid_1's binary_logloss: 0.0476823\tvalid_1's f1: 0.772136\n",
      "[521]\ttraining's binary_logloss: 0.0303779\ttraining's f1: 0.849996\tvalid_1's binary_logloss: 0.0476119\tvalid_1's f1: 0.772683\n",
      "[522]\ttraining's binary_logloss: 0.030338\ttraining's f1: 0.850224\tvalid_1's binary_logloss: 0.0475787\tvalid_1's f1: 0.77293\n",
      "[523]\ttraining's binary_logloss: 0.0302531\ttraining's f1: 0.850764\tvalid_1's binary_logloss: 0.0475094\tvalid_1's f1: 0.773165\n",
      "[524]\ttraining's binary_logloss: 0.0302055\ttraining's f1: 0.850883\tvalid_1's binary_logloss: 0.0474743\tvalid_1's f1: 0.773279\n",
      "[525]\ttraining's binary_logloss: 0.0300901\ttraining's f1: 0.851468\tvalid_1's binary_logloss: 0.047371\tvalid_1's f1: 0.773555\n",
      "[526]\ttraining's binary_logloss: 0.0300476\ttraining's f1: 0.851561\tvalid_1's binary_logloss: 0.0473381\tvalid_1's f1: 0.773632\n",
      "[527]\ttraining's binary_logloss: 0.0300283\ttraining's f1: 0.851569\tvalid_1's binary_logloss: 0.0473226\tvalid_1's f1: 0.773602\n",
      "[528]\ttraining's binary_logloss: 0.0299337\ttraining's f1: 0.851986\tvalid_1's binary_logloss: 0.047248\tvalid_1's f1: 0.773707\n",
      "[529]\ttraining's binary_logloss: 0.0298965\ttraining's f1: 0.852105\tvalid_1's binary_logloss: 0.0472259\tvalid_1's f1: 0.773764\n",
      "[530]\ttraining's binary_logloss: 0.0298613\ttraining's f1: 0.852208\tvalid_1's binary_logloss: 0.0472051\tvalid_1's f1: 0.77385\n",
      "[531]\ttraining's binary_logloss: 0.0297802\ttraining's f1: 0.852506\tvalid_1's binary_logloss: 0.0471415\tvalid_1's f1: 0.774242\n",
      "[532]\ttraining's binary_logloss: 0.029755\ttraining's f1: 0.852609\tvalid_1's binary_logloss: 0.0471294\tvalid_1's f1: 0.774164\n",
      "[533]\ttraining's binary_logloss: 0.0297359\ttraining's f1: 0.852634\tvalid_1's binary_logloss: 0.0471193\tvalid_1's f1: 0.774222\n",
      "[534]\ttraining's binary_logloss: 0.0296764\ttraining's f1: 0.852976\tvalid_1's binary_logloss: 0.0470768\tvalid_1's f1: 0.774327\n",
      "[535]\ttraining's binary_logloss: 0.0296486\ttraining's f1: 0.853045\tvalid_1's binary_logloss: 0.0470577\tvalid_1's f1: 0.774472\n",
      "[536]\ttraining's binary_logloss: 0.0296272\ttraining's f1: 0.853148\tvalid_1's binary_logloss: 0.0470476\tvalid_1's f1: 0.774529\n",
      "[537]\ttraining's binary_logloss: 0.02954\ttraining's f1: 0.853577\tvalid_1's binary_logloss: 0.0469809\tvalid_1's f1: 0.774789\n",
      "[538]\ttraining's binary_logloss: 0.0295248\ttraining's f1: 0.853645\tvalid_1's binary_logloss: 0.0469724\tvalid_1's f1: 0.77477\n",
      "[539]\ttraining's binary_logloss: 0.0294968\ttraining's f1: 0.853748\tvalid_1's binary_logloss: 0.0469569\tvalid_1's f1: 0.774847\n",
      "[540]\ttraining's binary_logloss: 0.0294269\ttraining's f1: 0.854032\tvalid_1's binary_logloss: 0.0469032\tvalid_1's f1: 0.775059\n",
      "[541]\ttraining's binary_logloss: 0.0293688\ttraining's f1: 0.854394\tvalid_1's binary_logloss: 0.0468566\tvalid_1's f1: 0.775203\n",
      "[542]\ttraining's binary_logloss: 0.0292601\ttraining's f1: 0.854921\tvalid_1's binary_logloss: 0.0467678\tvalid_1's f1: 0.775513\n",
      "[543]\ttraining's binary_logloss: 0.0292204\ttraining's f1: 0.855051\tvalid_1's binary_logloss: 0.0467457\tvalid_1's f1: 0.775464\n",
      "[544]\ttraining's binary_logloss: 0.0291673\ttraining's f1: 0.855258\tvalid_1's binary_logloss: 0.0467024\tvalid_1's f1: 0.775561\n",
      "[545]\ttraining's binary_logloss: 0.0291044\ttraining's f1: 0.855588\tvalid_1's binary_logloss: 0.0466502\tvalid_1's f1: 0.77558\n",
      "[546]\ttraining's binary_logloss: 0.0290719\ttraining's f1: 0.855796\tvalid_1's binary_logloss: 0.0466337\tvalid_1's f1: 0.775609\n",
      "[547]\ttraining's binary_logloss: 0.0290138\ttraining's f1: 0.85604\tvalid_1's binary_logloss: 0.0465848\tvalid_1's f1: 0.775901\n",
      "[548]\ttraining's binary_logloss: 0.0289208\ttraining's f1: 0.856562\tvalid_1's binary_logloss: 0.0465087\tvalid_1's f1: 0.776525\n",
      "[549]\ttraining's binary_logloss: 0.0288733\ttraining's f1: 0.856772\tvalid_1's binary_logloss: 0.0464691\tvalid_1's f1: 0.776564\n",
      "[550]\ttraining's binary_logloss: 0.0288401\ttraining's f1: 0.856877\tvalid_1's binary_logloss: 0.046448\tvalid_1's f1: 0.776691\n",
      "[551]\ttraining's binary_logloss: 0.0288096\ttraining's f1: 0.857025\tvalid_1's binary_logloss: 0.0464304\tvalid_1's f1: 0.776857\n",
      "[552]\ttraining's binary_logloss: 0.0287341\ttraining's f1: 0.857411\tvalid_1's binary_logloss: 0.0463676\tvalid_1's f1: 0.776975\n",
      "[553]\ttraining's binary_logloss: 0.0286998\ttraining's f1: 0.857595\tvalid_1's binary_logloss: 0.0463423\tvalid_1's f1: 0.777053\n",
      "[554]\ttraining's binary_logloss: 0.0286257\ttraining's f1: 0.857902\tvalid_1's binary_logloss: 0.0462836\tvalid_1's f1: 0.77724\n",
      "[555]\ttraining's binary_logloss: 0.02857\ttraining's f1: 0.858025\tvalid_1's binary_logloss: 0.0462392\tvalid_1's f1: 0.77724\n",
      "[556]\ttraining's binary_logloss: 0.0285016\ttraining's f1: 0.858562\tvalid_1's binary_logloss: 0.0461873\tvalid_1's f1: 0.777565\n",
      "[557]\ttraining's binary_logloss: 0.0284326\ttraining's f1: 0.858959\tvalid_1's binary_logloss: 0.0461303\tvalid_1's f1: 0.777742\n",
      "[558]\ttraining's binary_logloss: 0.0283391\ttraining's f1: 0.859401\tvalid_1's binary_logloss: 0.0460609\tvalid_1's f1: 0.778068\n",
      "[559]\ttraining's binary_logloss: 0.0282915\ttraining's f1: 0.859561\tvalid_1's binary_logloss: 0.0460278\tvalid_1's f1: 0.778009\n",
      "[560]\ttraining's binary_logloss: 0.0282522\ttraining's f1: 0.859658\tvalid_1's binary_logloss: 0.0459965\tvalid_1's f1: 0.778227\n",
      "[561]\ttraining's binary_logloss: 0.0281746\ttraining's f1: 0.860102\tvalid_1's binary_logloss: 0.0459283\tvalid_1's f1: 0.778406\n",
      "[562]\ttraining's binary_logloss: 0.0280971\ttraining's f1: 0.860476\tvalid_1's binary_logloss: 0.0458711\tvalid_1's f1: 0.778605\n",
      "[563]\ttraining's binary_logloss: 0.0280053\ttraining's f1: 0.860931\tvalid_1's binary_logloss: 0.0457947\tvalid_1's f1: 0.778983\n",
      "[564]\ttraining's binary_logloss: 0.0279554\ttraining's f1: 0.861091\tvalid_1's binary_logloss: 0.0457616\tvalid_1's f1: 0.779122\n",
      "[565]\ttraining's binary_logloss: 0.0279406\ttraining's f1: 0.861136\tvalid_1's binary_logloss: 0.0457543\tvalid_1's f1: 0.779142\n",
      "[566]\ttraining's binary_logloss: 0.0278935\ttraining's f1: 0.861252\tvalid_1's binary_logloss: 0.0457185\tvalid_1's f1: 0.779103\n",
      "[567]\ttraining's binary_logloss: 0.0278369\ttraining's f1: 0.861673\tvalid_1's binary_logloss: 0.0456757\tvalid_1's f1: 0.779303\n",
      "[568]\ttraining's binary_logloss: 0.027784\ttraining's f1: 0.862014\tvalid_1's binary_logloss: 0.0456376\tvalid_1's f1: 0.779462\n",
      "[569]\ttraining's binary_logloss: 0.0277084\ttraining's f1: 0.862274\tvalid_1's binary_logloss: 0.0455854\tvalid_1's f1: 0.779702\n",
      "[570]\ttraining's binary_logloss: 0.0276814\ttraining's f1: 0.862418\tvalid_1's binary_logloss: 0.0455723\tvalid_1's f1: 0.779733\n",
      "[571]\ttraining's binary_logloss: 0.0276087\ttraining's f1: 0.862796\tvalid_1's binary_logloss: 0.0455129\tvalid_1's f1: 0.780125\n",
      "[572]\ttraining's binary_logloss: 0.0275667\ttraining's f1: 0.863058\tvalid_1's binary_logloss: 0.0454866\tvalid_1's f1: 0.780296\n",
      "[573]\ttraining's binary_logloss: 0.0275109\ttraining's f1: 0.863248\tvalid_1's binary_logloss: 0.0454373\tvalid_1's f1: 0.780349\n",
      "[574]\ttraining's binary_logloss: 0.0274762\ttraining's f1: 0.863365\tvalid_1's binary_logloss: 0.0454219\tvalid_1's f1: 0.78055\n",
      "[575]\ttraining's binary_logloss: 0.0274427\ttraining's f1: 0.863546\tvalid_1's binary_logloss: 0.0453933\tvalid_1's f1: 0.78064\n",
      "[576]\ttraining's binary_logloss: 0.0273955\ttraining's f1: 0.863754\tvalid_1's binary_logloss: 0.0453577\tvalid_1's f1: 0.780763\n",
      "[577]\ttraining's binary_logloss: 0.0272931\ttraining's f1: 0.864298\tvalid_1's binary_logloss: 0.0452802\tvalid_1's f1: 0.781136\n",
      "[578]\ttraining's binary_logloss: 0.0272518\ttraining's f1: 0.864462\tvalid_1's binary_logloss: 0.0452461\tvalid_1's f1: 0.781196\n",
      "[579]\ttraining's binary_logloss: 0.0272205\ttraining's f1: 0.864626\tvalid_1's binary_logloss: 0.0452247\tvalid_1's f1: 0.78123\n",
      "[580]\ttraining's binary_logloss: 0.0271312\ttraining's f1: 0.865099\tvalid_1's binary_logloss: 0.0451517\tvalid_1's f1: 0.781635\n",
      "[581]\ttraining's binary_logloss: 0.0270866\ttraining's f1: 0.865227\tvalid_1's binary_logloss: 0.0451174\tvalid_1's f1: 0.781717\n",
      "[582]\ttraining's binary_logloss: 0.0269949\ttraining's f1: 0.865675\tvalid_1's binary_logloss: 0.0450462\tvalid_1's f1: 0.782076\n",
      "[583]\ttraining's binary_logloss: 0.0269321\ttraining's f1: 0.865977\tvalid_1's binary_logloss: 0.044997\tvalid_1's f1: 0.78221\n",
      "[584]\ttraining's binary_logloss: 0.0268199\ttraining's f1: 0.866638\tvalid_1's binary_logloss: 0.0449021\tvalid_1's f1: 0.782662\n",
      "[585]\ttraining's binary_logloss: 0.0267598\ttraining's f1: 0.866859\tvalid_1's binary_logloss: 0.0448531\tvalid_1's f1: 0.782735\n",
      "[586]\ttraining's binary_logloss: 0.0267253\ttraining's f1: 0.866942\tvalid_1's binary_logloss: 0.0448302\tvalid_1's f1: 0.782717\n",
      "[587]\ttraining's binary_logloss: 0.0266868\ttraining's f1: 0.867117\tvalid_1's binary_logloss: 0.0448018\tvalid_1's f1: 0.78277\n",
      "[588]\ttraining's binary_logloss: 0.0266234\ttraining's f1: 0.867375\tvalid_1's binary_logloss: 0.0447655\tvalid_1's f1: 0.782893\n",
      "[589]\ttraining's binary_logloss: 0.0266038\ttraining's f1: 0.86743\tvalid_1's binary_logloss: 0.0447583\tvalid_1's f1: 0.782934\n",
      "[590]\ttraining's binary_logloss: 0.0265452\ttraining's f1: 0.8678\tvalid_1's binary_logloss: 0.0447179\tvalid_1's f1: 0.783089\n",
      "[591]\ttraining's binary_logloss: 0.0264469\ttraining's f1: 0.868384\tvalid_1's binary_logloss: 0.0446469\tvalid_1's f1: 0.783369\n",
      "[592]\ttraining's binary_logloss: 0.0264084\ttraining's f1: 0.868541\tvalid_1's binary_logloss: 0.0446222\tvalid_1's f1: 0.783504\n",
      "[593]\ttraining's binary_logloss: 0.0263482\ttraining's f1: 0.868839\tvalid_1's binary_logloss: 0.0445777\tvalid_1's f1: 0.783495\n",
      "[594]\ttraining's binary_logloss: 0.0263089\ttraining's f1: 0.869016\tvalid_1's binary_logloss: 0.0445525\tvalid_1's f1: 0.783536\n",
      "[595]\ttraining's binary_logloss: 0.0262739\ttraining's f1: 0.869137\tvalid_1's binary_logloss: 0.0445238\tvalid_1's f1: 0.78359\n",
      "[596]\ttraining's binary_logloss: 0.0262426\ttraining's f1: 0.869183\tvalid_1's binary_logloss: 0.0445015\tvalid_1's f1: 0.783784\n",
      "[597]\ttraining's binary_logloss: 0.0262134\ttraining's f1: 0.869295\tvalid_1's binary_logloss: 0.0444788\tvalid_1's f1: 0.783775\n",
      "[598]\ttraining's binary_logloss: 0.0261847\ttraining's f1: 0.86936\tvalid_1's binary_logloss: 0.0444632\tvalid_1's f1: 0.783796\n",
      "[599]\ttraining's binary_logloss: 0.0261637\ttraining's f1: 0.869379\tvalid_1's binary_logloss: 0.0444532\tvalid_1's f1: 0.783817\n",
      "[600]\ttraining's binary_logloss: 0.0261344\ttraining's f1: 0.869472\tvalid_1's binary_logloss: 0.0444317\tvalid_1's f1: 0.783858\n",
      "[601]\ttraining's binary_logloss: 0.0261069\ttraining's f1: 0.8695\tvalid_1's binary_logloss: 0.0444163\tvalid_1's f1: 0.783911\n",
      "[602]\ttraining's binary_logloss: 0.0260788\ttraining's f1: 0.868882\tvalid_1's binary_logloss: 0.0443968\tvalid_1's f1: 0.783354\n",
      "[603]\ttraining's binary_logloss: 0.0260572\ttraining's f1: 0.868947\tvalid_1's binary_logloss: 0.0443836\tvalid_1's f1: 0.783395\n",
      "[604]\ttraining's binary_logloss: 0.0260027\ttraining's f1: 0.869855\tvalid_1's binary_logloss: 0.0443402\tvalid_1's f1: 0.784068\n",
      "[605]\ttraining's binary_logloss: 0.0259834\ttraining's f1: 0.869864\tvalid_1's binary_logloss: 0.0443304\tvalid_1's f1: 0.78411\n",
      "[606]\ttraining's binary_logloss: 0.0259385\ttraining's f1: 0.870042\tvalid_1's binary_logloss: 0.0442972\tvalid_1's f1: 0.784154\n",
      "[607]\ttraining's binary_logloss: 0.0259163\ttraining's f1: 0.870117\tvalid_1's binary_logloss: 0.0442869\tvalid_1's f1: 0.784267\n",
      "[608]\ttraining's binary_logloss: 0.0258429\ttraining's f1: 0.870482\tvalid_1's binary_logloss: 0.0442215\tvalid_1's f1: 0.784507\n",
      "[609]\ttraining's binary_logloss: 0.0258239\ttraining's f1: 0.870548\tvalid_1's binary_logloss: 0.0442136\tvalid_1's f1: 0.784715\n",
      "[610]\ttraining's binary_logloss: 0.0258052\ttraining's f1: 0.870614\tvalid_1's binary_logloss: 0.0442031\tvalid_1's f1: 0.784695\n",
      "[611]\ttraining's binary_logloss: 0.0257887\ttraining's f1: 0.870698\tvalid_1's binary_logloss: 0.0441976\tvalid_1's f1: 0.784786\n",
      "[612]\ttraining's binary_logloss: 0.0257376\ttraining's f1: 0.870989\tvalid_1's binary_logloss: 0.0441566\tvalid_1's f1: 0.784924\n",
      "[613]\ttraining's binary_logloss: 0.0256605\ttraining's f1: 0.871309\tvalid_1's binary_logloss: 0.0441026\tvalid_1's f1: 0.785052\n",
      "[614]\ttraining's binary_logloss: 0.0256219\ttraining's f1: 0.871422\tvalid_1's binary_logloss: 0.0440805\tvalid_1's f1: 0.785148\n",
      "[615]\ttraining's binary_logloss: 0.025592\ttraining's f1: 0.871517\tvalid_1's binary_logloss: 0.0440587\tvalid_1's f1: 0.785294\n",
      "[616]\ttraining's binary_logloss: 0.0255206\ttraining's f1: 0.871753\tvalid_1's binary_logloss: 0.0440052\tvalid_1's f1: 0.785495\n",
      "[617]\ttraining's binary_logloss: 0.0254846\ttraining's f1: 0.87196\tvalid_1's binary_logloss: 0.0439809\tvalid_1's f1: 0.785629\n",
      "[618]\ttraining's binary_logloss: 0.0254395\ttraining's f1: 0.872253\tvalid_1's binary_logloss: 0.0439539\tvalid_1's f1: 0.785755\n",
      "[619]\ttraining's binary_logloss: 0.0253824\ttraining's f1: 0.872509\tvalid_1's binary_logloss: 0.0439084\tvalid_1's f1: 0.786125\n",
      "[620]\ttraining's binary_logloss: 0.0253198\ttraining's f1: 0.872765\tvalid_1's binary_logloss: 0.0438551\tvalid_1's f1: 0.786318\n",
      "[621]\ttraining's binary_logloss: 0.025298\ttraining's f1: 0.872822\tvalid_1's binary_logloss: 0.0438386\tvalid_1's f1: 0.786571\n",
      "[622]\ttraining's binary_logloss: 0.0252677\ttraining's f1: 0.87305\tvalid_1's binary_logloss: 0.0438226\tvalid_1's f1: 0.786651\n",
      "[623]\ttraining's binary_logloss: 0.0252237\ttraining's f1: 0.873259\tvalid_1's binary_logloss: 0.0437922\tvalid_1's f1: 0.786689\n",
      "[624]\ttraining's binary_logloss: 0.0251679\ttraining's f1: 0.873535\tvalid_1's binary_logloss: 0.0437522\tvalid_1's f1: 0.786863\n",
      "[625]\ttraining's binary_logloss: 0.0251383\ttraining's f1: 0.873592\tvalid_1's binary_logloss: 0.0437241\tvalid_1's f1: 0.787062\n",
      "[626]\ttraining's binary_logloss: 0.0250885\ttraining's f1: 0.873869\tvalid_1's binary_logloss: 0.0436815\tvalid_1's f1: 0.787261\n",
      "[627]\ttraining's binary_logloss: 0.0250675\ttraining's f1: 0.873926\tvalid_1's binary_logloss: 0.0436679\tvalid_1's f1: 0.787252\n",
      "[628]\ttraining's binary_logloss: 0.0250565\ttraining's f1: 0.873974\tvalid_1's binary_logloss: 0.0436614\tvalid_1's f1: 0.787282\n",
      "[629]\ttraining's binary_logloss: 0.0249546\ttraining's f1: 0.874413\tvalid_1's binary_logloss: 0.0435808\tvalid_1's f1: 0.78766\n",
      "[630]\ttraining's binary_logloss: 0.0248929\ttraining's f1: 0.874749\tvalid_1's binary_logloss: 0.043529\tvalid_1's f1: 0.787572\n",
      "[631]\ttraining's binary_logloss: 0.0248545\ttraining's f1: 0.874864\tvalid_1's binary_logloss: 0.0435004\tvalid_1's f1: 0.787772\n",
      "[632]\ttraining's binary_logloss: 0.0247683\ttraining's f1: 0.875296\tvalid_1's binary_logloss: 0.0434311\tvalid_1's f1: 0.78808\n",
      "[633]\ttraining's binary_logloss: 0.024738\ttraining's f1: 0.875411\tvalid_1's binary_logloss: 0.043414\tvalid_1's f1: 0.788043\n",
      "[634]\ttraining's binary_logloss: 0.0246664\ttraining's f1: 0.875825\tvalid_1's binary_logloss: 0.0433554\tvalid_1's f1: 0.788382\n",
      "[635]\ttraining's binary_logloss: 0.0246339\ttraining's f1: 0.875902\tvalid_1's binary_logloss: 0.0433315\tvalid_1's f1: 0.788446\n",
      "[636]\ttraining's binary_logloss: 0.0246151\ttraining's f1: 0.876037\tvalid_1's binary_logloss: 0.04332\tvalid_1's f1: 0.788511\n",
      "[637]\ttraining's binary_logloss: 0.024556\ttraining's f1: 0.876442\tvalid_1's binary_logloss: 0.043273\tvalid_1's f1: 0.788803\n",
      "[638]\ttraining's binary_logloss: 0.0245045\ttraining's f1: 0.876723\tvalid_1's binary_logloss: 0.0432351\tvalid_1's f1: 0.788975\n",
      "[639]\ttraining's binary_logloss: 0.0244555\ttraining's f1: 0.876994\tvalid_1's binary_logloss: 0.043203\tvalid_1's f1: 0.78919\n",
      "[640]\ttraining's binary_logloss: 0.0244291\ttraining's f1: 0.877111\tvalid_1's binary_logloss: 0.0431888\tvalid_1's f1: 0.789255\n",
      "[641]\ttraining's binary_logloss: 0.0243673\ttraining's f1: 0.877499\tvalid_1's binary_logloss: 0.0431445\tvalid_1's f1: 0.789339\n",
      "[642]\ttraining's binary_logloss: 0.0243201\ttraining's f1: 0.877684\tvalid_1's binary_logloss: 0.0431041\tvalid_1's f1: 0.78946\n",
      "[643]\ttraining's binary_logloss: 0.0242797\ttraining's f1: 0.877839\tvalid_1's binary_logloss: 0.043078\tvalid_1's f1: 0.789641\n",
      "[644]\ttraining's binary_logloss: 0.0242338\ttraining's f1: 0.878122\tvalid_1's binary_logloss: 0.0430454\tvalid_1's f1: 0.789792\n",
      "[645]\ttraining's binary_logloss: 0.0241871\ttraining's f1: 0.878307\tvalid_1's binary_logloss: 0.0430015\tvalid_1's f1: 0.79003\n",
      "[646]\ttraining's binary_logloss: 0.0241481\ttraining's f1: 0.878434\tvalid_1's binary_logloss: 0.0429781\tvalid_1's f1: 0.790009\n",
      "[647]\ttraining's binary_logloss: 0.0241145\ttraining's f1: 0.8786\tvalid_1's binary_logloss: 0.0429562\tvalid_1's f1: 0.790044\n",
      "[648]\ttraining's binary_logloss: 0.0241009\ttraining's f1: 0.878619\tvalid_1's binary_logloss: 0.0429451\tvalid_1's f1: 0.790015\n",
      "[649]\ttraining's binary_logloss: 0.0240652\ttraining's f1: 0.878727\tvalid_1's binary_logloss: 0.042915\tvalid_1's f1: 0.790029\n",
      "[650]\ttraining's binary_logloss: 0.0240084\ttraining's f1: 0.878913\tvalid_1's binary_logloss: 0.0428803\tvalid_1's f1: 0.790108\n",
      "[651]\ttraining's binary_logloss: 0.02393\ttraining's f1: 0.879344\tvalid_1's binary_logloss: 0.0428182\tvalid_1's f1: 0.790274\n",
      "[652]\ttraining's binary_logloss: 0.0239028\ttraining's f1: 0.879471\tvalid_1's binary_logloss: 0.0428019\tvalid_1's f1: 0.790412\n",
      "[653]\ttraining's binary_logloss: 0.0238724\ttraining's f1: 0.87953\tvalid_1's binary_logloss: 0.042777\tvalid_1's f1: 0.79052\n",
      "[654]\ttraining's binary_logloss: 0.0238341\ttraining's f1: 0.879589\tvalid_1's binary_logloss: 0.042751\tvalid_1's f1: 0.7906\n",
      "[655]\ttraining's binary_logloss: 0.0238114\ttraining's f1: 0.879678\tvalid_1's binary_logloss: 0.0427438\tvalid_1's f1: 0.790578\n",
      "[656]\ttraining's binary_logloss: 0.0237253\ttraining's f1: 0.880189\tvalid_1's binary_logloss: 0.0426776\tvalid_1's f1: 0.790788\n",
      "[657]\ttraining's binary_logloss: 0.0236976\ttraining's f1: 0.880298\tvalid_1's binary_logloss: 0.042656\tvalid_1's f1: 0.790707\n",
      "[658]\ttraining's binary_logloss: 0.023668\ttraining's f1: 0.880455\tvalid_1's binary_logloss: 0.0426378\tvalid_1's f1: 0.790729\n",
      "[659]\ttraining's binary_logloss: 0.0236379\ttraining's f1: 0.880593\tvalid_1's binary_logloss: 0.0426129\tvalid_1's f1: 0.790889\n",
      "[660]\ttraining's binary_logloss: 0.0235759\ttraining's f1: 0.88083\tvalid_1's binary_logloss: 0.0425628\tvalid_1's f1: 0.790787\n",
      "[661]\ttraining's binary_logloss: 0.0235536\ttraining's f1: 0.880909\tvalid_1's binary_logloss: 0.0425503\tvalid_1's f1: 0.790874\n",
      "[662]\ttraining's binary_logloss: 0.023526\ttraining's f1: 0.881008\tvalid_1's binary_logloss: 0.0425368\tvalid_1's f1: 0.79094\n",
      "[663]\ttraining's binary_logloss: 0.0235131\ttraining's f1: 0.880998\tvalid_1's binary_logloss: 0.0425341\tvalid_1's f1: 0.79094\n",
      "[664]\ttraining's binary_logloss: 0.023482\ttraining's f1: 0.881038\tvalid_1's binary_logloss: 0.042518\tvalid_1's f1: 0.790764\n",
      "[665]\ttraining's binary_logloss: 0.0233893\ttraining's f1: 0.881751\tvalid_1's binary_logloss: 0.0424425\tvalid_1's f1: 0.790997\n",
      "[666]\ttraining's binary_logloss: 0.0233629\ttraining's f1: 0.881791\tvalid_1's binary_logloss: 0.0424268\tvalid_1's f1: 0.791048\n",
      "[667]\ttraining's binary_logloss: 0.023335\ttraining's f1: 0.88195\tvalid_1's binary_logloss: 0.042404\tvalid_1's f1: 0.791179\n",
      "[668]\ttraining's binary_logloss: 0.0233033\ttraining's f1: 0.88203\tvalid_1's binary_logloss: 0.0423836\tvalid_1's f1: 0.791267\n",
      "[669]\ttraining's binary_logloss: 0.0232914\ttraining's f1: 0.882049\tvalid_1's binary_logloss: 0.0423807\tvalid_1's f1: 0.791376\n",
      "[670]\ttraining's binary_logloss: 0.0232533\ttraining's f1: 0.882169\tvalid_1's binary_logloss: 0.0423551\tvalid_1's f1: 0.791383\n",
      "[671]\ttraining's binary_logloss: 0.0232227\ttraining's f1: 0.882278\tvalid_1's binary_logloss: 0.0423322\tvalid_1's f1: 0.791515\n",
      "[672]\ttraining's binary_logloss: 0.0232036\ttraining's f1: 0.882358\tvalid_1's binary_logloss: 0.0423205\tvalid_1's f1: 0.791493\n",
      "[673]\ttraining's binary_logloss: 0.0231542\ttraining's f1: 0.882617\tvalid_1's binary_logloss: 0.0422805\tvalid_1's f1: 0.791632\n",
      "[674]\ttraining's binary_logloss: 0.0230991\ttraining's f1: 0.882826\tvalid_1's binary_logloss: 0.0422368\tvalid_1's f1: 0.791756\n",
      "[675]\ttraining's binary_logloss: 0.0230666\ttraining's f1: 0.883016\tvalid_1's binary_logloss: 0.0422184\tvalid_1's f1: 0.791829\n",
      "[676]\ttraining's binary_logloss: 0.023056\ttraining's f1: 0.883066\tvalid_1's binary_logloss: 0.042215\tvalid_1's f1: 0.791895\n",
      "[677]\ttraining's binary_logloss: 0.0230448\ttraining's f1: 0.883096\tvalid_1's binary_logloss: 0.0422086\tvalid_1's f1: 0.791932\n",
      "[678]\ttraining's binary_logloss: 0.0230255\ttraining's f1: 0.883126\tvalid_1's binary_logloss: 0.0422033\tvalid_1's f1: 0.791858\n",
      "[679]\ttraining's binary_logloss: 0.022995\ttraining's f1: 0.883256\tvalid_1's binary_logloss: 0.0421817\tvalid_1's f1: 0.791939\n",
      "[680]\ttraining's binary_logloss: 0.0229306\ttraining's f1: 0.883506\tvalid_1's binary_logloss: 0.0421382\tvalid_1's f1: 0.792078\n",
      "[681]\ttraining's binary_logloss: 0.0228765\ttraining's f1: 0.883807\tvalid_1's binary_logloss: 0.0420926\tvalid_1's f1: 0.792159\n",
      "[682]\ttraining's binary_logloss: 0.0228663\ttraining's f1: 0.883857\tvalid_1's binary_logloss: 0.042089\tvalid_1's f1: 0.792181\n",
      "[683]\ttraining's binary_logloss: 0.0228042\ttraining's f1: 0.884088\tvalid_1's binary_logloss: 0.0420394\tvalid_1's f1: 0.792313\n",
      "[684]\ttraining's binary_logloss: 0.0227688\ttraining's f1: 0.884248\tvalid_1's binary_logloss: 0.0420265\tvalid_1's f1: 0.792262\n",
      "[685]\ttraining's binary_logloss: 0.0227219\ttraining's f1: 0.88458\tvalid_1's binary_logloss: 0.0419939\tvalid_1's f1: 0.79235\n",
      "[686]\ttraining's binary_logloss: 0.0227045\ttraining's f1: 0.884641\tvalid_1's binary_logloss: 0.0419805\tvalid_1's f1: 0.79235\n",
      "[687]\ttraining's binary_logloss: 0.0226796\ttraining's f1: 0.884822\tvalid_1's binary_logloss: 0.0419674\tvalid_1's f1: 0.792365\n",
      "[688]\ttraining's binary_logloss: 0.0226372\ttraining's f1: 0.885084\tvalid_1's binary_logloss: 0.0419429\tvalid_1's f1: 0.792306\n",
      "[689]\ttraining's binary_logloss: 0.022613\ttraining's f1: 0.885205\tvalid_1's binary_logloss: 0.0419267\tvalid_1's f1: 0.792306\n",
      "[690]\ttraining's binary_logloss: 0.0225462\ttraining's f1: 0.885468\tvalid_1's binary_logloss: 0.0418805\tvalid_1's f1: 0.792549\n",
      "[691]\ttraining's binary_logloss: 0.0225194\ttraining's f1: 0.88559\tvalid_1's binary_logloss: 0.0418672\tvalid_1's f1: 0.792564\n",
      "[692]\ttraining's binary_logloss: 0.0225102\ttraining's f1: 0.88561\tvalid_1's binary_logloss: 0.0418655\tvalid_1's f1: 0.792586\n",
      "[693]\ttraining's binary_logloss: 0.0225028\ttraining's f1: 0.88563\tvalid_1's binary_logloss: 0.0418657\tvalid_1's f1: 0.792608\n",
      "[694]\ttraining's binary_logloss: 0.0224599\ttraining's f1: 0.885832\tvalid_1's binary_logloss: 0.0418346\tvalid_1's f1: 0.792542\n",
      "[695]\ttraining's binary_logloss: 0.0224125\ttraining's f1: 0.886005\tvalid_1's binary_logloss: 0.0418008\tvalid_1's f1: 0.792896\n",
      "[696]\ttraining's binary_logloss: 0.0223644\ttraining's f1: 0.886157\tvalid_1's binary_logloss: 0.041765\tvalid_1's f1: 0.792889\n",
      "[697]\ttraining's binary_logloss: 0.0223106\ttraining's f1: 0.886553\tvalid_1's binary_logloss: 0.0417317\tvalid_1's f1: 0.793067\n",
      "[698]\ttraining's binary_logloss: 0.022287\ttraining's f1: 0.886634\tvalid_1's binary_logloss: 0.0417225\tvalid_1's f1: 0.793075\n",
      "[699]\ttraining's binary_logloss: 0.0222673\ttraining's f1: 0.886736\tvalid_1's binary_logloss: 0.0417071\tvalid_1's f1: 0.793105\n",
      "[700]\ttraining's binary_logloss: 0.0222203\ttraining's f1: 0.886868\tvalid_1's binary_logloss: 0.0416677\tvalid_1's f1: 0.793201\n"
     ]
    }
   ],
   "source": [
    "# train split to train and validation training set\n",
    "X_train , X_valid , y_train ,y_valid = train_test_split(\n",
    "    train.drop(['cano','bacno','fraud_ind','txkey','ecfg',\n",
    "                'flbmk', 'flg_3dsmk', 'insfg', 'ovrlt'],axis=1),\n",
    "    train['fraud_ind'],test_size=0.25,random_state =1102)\n",
    "\n",
    "# competiton require measure matrix\n",
    "def cus_f1(ytru, ypre):\n",
    "    threshold = 0.5\n",
    "    y_pre = list(map(lambda item:int(item>threshold),ypre))\n",
    "    f1 = f1_score(ytru, y_pre, average='macro')\n",
    "    return 'f1', f1, True\n",
    "\n",
    "#construct model use same hyperparameters\n",
    "clf = lig_model.fit(X_train,y_train\n",
    "                    ,eval_set=[(X_train, y_train),(X_valid,y_valid)],\n",
    "                            eval_metric=cus_f1,\n",
    "                            early_stopping_rounds=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train columns:Index(['acqic', 'conam', 'contp', 'csmcu', 'etymd', 'hcefg', 'iterm', 'locdt',\n",
      "       'loctm', 'mcc', 'mchno', 'scity', 'stocn', 'stscd'],\n",
      "      dtype='object')\n",
      "train shape:(1141340, 14)\n",
      "validation shape:(380447, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f'train columns:{X_train.columns}')\n",
    "print(f'train shape:{X_train.shape}')\n",
    "print(f'validation shape:{X_valid.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta score_train: 0.8973131434920859\n",
      "recall_score_train: 0.9999341368635974\n",
      "precision_score_train: 0.6361617431384873\n",
      "========================================================\n",
      "fbeta score: 0.6974677920924034\n",
      "recall_score: 0.7892498066511988\n",
      "precision_score: 0.47603498542274053\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    375275\n",
      "           1       0.48      0.79      0.59      5172\n",
      "\n",
      "    accuracy                           0.99    380447\n",
      "   macro avg       0.74      0.89      0.79    380447\n",
      "weighted avg       0.99      0.99      0.99    380447\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "results['ad'] = {}\n",
    "\n",
    "pre_train = clf.predict(X_train)\n",
    "pre_test = clf.predict(X_valid)\n",
    "\n",
    "results['ad']['fbeta_train'] = fbeta_score(y_train, pre_train, beta=2)\n",
    "results['ad']['recall_train'] = recall_score(y_train, pre_train)\n",
    "results['ad']['precision_train'] = precision_score(y_train, pre_train)\n",
    "\n",
    "results['ad']['fbeta_test'] = fbeta_score(y_valid, pre_test, beta=2)\n",
    "results['ad']['recall_test'] = recall_score(y_valid, pre_test)\n",
    "results['ad']['precision_test'] = precision_score(y_valid, pre_test)\n",
    "\n",
    "print(\"fbeta score_train:\", results['ad']['fbeta_train'])\n",
    "print('recall_score_train:', results['ad']['recall_train'])\n",
    "print('precision_score_train:', results['ad']['precision_train'])\n",
    "\n",
    "print('========================================================')\n",
    "print(\"fbeta score:\", results['ad']['fbeta_test'])\n",
    "print('recall_score:', results['ad']['recall_test'])\n",
    "print('precision_score:', results['ad']['precision_test'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_valid, pre_test))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_valid, pre_test)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solve the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = pd.DataFrame(train['txkey'])\n",
    "test_index = pd.DataFrame(test['txkey'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat train test into data all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train,test],axis=0,sort=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_processing.process_data(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acqic</th>\n",
       "      <th>bacno</th>\n",
       "      <th>cano</th>\n",
       "      <th>conam</th>\n",
       "      <th>contp</th>\n",
       "      <th>csmcu</th>\n",
       "      <th>ecfg</th>\n",
       "      <th>etymd</th>\n",
       "      <th>flbmk</th>\n",
       "      <th>flg_3dsmk</th>\n",
       "      <th>...</th>\n",
       "      <th>median_time_cano</th>\n",
       "      <th>total_seconds_diff</th>\n",
       "      <th>total_seconds_diff_cano</th>\n",
       "      <th>date_day</th>\n",
       "      <th>week</th>\n",
       "      <th>2_week</th>\n",
       "      <th>month</th>\n",
       "      <th>is_taiwan</th>\n",
       "      <th>country_com_num</th>\n",
       "      <th>city_com_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6697</td>\n",
       "      <td>12714</td>\n",
       "      <td>100972</td>\n",
       "      <td>966.58</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>48455.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1676085</td>\n",
       "      <td>930790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5559</td>\n",
       "      <td>34695</td>\n",
       "      <td>60550</td>\n",
       "      <td>1071.10</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>27539.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5680</td>\n",
       "      <td>5620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6750</td>\n",
       "      <td>22543</td>\n",
       "      <td>109977</td>\n",
       "      <td>438.21</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>51032.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1676085</td>\n",
       "      <td>51270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6748</td>\n",
       "      <td>91210</td>\n",
       "      <td>207875</td>\n",
       "      <td>1174.17</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62384.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1676085</td>\n",
       "      <td>930790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3186</td>\n",
       "      <td>83798</td>\n",
       "      <td>179174</td>\n",
       "      <td>367.29</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25386.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56178</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943447</th>\n",
       "      <td>6173</td>\n",
       "      <td>133825</td>\n",
       "      <td>121799</td>\n",
       "      <td>199.86</td>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45955.0</td>\n",
       "      <td>307638.0</td>\n",
       "      <td>307638.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1676085</td>\n",
       "      <td>930790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943448</th>\n",
       "      <td>6750</td>\n",
       "      <td>93331</td>\n",
       "      <td>189035</td>\n",
       "      <td>543.51</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66590.5</td>\n",
       "      <td>528118.0</td>\n",
       "      <td>528118.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1676085</td>\n",
       "      <td>930790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943449</th>\n",
       "      <td>6198</td>\n",
       "      <td>54235</td>\n",
       "      <td>153139</td>\n",
       "      <td>655.51</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73153.5</td>\n",
       "      <td>84743.0</td>\n",
       "      <td>84743.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52779</td>\n",
       "      <td>48446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943450</th>\n",
       "      <td>6198</td>\n",
       "      <td>54235</td>\n",
       "      <td>153139</td>\n",
       "      <td>490.68</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73153.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52779</td>\n",
       "      <td>48446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943451</th>\n",
       "      <td>3335</td>\n",
       "      <td>80452</td>\n",
       "      <td>106193</td>\n",
       "      <td>424.66</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36976.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56178</td>\n",
       "      <td>52196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1943452 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         acqic   bacno    cano    conam  contp  csmcu  ecfg  etymd  flbmk  \\\n",
       "0         6697   12714  100972   966.58      4     62     0      2      0   \n",
       "1         5559   34695   60550  1071.10      5     62     1      8      0   \n",
       "2         6750   22543  109977   438.21      5     62     0      5      0   \n",
       "3         6748   91210  207875  1174.17      5     62     0      5      0   \n",
       "4         3186   83798  179174   367.29      5     60     0      5      0   \n",
       "...        ...     ...     ...      ...    ...    ...   ...    ...    ...   \n",
       "1943447   6173  133825  121799   199.86      2     62     0      2      0   \n",
       "1943448   6750   93331  189035   543.51      5     62     0      5      0   \n",
       "1943449   6198   54235  153139   655.51      5     62     1      2      0   \n",
       "1943450   6198   54235  153139   490.68      5     62     1      2      0   \n",
       "1943451   3335   80452  106193   424.66      5     62     1      8      0   \n",
       "\n",
       "         flg_3dsmk  ...  median_time_cano  total_seconds_diff  \\\n",
       "0                0  ...           48455.5                 0.0   \n",
       "1                0  ...           27539.5                 0.0   \n",
       "2                0  ...           51032.0                 0.0   \n",
       "3                0  ...           62384.0                 0.0   \n",
       "4                0  ...           25386.5                 0.0   \n",
       "...            ...  ...               ...                 ...   \n",
       "1943447          0  ...           45955.0            307638.0   \n",
       "1943448          0  ...           66590.5            528118.0   \n",
       "1943449          0  ...           73153.5             84743.0   \n",
       "1943450          0  ...           73153.5                 3.0   \n",
       "1943451          0  ...           36976.0               582.0   \n",
       "\n",
       "         total_seconds_diff_cano  date_day  week  2_week  month  is_taiwan  \\\n",
       "0                            0.0         1     1       1      1          1   \n",
       "1                            0.0         1     1       1      1          0   \n",
       "2                            0.0         1     1       1      1          1   \n",
       "3                            0.0         1     1       1      1          1   \n",
       "4                            0.0         1     1       1      1          0   \n",
       "...                          ...       ...   ...     ...    ...        ...   \n",
       "1943447                 307638.0         0     1       8      0          1   \n",
       "1943448                 528118.0         0     1       8      0          1   \n",
       "1943449                  84743.0         0     1       8      0          0   \n",
       "1943450                      3.0         0     1       8      0          0   \n",
       "1943451                    582.0         0     1       8      0          0   \n",
       "\n",
       "         country_com_num  city_com_num  \n",
       "0                1676085        930790  \n",
       "1                   5680          5620  \n",
       "2                1676085         51270  \n",
       "3                1676085        930790  \n",
       "4                  56178             7  \n",
       "...                  ...           ...  \n",
       "1943447          1676085        930790  \n",
       "1943448          1676085        930790  \n",
       "1943449            52779         48446  \n",
       "1943450            52779         48446  \n",
       "1943451            56178         52196  \n",
       "\n",
       "[1943452 rows x 93 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acqic', 'bacno', 'cano', 'conam', 'contp', 'csmcu', 'ecfg', 'etymd',\n",
       "       'flbmk', 'flg_3dsmk', 'fraud_ind', 'hcefg', 'insfg', 'iterm', 'locdt',\n",
       "       'loctm', 'mcc', 'mchno', 'ovrlt', 'scity', 'stocn', 'stscd', 'txkey',\n",
       "       'ecfg_stocn', 'ecfg_scity', 'ovrlt_stocn', 'ovrlt_scity', 'loctm_int',\n",
       "       'loctm_str', 'hours', 'minutes', 'seconds', 'total_seconds', 'time',\n",
       "       'trad_hour', 'morning', 'afternoon', 'night', 'midnight',\n",
       "       'transaction_count', 'transaction_count_cano', 'acqic_duplicated_count',\n",
       "       'conam_duplicated_count', 'conam_stocn', 'bacno_mchno', 'cano_mchno',\n",
       "       'bacno_stocn', 'cano_stocn', 'bacno_scity', 'cano_scity',\n",
       "       'bacno_flg_3dsmk', 'cano_flg_3dsmk', 'bacno_ecfg_mean',\n",
       "       'cano_ecfg_mean', 'comsum_min', 'comsum_max', 'acc_trad_ave',\n",
       "       'acc_trad_total', 'comsum_total', 'comsum_ave', 'mean_amount',\n",
       "       'amtby_mean_amount', 'mean_amount_cano', 'amtby_mean_amount_cano',\n",
       "       'median_amount', 'amtby_median_amount', 'median_amount_cano',\n",
       "       'amtby_median_amount_cano', 'std_amount', 'comsum_feq30',\n",
       "       'comsum_feq3060', 'comsum_feq6090', 'comsum_feq90120', 'comsum_feq60',\n",
       "       'comsum_feq3090', 'comsum_feq60120', 'day_trad_num', 'day_comsum_total',\n",
       "       'frequency', 'frequency_cano', 'mean_time', 'median_time',\n",
       "       'mean_time_cano', 'median_time_cano', 'total_seconds_diff',\n",
       "       'total_seconds_diff_cano', 'date_day', 'week', '2_week', 'month',\n",
       "       'is_taiwan', 'country_com_num', 'city_com_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所使用的變數\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943452, 93)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 資料大小\n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get columns' list whose datatype as object\n",
    "object_list = []\n",
    "for col in data.columns.tolist():\n",
    "    if data[col].dtype == 'object':\n",
    "        object_list.append(col)\n",
    "\n",
    "# select object_list whose unique value above 4 type        \n",
    "nd_tar_list = []\n",
    "for col in object_list:\n",
    "\n",
    "    if len(data[col].unique()) < 5:\n",
    "        nd_ont_list.append(col)\n",
    "    else:\n",
    "        nd_tar_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ecfg_stocn', 'ecfg_scity', 'ovrlt_stocn', 'ovrlt_scity', 'loctm_str']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.merge(train_index)\n",
    "test = data.merge(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tar = train[train['locdt'] > 30]\n",
    "\n",
    "tar = TargetEncoder(smoothing=0.9).fit(train_tar[nd_tar_list],train_tar['fraud_ind'])\n",
    "test[nd_tar_list] = tar.transform(test[nd_tar_list])\n",
    "train[nd_tar_list] = tar.transform(train[nd_tar_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(1521787, 93)\n",
      " test shape:(421665, 92)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape:{train.shape}\\n test shape:{test.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check train test shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:(1521787, 93),test shape:(421665, 92)\n"
     ]
    }
   ],
   "source": [
    "test.drop('fraud_ind',axis=1,inplace=True)\n",
    "print(f'train shape:{train.shape},test shape:{test.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig_model = light.LGBMClassifier(\n",
    "    n_estimators=700,reg_alpha=0.3,num_leaves=200,learning_rate=0.1,\n",
    "    reg_lambda=0.5,subsample=0.7,is_unbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_valid , y_train ,y_valid = train_test_split(\n",
    "    train.drop(['cano','bacno','fraud_ind','txkey'],axis=1),\n",
    "    train['fraud_ind'],test_size=0.25,random_state =1102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cus_f1(ytru, ypre):\n",
    "    threshold = 0.5\n",
    "    y_pre = list(map(lambda item:int(item>threshold),ypre))\n",
    "    f1 = f1_score(ytru, y_pre, average='macro')\n",
    "    return 'f1', f1, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.0834554\ttraining's f1: 0.738217\tvalid_1's binary_logloss: 0.0854415\tvalid_1's f1: 0.730862\n",
      "[2]\ttraining's binary_logloss: 0.0794888\ttraining's f1: 0.739484\tvalid_1's binary_logloss: 0.081908\tvalid_1's f1: 0.731541\n",
      "[3]\ttraining's binary_logloss: 0.0747238\ttraining's f1: 0.741275\tvalid_1's binary_logloss: 0.0775116\tvalid_1's f1: 0.733513\n",
      "[4]\ttraining's binary_logloss: 0.0708456\ttraining's f1: 0.743281\tvalid_1's binary_logloss: 0.0738734\tvalid_1's f1: 0.735136\n",
      "[5]\ttraining's binary_logloss: 0.0672539\ttraining's f1: 0.745492\tvalid_1's binary_logloss: 0.0704401\tvalid_1's f1: 0.737124\n",
      "[6]\ttraining's binary_logloss: 0.0643663\ttraining's f1: 0.748194\tvalid_1's binary_logloss: 0.0676192\tvalid_1's f1: 0.739807\n",
      "[7]\ttraining's binary_logloss: 0.0616472\ttraining's f1: 0.751683\tvalid_1's binary_logloss: 0.0650308\tvalid_1's f1: 0.742784\n",
      "[8]\ttraining's binary_logloss: 0.0589693\ttraining's f1: 0.756155\tvalid_1's binary_logloss: 0.0625829\tvalid_1's f1: 0.746956\n",
      "[9]\ttraining's binary_logloss: 0.056806\ttraining's f1: 0.759756\tvalid_1's binary_logloss: 0.0605201\tvalid_1's f1: 0.75018\n",
      "[10]\ttraining's binary_logloss: 0.0545153\ttraining's f1: 0.764057\tvalid_1's binary_logloss: 0.0583379\tvalid_1's f1: 0.753387\n",
      "[11]\ttraining's binary_logloss: 0.0525229\ttraining's f1: 0.76826\tvalid_1's binary_logloss: 0.0564267\tvalid_1's f1: 0.756693\n",
      "[12]\ttraining's binary_logloss: 0.050648\ttraining's f1: 0.772101\tvalid_1's binary_logloss: 0.0546989\tvalid_1's f1: 0.759591\n",
      "[13]\ttraining's binary_logloss: 0.0488207\ttraining's f1: 0.776787\tvalid_1's binary_logloss: 0.0529398\tvalid_1's f1: 0.76384\n",
      "[14]\ttraining's binary_logloss: 0.0472723\ttraining's f1: 0.781096\tvalid_1's binary_logloss: 0.0514243\tvalid_1's f1: 0.768168\n",
      "[15]\ttraining's binary_logloss: 0.0458054\ttraining's f1: 0.785672\tvalid_1's binary_logloss: 0.0500084\tvalid_1's f1: 0.772213\n",
      "[16]\ttraining's binary_logloss: 0.0443377\ttraining's f1: 0.79059\tvalid_1's binary_logloss: 0.0486412\tvalid_1's f1: 0.776466\n",
      "[17]\ttraining's binary_logloss: 0.0429674\ttraining's f1: 0.79491\tvalid_1's binary_logloss: 0.0473187\tvalid_1's f1: 0.780113\n",
      "[18]\ttraining's binary_logloss: 0.041562\ttraining's f1: 0.800045\tvalid_1's binary_logloss: 0.0459549\tvalid_1's f1: 0.784372\n",
      "[19]\ttraining's binary_logloss: 0.0404211\ttraining's f1: 0.804737\tvalid_1's binary_logloss: 0.0448489\tvalid_1's f1: 0.788664\n",
      "[20]\ttraining's binary_logloss: 0.0392003\ttraining's f1: 0.809467\tvalid_1's binary_logloss: 0.0436956\tvalid_1's f1: 0.792692\n",
      "[21]\ttraining's binary_logloss: 0.0381219\ttraining's f1: 0.8136\tvalid_1's binary_logloss: 0.0426972\tvalid_1's f1: 0.796725\n",
      "[22]\ttraining's binary_logloss: 0.0371182\ttraining's f1: 0.817354\tvalid_1's binary_logloss: 0.041804\tvalid_1's f1: 0.800392\n",
      "[23]\ttraining's binary_logloss: 0.036203\ttraining's f1: 0.820869\tvalid_1's binary_logloss: 0.0409571\tvalid_1's f1: 0.803876\n",
      "[24]\ttraining's binary_logloss: 0.0351486\ttraining's f1: 0.825199\tvalid_1's binary_logloss: 0.0399386\tvalid_1's f1: 0.807688\n",
      "[25]\ttraining's binary_logloss: 0.0341512\ttraining's f1: 0.82872\tvalid_1's binary_logloss: 0.0390282\tvalid_1's f1: 0.810336\n",
      "[26]\ttraining's binary_logloss: 0.033088\ttraining's f1: 0.832654\tvalid_1's binary_logloss: 0.0379959\tvalid_1's f1: 0.813611\n",
      "[27]\ttraining's binary_logloss: 0.0322804\ttraining's f1: 0.83604\tvalid_1's binary_logloss: 0.0372711\tvalid_1's f1: 0.817204\n",
      "[28]\ttraining's binary_logloss: 0.0312803\ttraining's f1: 0.839553\tvalid_1's binary_logloss: 0.0364103\tvalid_1's f1: 0.820149\n",
      "[29]\ttraining's binary_logloss: 0.0305064\ttraining's f1: 0.842612\tvalid_1's binary_logloss: 0.0356765\tvalid_1's f1: 0.823913\n",
      "[30]\ttraining's binary_logloss: 0.0297965\ttraining's f1: 0.845978\tvalid_1's binary_logloss: 0.0350728\tvalid_1's f1: 0.826329\n",
      "[31]\ttraining's binary_logloss: 0.0290485\ttraining's f1: 0.849188\tvalid_1's binary_logloss: 0.0344372\tvalid_1's f1: 0.829247\n",
      "[32]\ttraining's binary_logloss: 0.0282783\ttraining's f1: 0.852091\tvalid_1's binary_logloss: 0.0337301\tvalid_1's f1: 0.831788\n",
      "[33]\ttraining's binary_logloss: 0.027604\ttraining's f1: 0.854783\tvalid_1's binary_logloss: 0.0331\tvalid_1's f1: 0.833986\n",
      "[34]\ttraining's binary_logloss: 0.0268822\ttraining's f1: 0.857679\tvalid_1's binary_logloss: 0.0324773\tvalid_1's f1: 0.836356\n",
      "[35]\ttraining's binary_logloss: 0.0262516\ttraining's f1: 0.860567\tvalid_1's binary_logloss: 0.0318983\tvalid_1's f1: 0.838853\n",
      "[36]\ttraining's binary_logloss: 0.0254429\ttraining's f1: 0.863939\tvalid_1's binary_logloss: 0.0311106\tvalid_1's f1: 0.841486\n",
      "[37]\ttraining's binary_logloss: 0.0248022\ttraining's f1: 0.86623\tvalid_1's binary_logloss: 0.0305506\tvalid_1's f1: 0.842808\n",
      "[38]\ttraining's binary_logloss: 0.0242536\ttraining's f1: 0.868668\tvalid_1's binary_logloss: 0.0300502\tvalid_1's f1: 0.845199\n",
      "[39]\ttraining's binary_logloss: 0.0237119\ttraining's f1: 0.870634\tvalid_1's binary_logloss: 0.0295759\tvalid_1's f1: 0.846663\n",
      "[40]\ttraining's binary_logloss: 0.0230789\ttraining's f1: 0.873496\tvalid_1's binary_logloss: 0.0290016\tvalid_1's f1: 0.848885\n",
      "[41]\ttraining's binary_logloss: 0.0225506\ttraining's f1: 0.87551\tvalid_1's binary_logloss: 0.0285445\tvalid_1's f1: 0.850473\n",
      "[42]\ttraining's binary_logloss: 0.0220277\ttraining's f1: 0.877623\tvalid_1's binary_logloss: 0.0280709\tvalid_1's f1: 0.852534\n",
      "[43]\ttraining's binary_logloss: 0.0214895\ttraining's f1: 0.879923\tvalid_1's binary_logloss: 0.0275784\tvalid_1's f1: 0.855373\n",
      "[44]\ttraining's binary_logloss: 0.0210407\ttraining's f1: 0.881708\tvalid_1's binary_logloss: 0.0271851\tvalid_1's f1: 0.856738\n",
      "[45]\ttraining's binary_logloss: 0.0205549\ttraining's f1: 0.883937\tvalid_1's binary_logloss: 0.0267265\tvalid_1's f1: 0.858768\n",
      "[46]\ttraining's binary_logloss: 0.0201048\ttraining's f1: 0.88604\tvalid_1's binary_logloss: 0.0263336\tvalid_1's f1: 0.859958\n",
      "[47]\ttraining's binary_logloss: 0.019659\ttraining's f1: 0.888195\tvalid_1's binary_logloss: 0.0259086\tvalid_1's f1: 0.861339\n",
      "[48]\ttraining's binary_logloss: 0.0191979\ttraining's f1: 0.890024\tvalid_1's binary_logloss: 0.0255216\tvalid_1's f1: 0.862997\n",
      "[49]\ttraining's binary_logloss: 0.0187555\ttraining's f1: 0.892015\tvalid_1's binary_logloss: 0.025116\tvalid_1's f1: 0.864613\n",
      "[50]\ttraining's binary_logloss: 0.0183437\ttraining's f1: 0.893721\tvalid_1's binary_logloss: 0.0247635\tvalid_1's f1: 0.866116\n",
      "[51]\ttraining's binary_logloss: 0.0179456\ttraining's f1: 0.895758\tvalid_1's binary_logloss: 0.0244144\tvalid_1's f1: 0.867933\n",
      "[52]\ttraining's binary_logloss: 0.0175504\ttraining's f1: 0.897262\tvalid_1's binary_logloss: 0.0240732\tvalid_1's f1: 0.869007\n",
      "[53]\ttraining's binary_logloss: 0.0171633\ttraining's f1: 0.899056\tvalid_1's binary_logloss: 0.0237324\tvalid_1's f1: 0.870186\n",
      "[54]\ttraining's binary_logloss: 0.0167958\ttraining's f1: 0.9012\tvalid_1's binary_logloss: 0.0233991\tvalid_1's f1: 0.871549\n",
      "[55]\ttraining's binary_logloss: 0.0164496\ttraining's f1: 0.902624\tvalid_1's binary_logloss: 0.0231063\tvalid_1's f1: 0.872994\n",
      "[56]\ttraining's binary_logloss: 0.0161164\ttraining's f1: 0.904519\tvalid_1's binary_logloss: 0.02281\tvalid_1's f1: 0.874278\n",
      "[57]\ttraining's binary_logloss: 0.0157829\ttraining's f1: 0.90611\tvalid_1's binary_logloss: 0.0225119\tvalid_1's f1: 0.875952\n",
      "[58]\ttraining's binary_logloss: 0.0154557\ttraining's f1: 0.907869\tvalid_1's binary_logloss: 0.0222261\tvalid_1's f1: 0.877092\n",
      "[59]\ttraining's binary_logloss: 0.0151466\ttraining's f1: 0.909338\tvalid_1's binary_logloss: 0.0219607\tvalid_1's f1: 0.878057\n",
      "[60]\ttraining's binary_logloss: 0.0148604\ttraining's f1: 0.910727\tvalid_1's binary_logloss: 0.021708\tvalid_1's f1: 0.87923\n",
      "[61]\ttraining's binary_logloss: 0.0145659\ttraining's f1: 0.912216\tvalid_1's binary_logloss: 0.0214595\tvalid_1's f1: 0.880612\n",
      "[62]\ttraining's binary_logloss: 0.0142895\ttraining's f1: 0.913911\tvalid_1's binary_logloss: 0.021228\tvalid_1's f1: 0.882054\n",
      "[63]\ttraining's binary_logloss: 0.0140168\ttraining's f1: 0.915295\tvalid_1's binary_logloss: 0.0209769\tvalid_1's f1: 0.883225\n",
      "[64]\ttraining's binary_logloss: 0.0137539\ttraining's f1: 0.916618\tvalid_1's binary_logloss: 0.0207773\tvalid_1's f1: 0.883849\n",
      "[65]\ttraining's binary_logloss: 0.0135082\ttraining's f1: 0.917985\tvalid_1's binary_logloss: 0.0206032\tvalid_1's f1: 0.884574\n",
      "[66]\ttraining's binary_logloss: 0.0132408\ttraining's f1: 0.919537\tvalid_1's binary_logloss: 0.020372\tvalid_1's f1: 0.886303\n",
      "[67]\ttraining's binary_logloss: 0.0129868\ttraining's f1: 0.920815\tvalid_1's binary_logloss: 0.0201452\tvalid_1's f1: 0.887722\n",
      "[68]\ttraining's binary_logloss: 0.0127405\ttraining's f1: 0.922052\tvalid_1's binary_logloss: 0.0199442\tvalid_1's f1: 0.889317\n",
      "[69]\ttraining's binary_logloss: 0.0125073\ttraining's f1: 0.923237\tvalid_1's binary_logloss: 0.0197369\tvalid_1's f1: 0.889839\n",
      "[70]\ttraining's binary_logloss: 0.0122645\ttraining's f1: 0.924791\tvalid_1's binary_logloss: 0.0195411\tvalid_1's f1: 0.890797\n",
      "[71]\ttraining's binary_logloss: 0.01205\ttraining's f1: 0.925541\tvalid_1's binary_logloss: 0.0193864\tvalid_1's f1: 0.89163\n",
      "[72]\ttraining's binary_logloss: 0.0118238\ttraining's f1: 0.927233\tvalid_1's binary_logloss: 0.019195\tvalid_1's f1: 0.892596\n",
      "[73]\ttraining's binary_logloss: 0.0116214\ttraining's f1: 0.928213\tvalid_1's binary_logloss: 0.0190456\tvalid_1's f1: 0.893321\n",
      "[74]\ttraining's binary_logloss: 0.0114233\ttraining's f1: 0.929073\tvalid_1's binary_logloss: 0.0189246\tvalid_1's f1: 0.894182\n",
      "[75]\ttraining's binary_logloss: 0.0112015\ttraining's f1: 0.930123\tvalid_1's binary_logloss: 0.0187441\tvalid_1's f1: 0.894764\n",
      "[76]\ttraining's binary_logloss: 0.0110318\ttraining's f1: 0.930892\tvalid_1's binary_logloss: 0.018635\tvalid_1's f1: 0.895314\n",
      "[77]\ttraining's binary_logloss: 0.0108498\ttraining's f1: 0.932325\tvalid_1's binary_logloss: 0.018498\tvalid_1's f1: 0.896536\n",
      "[78]\ttraining's binary_logloss: 0.0106497\ttraining's f1: 0.933565\tvalid_1's binary_logloss: 0.0183483\tvalid_1's f1: 0.897227\n",
      "[79]\ttraining's binary_logloss: 0.0104615\ttraining's f1: 0.934775\tvalid_1's binary_logloss: 0.0182015\tvalid_1's f1: 0.89841\n",
      "[80]\ttraining's binary_logloss: 0.0102906\ttraining's f1: 0.935725\tvalid_1's binary_logloss: 0.0180818\tvalid_1's f1: 0.898852\n",
      "[81]\ttraining's binary_logloss: 0.0101115\ttraining's f1: 0.936373\tvalid_1's binary_logloss: 0.0179522\tvalid_1's f1: 0.899362\n",
      "[82]\ttraining's binary_logloss: 0.00993075\ttraining's f1: 0.937317\tvalid_1's binary_logloss: 0.0178045\tvalid_1's f1: 0.899807\n",
      "[83]\ttraining's binary_logloss: 0.00976045\ttraining's f1: 0.937944\tvalid_1's binary_logloss: 0.0176807\tvalid_1's f1: 0.900747\n",
      "[84]\ttraining's binary_logloss: 0.00959463\ttraining's f1: 0.939319\tvalid_1's binary_logloss: 0.0175509\tvalid_1's f1: 0.901299\n",
      "[85]\ttraining's binary_logloss: 0.00945788\ttraining's f1: 0.940392\tvalid_1's binary_logloss: 0.0174482\tvalid_1's f1: 0.901903\n",
      "[86]\ttraining's binary_logloss: 0.00928879\ttraining's f1: 0.941079\tvalid_1's binary_logloss: 0.017335\tvalid_1's f1: 0.902373\n",
      "[87]\ttraining's binary_logloss: 0.00912067\ttraining's f1: 0.942395\tvalid_1's binary_logloss: 0.0171889\tvalid_1's f1: 0.90317\n",
      "[88]\ttraining's binary_logloss: 0.00896368\ttraining's f1: 0.943272\tvalid_1's binary_logloss: 0.0170718\tvalid_1's f1: 0.904317\n",
      "[89]\ttraining's binary_logloss: 0.00879071\ttraining's f1: 0.944429\tvalid_1's binary_logloss: 0.0169505\tvalid_1's f1: 0.904778\n",
      "[90]\ttraining's binary_logloss: 0.0086396\ttraining's f1: 0.945169\tvalid_1's binary_logloss: 0.0168395\tvalid_1's f1: 0.905464\n",
      "[91]\ttraining's binary_logloss: 0.00850561\ttraining's f1: 0.945911\tvalid_1's binary_logloss: 0.0167493\tvalid_1's f1: 0.905941\n",
      "[92]\ttraining's binary_logloss: 0.00838589\ttraining's f1: 0.946522\tvalid_1's binary_logloss: 0.0166777\tvalid_1's f1: 0.90607\n",
      "[93]\ttraining's binary_logloss: 0.00823749\ttraining's f1: 0.947575\tvalid_1's binary_logloss: 0.0165671\tvalid_1's f1: 0.906467\n",
      "[94]\ttraining's binary_logloss: 0.0081004\ttraining's f1: 0.948835\tvalid_1's binary_logloss: 0.0164556\tvalid_1's f1: 0.907064\n",
      "[95]\ttraining's binary_logloss: 0.00797517\ttraining's f1: 0.949764\tvalid_1's binary_logloss: 0.016356\tvalid_1's f1: 0.907555\n",
      "[96]\ttraining's binary_logloss: 0.00784607\ttraining's f1: 0.950371\tvalid_1's binary_logloss: 0.0162758\tvalid_1's f1: 0.908181\n",
      "[97]\ttraining's binary_logloss: 0.00772388\ttraining's f1: 0.951076\tvalid_1's binary_logloss: 0.0161871\tvalid_1's f1: 0.908732\n",
      "[98]\ttraining's binary_logloss: 0.00760162\ttraining's f1: 0.95185\tvalid_1's binary_logloss: 0.0160862\tvalid_1's f1: 0.908717\n",
      "[99]\ttraining's binary_logloss: 0.00750122\ttraining's f1: 0.952491\tvalid_1's binary_logloss: 0.0160323\tvalid_1's f1: 0.909131\n",
      "[100]\ttraining's binary_logloss: 0.00740316\ttraining's f1: 0.953106\tvalid_1's binary_logloss: 0.0159796\tvalid_1's f1: 0.909849\n",
      "[101]\ttraining's binary_logloss: 0.00728435\ttraining's f1: 0.953736\tvalid_1's binary_logloss: 0.0158956\tvalid_1's f1: 0.910266\n",
      "[102]\ttraining's binary_logloss: 0.00717525\ttraining's f1: 0.954437\tvalid_1's binary_logloss: 0.0158313\tvalid_1's f1: 0.91039\n",
      "[103]\ttraining's binary_logloss: 0.007057\ttraining's f1: 0.955057\tvalid_1's binary_logloss: 0.0157493\tvalid_1's f1: 0.910955\n",
      "[104]\ttraining's binary_logloss: 0.00695554\ttraining's f1: 0.95579\tvalid_1's binary_logloss: 0.0156769\tvalid_1's f1: 0.911049\n",
      "[105]\ttraining's binary_logloss: 0.00686688\ttraining's f1: 0.956399\tvalid_1's binary_logloss: 0.0156152\tvalid_1's f1: 0.911323\n",
      "[106]\ttraining's binary_logloss: 0.0067655\ttraining's f1: 0.956899\tvalid_1's binary_logloss: 0.0155455\tvalid_1's f1: 0.911794\n",
      "[107]\ttraining's binary_logloss: 0.00667168\ttraining's f1: 0.957652\tvalid_1's binary_logloss: 0.015477\tvalid_1's f1: 0.911901\n",
      "[108]\ttraining's binary_logloss: 0.00657216\ttraining's f1: 0.958238\tvalid_1's binary_logloss: 0.0154158\tvalid_1's f1: 0.912614\n",
      "[109]\ttraining's binary_logloss: 0.00645768\ttraining's f1: 0.959023\tvalid_1's binary_logloss: 0.0153408\tvalid_1's f1: 0.912979\n",
      "[110]\ttraining's binary_logloss: 0.00636501\ttraining's f1: 0.959697\tvalid_1's binary_logloss: 0.0152649\tvalid_1's f1: 0.913403\n",
      "[111]\ttraining's binary_logloss: 0.00625186\ttraining's f1: 0.96043\tvalid_1's binary_logloss: 0.0151926\tvalid_1's f1: 0.913858\n",
      "[112]\ttraining's binary_logloss: 0.00615286\ttraining's f1: 0.960967\tvalid_1's binary_logloss: 0.0151199\tvalid_1's f1: 0.914144\n",
      "[113]\ttraining's binary_logloss: 0.00607876\ttraining's f1: 0.961548\tvalid_1's binary_logloss: 0.015077\tvalid_1's f1: 0.914188\n",
      "[114]\ttraining's binary_logloss: 0.00599521\ttraining's f1: 0.962229\tvalid_1's binary_logloss: 0.0150102\tvalid_1's f1: 0.914682\n",
      "[115]\ttraining's binary_logloss: 0.00590542\ttraining's f1: 0.962713\tvalid_1's binary_logloss: 0.0149625\tvalid_1's f1: 0.914726\n",
      "[116]\ttraining's binary_logloss: 0.00582327\ttraining's f1: 0.963398\tvalid_1's binary_logloss: 0.0149\tvalid_1's f1: 0.914859\n",
      "[117]\ttraining's binary_logloss: 0.00573675\ttraining's f1: 0.9641\tvalid_1's binary_logloss: 0.0148435\tvalid_1's f1: 0.915562\n",
      "[118]\ttraining's binary_logloss: 0.00564923\ttraining's f1: 0.964688\tvalid_1's binary_logloss: 0.0147801\tvalid_1's f1: 0.916118\n",
      "[119]\ttraining's binary_logloss: 0.00557317\ttraining's f1: 0.965206\tvalid_1's binary_logloss: 0.0147403\tvalid_1's f1: 0.916586\n",
      "[120]\ttraining's binary_logloss: 0.00547137\ttraining's f1: 0.966231\tvalid_1's binary_logloss: 0.0146711\tvalid_1's f1: 0.917033\n",
      "[121]\ttraining's binary_logloss: 0.00538971\ttraining's f1: 0.966911\tvalid_1's binary_logloss: 0.0146114\tvalid_1's f1: 0.917392\n",
      "[122]\ttraining's binary_logloss: 0.00530651\ttraining's f1: 0.96726\tvalid_1's binary_logloss: 0.0145438\tvalid_1's f1: 0.917962\n",
      "[123]\ttraining's binary_logloss: 0.0052439\ttraining's f1: 0.967812\tvalid_1's binary_logloss: 0.0144939\tvalid_1's f1: 0.918488\n",
      "[124]\ttraining's binary_logloss: 0.00517013\ttraining's f1: 0.96838\tvalid_1's binary_logloss: 0.014451\tvalid_1's f1: 0.918699\n",
      "[125]\ttraining's binary_logloss: 0.00509509\ttraining's f1: 0.96895\tvalid_1's binary_logloss: 0.0144044\tvalid_1's f1: 0.918812\n",
      "[126]\ttraining's binary_logloss: 0.00501979\ttraining's f1: 0.969668\tvalid_1's binary_logloss: 0.0143547\tvalid_1's f1: 0.919297\n",
      "[127]\ttraining's binary_logloss: 0.00494744\ttraining's f1: 0.970138\tvalid_1's binary_logloss: 0.0142977\tvalid_1's f1: 0.919713\n",
      "[128]\ttraining's binary_logloss: 0.00488129\ttraining's f1: 0.970388\tvalid_1's binary_logloss: 0.0142698\tvalid_1's f1: 0.919916\n",
      "[129]\ttraining's binary_logloss: 0.00480906\ttraining's f1: 0.970785\tvalid_1's binary_logloss: 0.0142282\tvalid_1's f1: 0.920243\n",
      "[130]\ttraining's binary_logloss: 0.00474794\ttraining's f1: 0.971169\tvalid_1's binary_logloss: 0.0141961\tvalid_1's f1: 0.920394\n",
      "[131]\ttraining's binary_logloss: 0.00468012\ttraining's f1: 0.971597\tvalid_1's binary_logloss: 0.014159\tvalid_1's f1: 0.920456\n",
      "[132]\ttraining's binary_logloss: 0.00461616\ttraining's f1: 0.972189\tvalid_1's binary_logloss: 0.0141196\tvalid_1's f1: 0.92048\n",
      "[133]\ttraining's binary_logloss: 0.00455717\ttraining's f1: 0.972798\tvalid_1's binary_logloss: 0.0140837\tvalid_1's f1: 0.920618\n",
      "[134]\ttraining's binary_logloss: 0.00449694\ttraining's f1: 0.973318\tvalid_1's binary_logloss: 0.0140486\tvalid_1's f1: 0.920722\n",
      "[135]\ttraining's binary_logloss: 0.00443819\ttraining's f1: 0.973795\tvalid_1's binary_logloss: 0.0140133\tvalid_1's f1: 0.920836\n",
      "[136]\ttraining's binary_logloss: 0.00437637\ttraining's f1: 0.974393\tvalid_1's binary_logloss: 0.0139814\tvalid_1's f1: 0.921164\n",
      "[137]\ttraining's binary_logloss: 0.00431012\ttraining's f1: 0.974917\tvalid_1's binary_logloss: 0.0139402\tvalid_1's f1: 0.921439\n",
      "[138]\ttraining's binary_logloss: 0.00425114\ttraining's f1: 0.975397\tvalid_1's binary_logloss: 0.0138987\tvalid_1's f1: 0.921526\n",
      "[139]\ttraining's binary_logloss: 0.00419776\ttraining's f1: 0.975742\tvalid_1's binary_logloss: 0.0138617\tvalid_1's f1: 0.921821\n",
      "[140]\ttraining's binary_logloss: 0.00413913\ttraining's f1: 0.976209\tvalid_1's binary_logloss: 0.013833\tvalid_1's f1: 0.92205\n",
      "[141]\ttraining's binary_logloss: 0.00407423\ttraining's f1: 0.976737\tvalid_1's binary_logloss: 0.0137865\tvalid_1's f1: 0.922614\n",
      "[142]\ttraining's binary_logloss: 0.00401934\ttraining's f1: 0.977175\tvalid_1's binary_logloss: 0.0137464\tvalid_1's f1: 0.922767\n",
      "[143]\ttraining's binary_logloss: 0.00395995\ttraining's f1: 0.97769\tvalid_1's binary_logloss: 0.0136965\tvalid_1's f1: 0.923201\n",
      "[144]\ttraining's binary_logloss: 0.00390394\ttraining's f1: 0.978054\tvalid_1's binary_logloss: 0.0136556\tvalid_1's f1: 0.923147\n",
      "[145]\ttraining's binary_logloss: 0.00385695\ttraining's f1: 0.978312\tvalid_1's binary_logloss: 0.0136355\tvalid_1's f1: 0.923249\n",
      "[146]\ttraining's binary_logloss: 0.00380054\ttraining's f1: 0.978647\tvalid_1's binary_logloss: 0.0136096\tvalid_1's f1: 0.923417\n",
      "[147]\ttraining's binary_logloss: 0.0037402\ttraining's f1: 0.979119\tvalid_1's binary_logloss: 0.0135716\tvalid_1's f1: 0.923494\n",
      "[148]\ttraining's binary_logloss: 0.00368582\ttraining's f1: 0.979424\tvalid_1's binary_logloss: 0.013529\tvalid_1's f1: 0.923969\n",
      "[149]\ttraining's binary_logloss: 0.00364332\ttraining's f1: 0.979791\tvalid_1's binary_logloss: 0.0135075\tvalid_1's f1: 0.924019\n",
      "[150]\ttraining's binary_logloss: 0.00359119\ttraining's f1: 0.980234\tvalid_1's binary_logloss: 0.0134679\tvalid_1's f1: 0.924536\n",
      "[151]\ttraining's binary_logloss: 0.00353532\ttraining's f1: 0.980556\tvalid_1's binary_logloss: 0.0134238\tvalid_1's f1: 0.925158\n",
      "[152]\ttraining's binary_logloss: 0.00348535\ttraining's f1: 0.980955\tvalid_1's binary_logloss: 0.013403\tvalid_1's f1: 0.925325\n",
      "[153]\ttraining's binary_logloss: 0.00344463\ttraining's f1: 0.981232\tvalid_1's binary_logloss: 0.0133796\tvalid_1's f1: 0.925442\n",
      "[154]\ttraining's binary_logloss: 0.00339979\ttraining's f1: 0.981478\tvalid_1's binary_logloss: 0.0133462\tvalid_1's f1: 0.92561\n",
      "[155]\ttraining's binary_logloss: 0.00335002\ttraining's f1: 0.981894\tvalid_1's binary_logloss: 0.0133155\tvalid_1's f1: 0.925714\n",
      "[156]\ttraining's binary_logloss: 0.00329742\ttraining's f1: 0.982357\tvalid_1's binary_logloss: 0.013292\tvalid_1's f1: 0.926078\n",
      "[157]\ttraining's binary_logloss: 0.00324993\ttraining's f1: 0.982589\tvalid_1's binary_logloss: 0.013257\tvalid_1's f1: 0.926456\n",
      "[158]\ttraining's binary_logloss: 0.00320913\ttraining's f1: 0.982914\tvalid_1's binary_logloss: 0.0132341\tvalid_1's f1: 0.9266\n",
      "[159]\ttraining's binary_logloss: 0.0031647\ttraining's f1: 0.983192\tvalid_1's binary_logloss: 0.0131935\tvalid_1's f1: 0.926952\n",
      "[160]\ttraining's binary_logloss: 0.00312866\ttraining's f1: 0.98358\tvalid_1's binary_logloss: 0.013178\tvalid_1's f1: 0.927135\n",
      "[161]\ttraining's binary_logloss: 0.00308906\ttraining's f1: 0.984155\tvalid_1's binary_logloss: 0.0131627\tvalid_1's f1: 0.92707\n",
      "[162]\ttraining's binary_logloss: 0.0030411\ttraining's f1: 0.984233\tvalid_1's binary_logloss: 0.0131312\tvalid_1's f1: 0.927175\n",
      "[163]\ttraining's binary_logloss: 0.0029933\ttraining's f1: 0.984545\tvalid_1's binary_logloss: 0.0131005\tvalid_1's f1: 0.92728\n",
      "[164]\ttraining's binary_logloss: 0.00295088\ttraining's f1: 0.985012\tvalid_1's binary_logloss: 0.0130675\tvalid_1's f1: 0.927254\n",
      "[165]\ttraining's binary_logloss: 0.00290462\ttraining's f1: 0.985356\tvalid_1's binary_logloss: 0.0130423\tvalid_1's f1: 0.9277\n",
      "[166]\ttraining's binary_logloss: 0.00286088\ttraining's f1: 0.985826\tvalid_1's binary_logloss: 0.0130076\tvalid_1's f1: 0.927963\n",
      "[167]\ttraining's binary_logloss: 0.00282435\ttraining's f1: 0.986233\tvalid_1's binary_logloss: 0.0129848\tvalid_1's f1: 0.928279\n",
      "[168]\ttraining's binary_logloss: 0.00278869\ttraining's f1: 0.986626\tvalid_1's binary_logloss: 0.012965\tvalid_1's f1: 0.928595\n",
      "[169]\ttraining's binary_logloss: 0.00275063\ttraining's f1: 0.986972\tvalid_1's binary_logloss: 0.0129514\tvalid_1's f1: 0.928766\n",
      "[170]\ttraining's binary_logloss: 0.00271162\ttraining's f1: 0.987271\tvalid_1's binary_logloss: 0.0129259\tvalid_1's f1: 0.929003\n",
      "[171]\ttraining's binary_logloss: 0.00267739\ttraining's f1: 0.987618\tvalid_1's binary_logloss: 0.0129187\tvalid_1's f1: 0.929268\n",
      "[172]\ttraining's binary_logloss: 0.00263528\ttraining's f1: 0.988155\tvalid_1's binary_logloss: 0.0128958\tvalid_1's f1: 0.929533\n",
      "[173]\ttraining's binary_logloss: 0.00259832\ttraining's f1: 0.988423\tvalid_1's binary_logloss: 0.012868\tvalid_1's f1: 0.929613\n",
      "[174]\ttraining's binary_logloss: 0.0025604\ttraining's f1: 0.988645\tvalid_1's binary_logloss: 0.0128526\tvalid_1's f1: 0.92968\n",
      "[175]\ttraining's binary_logloss: 0.00252392\ttraining's f1: 0.988978\tvalid_1's binary_logloss: 0.0128245\tvalid_1's f1: 0.929824\n",
      "[176]\ttraining's binary_logloss: 0.0024839\ttraining's f1: 0.989216\tvalid_1's binary_logloss: 0.0127941\tvalid_1's f1: 0.929998\n",
      "[177]\ttraining's binary_logloss: 0.00245553\ttraining's f1: 0.98947\tvalid_1's binary_logloss: 0.0127724\tvalid_1's f1: 0.930065\n",
      "[178]\ttraining's binary_logloss: 0.00242364\ttraining's f1: 0.989725\tvalid_1's binary_logloss: 0.0127531\tvalid_1's f1: 0.930317\n",
      "[179]\ttraining's binary_logloss: 0.00238897\ttraining's f1: 0.990123\tvalid_1's binary_logloss: 0.0127312\tvalid_1's f1: 0.930437\n",
      "[180]\ttraining's binary_logloss: 0.00235673\ttraining's f1: 0.990362\tvalid_1's binary_logloss: 0.0127101\tvalid_1's f1: 0.930424\n",
      "[181]\ttraining's binary_logloss: 0.00232962\ttraining's f1: 0.990537\tvalid_1's binary_logloss: 0.0126981\tvalid_1's f1: 0.930534\n",
      "[182]\ttraining's binary_logloss: 0.00229671\ttraining's f1: 0.990777\tvalid_1's binary_logloss: 0.0126756\tvalid_1's f1: 0.930654\n",
      "[183]\ttraining's binary_logloss: 0.00226519\ttraining's f1: 0.991144\tvalid_1's binary_logloss: 0.0126606\tvalid_1's f1: 0.930601\n",
      "[184]\ttraining's binary_logloss: 0.00223381\ttraining's f1: 0.991401\tvalid_1's binary_logloss: 0.0126424\tvalid_1's f1: 0.930641\n",
      "[185]\ttraining's binary_logloss: 0.00220327\ttraining's f1: 0.991481\tvalid_1's binary_logloss: 0.0126172\tvalid_1's f1: 0.930669\n",
      "[186]\ttraining's binary_logloss: 0.00217332\ttraining's f1: 0.991625\tvalid_1's binary_logloss: 0.0125996\tvalid_1's f1: 0.931002\n",
      "[187]\ttraining's binary_logloss: 0.00214413\ttraining's f1: 0.991865\tvalid_1's binary_logloss: 0.0125837\tvalid_1's f1: 0.93147\n",
      "[188]\ttraining's binary_logloss: 0.00211515\ttraining's f1: 0.991978\tvalid_1's binary_logloss: 0.0125635\tvalid_1's f1: 0.931631\n",
      "[189]\ttraining's binary_logloss: 0.00208587\ttraining's f1: 0.992154\tvalid_1's binary_logloss: 0.0125416\tvalid_1's f1: 0.931538\n",
      "[190]\ttraining's binary_logloss: 0.00205544\ttraining's f1: 0.992379\tvalid_1's binary_logloss: 0.0125305\tvalid_1's f1: 0.931619\n",
      "[191]\ttraining's binary_logloss: 0.00202567\ttraining's f1: 0.992508\tvalid_1's binary_logloss: 0.0125136\tvalid_1's f1: 0.931711\n",
      "[192]\ttraining's binary_logloss: 0.00200285\ttraining's f1: 0.992717\tvalid_1's binary_logloss: 0.0124995\tvalid_1's f1: 0.931792\n",
      "[193]\ttraining's binary_logloss: 0.00197525\ttraining's f1: 0.992975\tvalid_1's binary_logloss: 0.0124966\tvalid_1's f1: 0.931792\n",
      "[194]\ttraining's binary_logloss: 0.00194611\ttraining's f1: 0.993168\tvalid_1's binary_logloss: 0.0124885\tvalid_1's f1: 0.931888\n",
      "[195]\ttraining's binary_logloss: 0.00192127\ttraining's f1: 0.993313\tvalid_1's binary_logloss: 0.0124704\tvalid_1's f1: 0.932037\n",
      "[196]\ttraining's binary_logloss: 0.00189796\ttraining's f1: 0.993523\tvalid_1's binary_logloss: 0.0124554\tvalid_1's f1: 0.932182\n",
      "[197]\ttraining's binary_logloss: 0.00187291\ttraining's f1: 0.993604\tvalid_1's binary_logloss: 0.0124507\tvalid_1's f1: 0.932024\n",
      "[198]\ttraining's binary_logloss: 0.00185062\ttraining's f1: 0.99375\tvalid_1's binary_logloss: 0.0124351\tvalid_1's f1: 0.932601\n",
      "[199]\ttraining's binary_logloss: 0.00182698\ttraining's f1: 0.993847\tvalid_1's binary_logloss: 0.0124222\tvalid_1's f1: 0.932294\n",
      "[200]\ttraining's binary_logloss: 0.00179933\ttraining's f1: 0.994089\tvalid_1's binary_logloss: 0.0123963\tvalid_1's f1: 0.932282\n",
      "[201]\ttraining's binary_logloss: 0.00177476\ttraining's f1: 0.994348\tvalid_1's binary_logloss: 0.0123884\tvalid_1's f1: 0.932391\n",
      "[202]\ttraining's binary_logloss: 0.00175253\ttraining's f1: 0.994494\tvalid_1's binary_logloss: 0.0123734\tvalid_1's f1: 0.932568\n",
      "[203]\ttraining's binary_logloss: 0.00173058\ttraining's f1: 0.994656\tvalid_1's binary_logloss: 0.0123562\tvalid_1's f1: 0.932621\n",
      "[204]\ttraining's binary_logloss: 0.00171095\ttraining's f1: 0.99477\tvalid_1's binary_logloss: 0.012348\tvalid_1's f1: 0.932754\n",
      "[205]\ttraining's binary_logloss: 0.00168773\ttraining's f1: 0.994997\tvalid_1's binary_logloss: 0.0123384\tvalid_1's f1: 0.932835\n",
      "[206]\ttraining's binary_logloss: 0.00166398\ttraining's f1: 0.995111\tvalid_1's binary_logloss: 0.0123308\tvalid_1's f1: 0.933009\n",
      "[207]\ttraining's binary_logloss: 0.00164318\ttraining's f1: 0.995322\tvalid_1's binary_logloss: 0.0123149\tvalid_1's f1: 0.933025\n",
      "[208]\ttraining's binary_logloss: 0.00162381\ttraining's f1: 0.99542\tvalid_1's binary_logloss: 0.0123005\tvalid_1's f1: 0.933001\n",
      "[209]\ttraining's binary_logloss: 0.00159966\ttraining's f1: 0.995501\tvalid_1's binary_logloss: 0.0122851\tvalid_1's f1: 0.93307\n",
      "[210]\ttraining's binary_logloss: 0.00157807\ttraining's f1: 0.99568\tvalid_1's binary_logloss: 0.0122788\tvalid_1's f1: 0.933086\n",
      "[211]\ttraining's binary_logloss: 0.00155642\ttraining's f1: 0.995811\tvalid_1's binary_logloss: 0.0122703\tvalid_1's f1: 0.933301\n",
      "[212]\ttraining's binary_logloss: 0.00153778\ttraining's f1: 0.995892\tvalid_1's binary_logloss: 0.0122514\tvalid_1's f1: 0.933196\n",
      "[213]\ttraining's binary_logloss: 0.00151888\ttraining's f1: 0.996039\tvalid_1's binary_logloss: 0.0122528\tvalid_1's f1: 0.933277\n",
      "[214]\ttraining's binary_logloss: 0.00149955\ttraining's f1: 0.99612\tvalid_1's binary_logloss: 0.0122407\tvalid_1's f1: 0.933423\n",
      "[215]\ttraining's binary_logloss: 0.00148244\ttraining's f1: 0.996202\tvalid_1's binary_logloss: 0.0122265\tvalid_1's f1: 0.933655\n",
      "[216]\ttraining's binary_logloss: 0.00146233\ttraining's f1: 0.996218\tvalid_1's binary_logloss: 0.0122137\tvalid_1's f1: 0.933777\n",
      "[217]\ttraining's binary_logloss: 0.00144357\ttraining's f1: 0.996365\tvalid_1's binary_logloss: 0.0122046\tvalid_1's f1: 0.933968\n",
      "[218]\ttraining's binary_logloss: 0.00142603\ttraining's f1: 0.996431\tvalid_1's binary_logloss: 0.0121909\tvalid_1's f1: 0.934004\n",
      "[219]\ttraining's binary_logloss: 0.0014076\ttraining's f1: 0.996561\tvalid_1's binary_logloss: 0.0121769\tvalid_1's f1: 0.934196\n",
      "[220]\ttraining's binary_logloss: 0.00139228\ttraining's f1: 0.996643\tvalid_1's binary_logloss: 0.0121635\tvalid_1's f1: 0.934212\n",
      "[221]\ttraining's binary_logloss: 0.0013736\ttraining's f1: 0.996725\tvalid_1's binary_logloss: 0.0121538\tvalid_1's f1: 0.934311\n",
      "[222]\ttraining's binary_logloss: 0.0013551\ttraining's f1: 0.996856\tvalid_1's binary_logloss: 0.0121491\tvalid_1's f1: 0.934136\n",
      "[223]\ttraining's binary_logloss: 0.0013352\ttraining's f1: 0.996954\tvalid_1's binary_logloss: 0.0121404\tvalid_1's f1: 0.934544\n",
      "[224]\ttraining's binary_logloss: 0.0013188\ttraining's f1: 0.997019\tvalid_1's binary_logloss: 0.0121353\tvalid_1's f1: 0.934532\n",
      "[225]\ttraining's binary_logloss: 0.00130272\ttraining's f1: 0.997118\tvalid_1's binary_logloss: 0.012127\tvalid_1's f1: 0.93459\n",
      "[226]\ttraining's binary_logloss: 0.00128844\ttraining's f1: 0.997199\tvalid_1's binary_logloss: 0.0121168\tvalid_1's f1: 0.934736\n",
      "[227]\ttraining's binary_logloss: 0.00127083\ttraining's f1: 0.997232\tvalid_1's binary_logloss: 0.0121057\tvalid_1's f1: 0.934835\n",
      "[228]\ttraining's binary_logloss: 0.00125723\ttraining's f1: 0.997331\tvalid_1's binary_logloss: 0.0120991\tvalid_1's f1: 0.934765\n",
      "[229]\ttraining's binary_logloss: 0.00124068\ttraining's f1: 0.997429\tvalid_1's binary_logloss: 0.0120863\tvalid_1's f1: 0.934818\n",
      "[230]\ttraining's binary_logloss: 0.00122514\ttraining's f1: 0.997577\tvalid_1's binary_logloss: 0.0120812\tvalid_1's f1: 0.934736\n",
      "[231]\ttraining's binary_logloss: 0.00120966\ttraining's f1: 0.997626\tvalid_1's binary_logloss: 0.0120731\tvalid_1's f1: 0.934578\n",
      "[232]\ttraining's binary_logloss: 0.00119707\ttraining's f1: 0.997823\tvalid_1's binary_logloss: 0.012067\tvalid_1's f1: 0.934794\n",
      "[233]\ttraining's binary_logloss: 0.00118259\ttraining's f1: 0.997954\tvalid_1's binary_logloss: 0.0120619\tvalid_1's f1: 0.934742\n",
      "[234]\ttraining's binary_logloss: 0.00116747\ttraining's f1: 0.997954\tvalid_1's binary_logloss: 0.0120548\tvalid_1's f1: 0.93511\n",
      "[235]\ttraining's binary_logloss: 0.00115238\ttraining's f1: 0.997971\tvalid_1's binary_logloss: 0.0120442\tvalid_1's f1: 0.935245\n",
      "[236]\ttraining's binary_logloss: 0.00113817\ttraining's f1: 0.998053\tvalid_1's binary_logloss: 0.0120378\tvalid_1's f1: 0.935221\n",
      "[237]\ttraining's binary_logloss: 0.00112474\ttraining's f1: 0.998135\tvalid_1's binary_logloss: 0.0120271\tvalid_1's f1: 0.935303\n",
      "[238]\ttraining's binary_logloss: 0.00110971\ttraining's f1: 0.998267\tvalid_1's binary_logloss: 0.0120284\tvalid_1's f1: 0.935268\n",
      "[239]\ttraining's binary_logloss: 0.00109534\ttraining's f1: 0.998382\tvalid_1's binary_logloss: 0.0120193\tvalid_1's f1: 0.935543\n",
      "[240]\ttraining's binary_logloss: 0.00108397\ttraining's f1: 0.998431\tvalid_1's binary_logloss: 0.0120087\tvalid_1's f1: 0.935532\n",
      "[241]\ttraining's binary_logloss: 0.0010693\ttraining's f1: 0.998448\tvalid_1's binary_logloss: 0.0119933\tvalid_1's f1: 0.935725\n",
      "[242]\ttraining's binary_logloss: 0.00105668\ttraining's f1: 0.998448\tvalid_1's binary_logloss: 0.0119836\tvalid_1's f1: 0.935673\n",
      "[243]\ttraining's binary_logloss: 0.00104345\ttraining's f1: 0.99853\tvalid_1's binary_logloss: 0.0119797\tvalid_1's f1: 0.935808\n",
      "[244]\ttraining's binary_logloss: 0.00102888\ttraining's f1: 0.998546\tvalid_1's binary_logloss: 0.0119653\tvalid_1's f1: 0.936149\n",
      "[245]\ttraining's binary_logloss: 0.00101584\ttraining's f1: 0.998596\tvalid_1's binary_logloss: 0.0119568\tvalid_1's f1: 0.935843\n",
      "[246]\ttraining's binary_logloss: 0.00100401\ttraining's f1: 0.998612\tvalid_1's binary_logloss: 0.0119495\tvalid_1's f1: 0.936073\n",
      "[247]\ttraining's binary_logloss: 0.000992047\ttraining's f1: 0.998662\tvalid_1's binary_logloss: 0.0119453\tvalid_1's f1: 0.936084\n",
      "[248]\ttraining's binary_logloss: 0.000980579\ttraining's f1: 0.998711\tvalid_1's binary_logloss: 0.0119422\tvalid_1's f1: 0.936267\n",
      "[249]\ttraining's binary_logloss: 0.000968504\ttraining's f1: 0.998728\tvalid_1's binary_logloss: 0.0119311\tvalid_1's f1: 0.93635\n",
      "[250]\ttraining's binary_logloss: 0.000955738\ttraining's f1: 0.998777\tvalid_1's binary_logloss: 0.0119169\tvalid_1's f1: 0.936556\n",
      "[251]\ttraining's binary_logloss: 0.000943802\ttraining's f1: 0.998777\tvalid_1's binary_logloss: 0.0119051\tvalid_1's f1: 0.936881\n",
      "[252]\ttraining's binary_logloss: 0.000934523\ttraining's f1: 0.99881\tvalid_1's binary_logloss: 0.0119051\tvalid_1's f1: 0.936745\n",
      "[253]\ttraining's binary_logloss: 0.000922564\ttraining's f1: 0.998843\tvalid_1's binary_logloss: 0.0118989\tvalid_1's f1: 0.936763\n",
      "[254]\ttraining's binary_logloss: 0.000911361\ttraining's f1: 0.998876\tvalid_1's binary_logloss: 0.0118939\tvalid_1's f1: 0.936722\n",
      "[255]\ttraining's binary_logloss: 0.000899341\ttraining's f1: 0.998926\tvalid_1's binary_logloss: 0.01189\tvalid_1's f1: 0.93694\n",
      "[256]\ttraining's binary_logloss: 0.000888647\ttraining's f1: 0.998942\tvalid_1's binary_logloss: 0.0118861\tvalid_1's f1: 0.93694\n",
      "[257]\ttraining's binary_logloss: 0.000878108\ttraining's f1: 0.998992\tvalid_1's binary_logloss: 0.0118826\tvalid_1's f1: 0.936846\n",
      "[258]\ttraining's binary_logloss: 0.000868051\ttraining's f1: 0.999008\tvalid_1's binary_logloss: 0.011877\tvalid_1's f1: 0.936751\n",
      "[259]\ttraining's binary_logloss: 0.000858265\ttraining's f1: 0.999041\tvalid_1's binary_logloss: 0.01188\tvalid_1's f1: 0.936988\n",
      "[260]\ttraining's binary_logloss: 0.00084849\ttraining's f1: 0.999074\tvalid_1's binary_logloss: 0.0118789\tvalid_1's f1: 0.937094\n",
      "[261]\ttraining's binary_logloss: 0.000839783\ttraining's f1: 0.999091\tvalid_1's binary_logloss: 0.0118725\tvalid_1's f1: 0.936947\n",
      "[262]\ttraining's binary_logloss: 0.000830404\ttraining's f1: 0.999124\tvalid_1's binary_logloss: 0.0118737\tvalid_1's f1: 0.937\n",
      "[263]\ttraining's binary_logloss: 0.000819445\ttraining's f1: 0.999157\tvalid_1's binary_logloss: 0.0118703\tvalid_1's f1: 0.937124\n",
      "[264]\ttraining's binary_logloss: 0.000810367\ttraining's f1: 0.999173\tvalid_1's binary_logloss: 0.0118656\tvalid_1's f1: 0.937301\n",
      "[265]\ttraining's binary_logloss: 0.000801223\ttraining's f1: 0.999239\tvalid_1's binary_logloss: 0.0118573\tvalid_1's f1: 0.937698\n",
      "[266]\ttraining's binary_logloss: 0.000792727\ttraining's f1: 0.999289\tvalid_1's binary_logloss: 0.0118511\tvalid_1's f1: 0.937917\n",
      "[267]\ttraining's binary_logloss: 0.000783065\ttraining's f1: 0.999322\tvalid_1's binary_logloss: 0.0118513\tvalid_1's f1: 0.937686\n",
      "[268]\ttraining's binary_logloss: 0.000774421\ttraining's f1: 0.999322\tvalid_1's binary_logloss: 0.0118454\tvalid_1's f1: 0.937663\n",
      "[269]\ttraining's binary_logloss: 0.000765015\ttraining's f1: 0.999338\tvalid_1's binary_logloss: 0.0118413\tvalid_1's f1: 0.937894\n",
      "[270]\ttraining's binary_logloss: 0.000757186\ttraining's f1: 0.999355\tvalid_1's binary_logloss: 0.0118381\tvalid_1's f1: 0.937966\n",
      "[271]\ttraining's binary_logloss: 0.000749166\ttraining's f1: 0.999388\tvalid_1's binary_logloss: 0.0118349\tvalid_1's f1: 0.937587\n",
      "[272]\ttraining's binary_logloss: 0.000740856\ttraining's f1: 0.999371\tvalid_1's binary_logloss: 0.0118291\tvalid_1's f1: 0.937599\n",
      "[273]\ttraining's binary_logloss: 0.00073288\ttraining's f1: 0.999371\tvalid_1's binary_logloss: 0.0118294\tvalid_1's f1: 0.937534\n",
      "[274]\ttraining's binary_logloss: 0.000724185\ttraining's f1: 0.999371\tvalid_1's binary_logloss: 0.0118278\tvalid_1's f1: 0.937943\n",
      "[275]\ttraining's binary_logloss: 0.000716284\ttraining's f1: 0.999404\tvalid_1's binary_logloss: 0.0118204\tvalid_1's f1: 0.937932\n",
      "[276]\ttraining's binary_logloss: 0.000707553\ttraining's f1: 0.999404\tvalid_1's binary_logloss: 0.0118163\tvalid_1's f1: 0.937731\n",
      "[277]\ttraining's binary_logloss: 0.000699726\ttraining's f1: 0.999437\tvalid_1's binary_logloss: 0.0118158\tvalid_1's f1: 0.937659\n",
      "[278]\ttraining's binary_logloss: 0.000691315\ttraining's f1: 0.99947\tvalid_1's binary_logloss: 0.011814\tvalid_1's f1: 0.937856\n",
      "[279]\ttraining's binary_logloss: 0.000682573\ttraining's f1: 0.999504\tvalid_1's binary_logloss: 0.0118069\tvalid_1's f1: 0.937981\n",
      "[280]\ttraining's binary_logloss: 0.000675359\ttraining's f1: 0.999504\tvalid_1's binary_logloss: 0.0118048\tvalid_1's f1: 0.937927\n",
      "[281]\ttraining's binary_logloss: 0.000668226\ttraining's f1: 0.99952\tvalid_1's binary_logloss: 0.0118018\tvalid_1's f1: 0.938117\n",
      "[282]\ttraining's binary_logloss: 0.000661042\ttraining's f1: 0.999537\tvalid_1's binary_logloss: 0.0118045\tvalid_1's f1: 0.938189\n",
      "[283]\ttraining's binary_logloss: 0.000653109\ttraining's f1: 0.999537\tvalid_1's binary_logloss: 0.0117974\tvalid_1's f1: 0.938189\n",
      "[284]\ttraining's binary_logloss: 0.000646162\ttraining's f1: 0.999586\tvalid_1's binary_logloss: 0.0117918\tvalid_1's f1: 0.938177\n",
      "[285]\ttraining's binary_logloss: 0.000639654\ttraining's f1: 0.999636\tvalid_1's binary_logloss: 0.0117881\tvalid_1's f1: 0.938344\n",
      "[286]\ttraining's binary_logloss: 0.000632464\ttraining's f1: 0.999636\tvalid_1's binary_logloss: 0.011782\tvalid_1's f1: 0.938481\n",
      "[287]\ttraining's binary_logloss: 0.000625037\ttraining's f1: 0.999636\tvalid_1's binary_logloss: 0.0117718\tvalid_1's f1: 0.938522\n",
      "[288]\ttraining's binary_logloss: 0.00061802\ttraining's f1: 0.999652\tvalid_1's binary_logloss: 0.0117665\tvalid_1's f1: 0.938564\n",
      "[289]\ttraining's binary_logloss: 0.000612064\ttraining's f1: 0.999669\tvalid_1's binary_logloss: 0.011766\tvalid_1's f1: 0.938534\n",
      "[290]\ttraining's binary_logloss: 0.000605377\ttraining's f1: 0.999685\tvalid_1's binary_logloss: 0.0117639\tvalid_1's f1: 0.938492\n",
      "[291]\ttraining's binary_logloss: 0.000598926\ttraining's f1: 0.999685\tvalid_1's binary_logloss: 0.0117559\tvalid_1's f1: 0.938553\n",
      "[292]\ttraining's binary_logloss: 0.000592694\ttraining's f1: 0.999685\tvalid_1's binary_logloss: 0.0117564\tvalid_1's f1: 0.93872\n",
      "[293]\ttraining's binary_logloss: 0.000585725\ttraining's f1: 0.999735\tvalid_1's binary_logloss: 0.0117497\tvalid_1's f1: 0.938762\n",
      "[294]\ttraining's binary_logloss: 0.000579118\ttraining's f1: 0.999719\tvalid_1's binary_logloss: 0.0117454\tvalid_1's f1: 0.939013\n",
      "[295]\ttraining's binary_logloss: 0.000572624\ttraining's f1: 0.999719\tvalid_1's binary_logloss: 0.0117429\tvalid_1's f1: 0.938823\n",
      "[296]\ttraining's binary_logloss: 0.000566826\ttraining's f1: 0.999752\tvalid_1's binary_logloss: 0.0117391\tvalid_1's f1: 0.938853\n",
      "[297]\ttraining's binary_logloss: 0.000560863\ttraining's f1: 0.999752\tvalid_1's binary_logloss: 0.0117385\tvalid_1's f1: 0.938716\n",
      "[298]\ttraining's binary_logloss: 0.000554399\ttraining's f1: 0.999768\tvalid_1's binary_logloss: 0.011728\tvalid_1's f1: 0.938842\n",
      "[299]\ttraining's binary_logloss: 0.000548237\ttraining's f1: 0.999768\tvalid_1's binary_logloss: 0.0117232\tvalid_1's f1: 0.939032\n",
      "[300]\ttraining's binary_logloss: 0.000542752\ttraining's f1: 0.999768\tvalid_1's binary_logloss: 0.0117232\tvalid_1's f1: 0.93899\n",
      "[301]\ttraining's binary_logloss: 0.000536951\ttraining's f1: 0.999768\tvalid_1's binary_logloss: 0.0117224\tvalid_1's f1: 0.939138\n",
      "[302]\ttraining's binary_logloss: 0.000531979\ttraining's f1: 0.999785\tvalid_1's binary_logloss: 0.0117258\tvalid_1's f1: 0.939157\n",
      "[303]\ttraining's binary_logloss: 0.000526455\ttraining's f1: 0.999801\tvalid_1's binary_logloss: 0.0117278\tvalid_1's f1: 0.93923\n",
      "[304]\ttraining's binary_logloss: 0.000520999\ttraining's f1: 0.999818\tvalid_1's binary_logloss: 0.0117253\tvalid_1's f1: 0.939188\n",
      "[305]\ttraining's binary_logloss: 0.000515884\ttraining's f1: 0.999834\tvalid_1's binary_logloss: 0.0117245\tvalid_1's f1: 0.939135\n",
      "[306]\ttraining's binary_logloss: 0.000510677\ttraining's f1: 0.999834\tvalid_1's binary_logloss: 0.011728\tvalid_1's f1: 0.939261\n",
      "[307]\ttraining's binary_logloss: 0.000505483\ttraining's f1: 0.999834\tvalid_1's binary_logloss: 0.0117252\tvalid_1's f1: 0.939154\n",
      "[308]\ttraining's binary_logloss: 0.000500316\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117228\tvalid_1's f1: 0.939333\n",
      "[309]\ttraining's binary_logloss: 0.000495184\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.011725\tvalid_1's f1: 0.939188\n",
      "[310]\ttraining's binary_logloss: 0.000490193\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117168\tvalid_1's f1: 0.939272\n",
      "[311]\ttraining's binary_logloss: 0.000485113\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117112\tvalid_1's f1: 0.939577\n",
      "[312]\ttraining's binary_logloss: 0.000480169\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117094\tvalid_1's f1: 0.93949\n",
      "[313]\ttraining's binary_logloss: 0.000475184\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117084\tvalid_1's f1: 0.93968\n",
      "[314]\ttraining's binary_logloss: 0.000470669\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.011709\tvalid_1's f1: 0.939649\n",
      "[315]\ttraining's binary_logloss: 0.000467106\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117105\tvalid_1's f1: 0.939955\n",
      "[316]\ttraining's binary_logloss: 0.000462523\ttraining's f1: 0.999851\tvalid_1's binary_logloss: 0.0117076\tvalid_1's f1: 0.940134\n",
      "[317]\ttraining's binary_logloss: 0.000458102\ttraining's f1: 0.999868\tvalid_1's binary_logloss: 0.0117034\tvalid_1's f1: 0.940112\n",
      "[318]\ttraining's binary_logloss: 0.000454077\ttraining's f1: 0.999868\tvalid_1's binary_logloss: 0.0117086\tvalid_1's f1: 0.939986\n",
      "[319]\ttraining's binary_logloss: 0.000449731\ttraining's f1: 0.999868\tvalid_1's binary_logloss: 0.011706\tvalid_1's f1: 0.939963\n",
      "[320]\ttraining's binary_logloss: 0.000445302\ttraining's f1: 0.999868\tvalid_1's binary_logloss: 0.0117079\tvalid_1's f1: 0.94012\n",
      "[321]\ttraining's binary_logloss: 0.000441118\ttraining's f1: 0.999868\tvalid_1's binary_logloss: 0.0117101\tvalid_1's f1: 0.940047\n",
      "[322]\ttraining's binary_logloss: 0.00043665\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0117015\tvalid_1's f1: 0.940078\n",
      "[323]\ttraining's binary_logloss: 0.000432567\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0117028\tvalid_1's f1: 0.940311\n",
      "[324]\ttraining's binary_logloss: 0.000428246\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.011697\tvalid_1's f1: 0.940078\n",
      "[325]\ttraining's binary_logloss: 0.000424039\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116967\tvalid_1's f1: 0.940373\n",
      "[326]\ttraining's binary_logloss: 0.000420243\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116964\tvalid_1's f1: 0.940278\n",
      "[327]\ttraining's binary_logloss: 0.000416024\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116957\tvalid_1's f1: 0.940278\n",
      "[328]\ttraining's binary_logloss: 0.000412542\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116982\tvalid_1's f1: 0.940362\n",
      "[329]\ttraining's binary_logloss: 0.000407885\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116949\tvalid_1's f1: 0.940362\n",
      "[330]\ttraining's binary_logloss: 0.000404391\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116984\tvalid_1's f1: 0.940489\n",
      "[331]\ttraining's binary_logloss: 0.000400647\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0117026\tvalid_1's f1: 0.940637\n",
      "[332]\ttraining's binary_logloss: 0.000396833\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116933\tvalid_1's f1: 0.940722\n",
      "[333]\ttraining's binary_logloss: 0.000393346\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.011689\tvalid_1's f1: 0.940457\n",
      "[334]\ttraining's binary_logloss: 0.000389774\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116875\tvalid_1's f1: 0.940595\n",
      "[335]\ttraining's binary_logloss: 0.000386505\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116912\tvalid_1's f1: 0.940648\n",
      "[336]\ttraining's binary_logloss: 0.000382707\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116875\tvalid_1's f1: 0.94069\n",
      "[337]\ttraining's binary_logloss: 0.000379385\ttraining's f1: 0.999884\tvalid_1's binary_logloss: 0.0116894\tvalid_1's f1: 0.940722\n",
      "[338]\ttraining's binary_logloss: 0.000376016\ttraining's f1: 0.999901\tvalid_1's binary_logloss: 0.0116882\tvalid_1's f1: 0.940806\n",
      "[339]\ttraining's binary_logloss: 0.000372708\ttraining's f1: 0.999934\tvalid_1's binary_logloss: 0.0116883\tvalid_1's f1: 0.940848\n",
      "[340]\ttraining's binary_logloss: 0.000369775\ttraining's f1: 0.99995\tvalid_1's binary_logloss: 0.0116932\tvalid_1's f1: 0.941028\n",
      "[341]\ttraining's binary_logloss: 0.000366234\ttraining's f1: 0.99995\tvalid_1's binary_logloss: 0.0116909\tvalid_1's f1: 0.940942\n",
      "[342]\ttraining's binary_logloss: 0.000362844\ttraining's f1: 0.999934\tvalid_1's binary_logloss: 0.0116924\tvalid_1's f1: 0.9409\n",
      "[343]\ttraining's binary_logloss: 0.000360043\ttraining's f1: 0.999934\tvalid_1's binary_logloss: 0.0116887\tvalid_1's f1: 0.941016\n",
      "[344]\ttraining's binary_logloss: 0.00035682\ttraining's f1: 0.99995\tvalid_1's binary_logloss: 0.0116833\tvalid_1's f1: 0.94092\n",
      "[345]\ttraining's binary_logloss: 0.000353536\ttraining's f1: 0.99995\tvalid_1's binary_logloss: 0.0116768\tvalid_1's f1: 0.940973\n",
      "[346]\ttraining's binary_logloss: 0.000350378\ttraining's f1: 0.999967\tvalid_1's binary_logloss: 0.0116781\tvalid_1's f1: 0.940931\n",
      "[347]\ttraining's binary_logloss: 0.000346744\ttraining's f1: 0.999967\tvalid_1's binary_logloss: 0.0116774\tvalid_1's f1: 0.941047\n",
      "[348]\ttraining's binary_logloss: 0.000343379\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116804\tvalid_1's f1: 0.94092\n",
      "[349]\ttraining's binary_logloss: 0.000340258\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116784\tvalid_1's f1: 0.940856\n",
      "[350]\ttraining's binary_logloss: 0.000337082\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116799\tvalid_1's f1: 0.940994\n",
      "[351]\ttraining's binary_logloss: 0.000334228\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.011681\tvalid_1's f1: 0.940845\n",
      "[352]\ttraining's binary_logloss: 0.000330851\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116796\tvalid_1's f1: 0.940856\n",
      "[353]\ttraining's binary_logloss: 0.000328213\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116845\tvalid_1's f1: 0.941089\n",
      "[354]\ttraining's binary_logloss: 0.000325469\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116863\tvalid_1's f1: 0.941036\n",
      "[355]\ttraining's binary_logloss: 0.000322818\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116878\tvalid_1's f1: 0.941036\n",
      "[356]\ttraining's binary_logloss: 0.000319958\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116927\tvalid_1's f1: 0.941089\n",
      "[357]\ttraining's binary_logloss: 0.000317199\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.011692\tvalid_1's f1: 0.941036\n",
      "[358]\ttraining's binary_logloss: 0.000314769\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116967\tvalid_1's f1: 0.941036\n",
      "[359]\ttraining's binary_logloss: 0.000311982\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.0116992\tvalid_1's f1: 0.940983\n",
      "[360]\ttraining's binary_logloss: 0.000309608\ttraining's f1: 0.999983\tvalid_1's binary_logloss: 0.011701\tvalid_1's f1: 0.940994\n",
      "[361]\ttraining's binary_logloss: 0.000306848\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117019\tvalid_1's f1: 0.940983\n",
      "[362]\ttraining's binary_logloss: 0.00030446\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117063\tvalid_1's f1: 0.940972\n",
      "[363]\ttraining's binary_logloss: 0.000301748\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117104\tvalid_1's f1: 0.940992\n",
      "[364]\ttraining's binary_logloss: 0.000299272\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117143\tvalid_1's f1: 0.941056\n",
      "[365]\ttraining's binary_logloss: 0.000296842\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117123\tvalid_1's f1: 0.941088\n",
      "[366]\ttraining's binary_logloss: 0.00029396\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117115\tvalid_1's f1: 0.940992\n",
      "[367]\ttraining's binary_logloss: 0.000291615\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117133\tvalid_1's f1: 0.94113\n",
      "[368]\ttraining's binary_logloss: 0.000289006\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117109\tvalid_1's f1: 0.941119\n",
      "[369]\ttraining's binary_logloss: 0.000286694\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117118\tvalid_1's f1: 0.941246\n",
      "[370]\ttraining's binary_logloss: 0.000284372\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117117\tvalid_1's f1: 0.941161\n",
      "[371]\ttraining's binary_logloss: 0.000281855\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117127\tvalid_1's f1: 0.941161\n",
      "[372]\ttraining's binary_logloss: 0.000279249\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117104\tvalid_1's f1: 0.94148\n",
      "[373]\ttraining's binary_logloss: 0.000276843\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117152\tvalid_1's f1: 0.941491\n",
      "[374]\ttraining's binary_logloss: 0.000274703\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117207\tvalid_1's f1: 0.941469\n",
      "[375]\ttraining's binary_logloss: 0.000272099\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117182\tvalid_1's f1: 0.941405\n",
      "[376]\ttraining's binary_logloss: 0.000269886\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117235\tvalid_1's f1: 0.941447\n",
      "[377]\ttraining's binary_logloss: 0.000267929\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117243\tvalid_1's f1: 0.941554\n",
      "[378]\ttraining's binary_logloss: 0.000265789\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117243\tvalid_1's f1: 0.941554\n",
      "[379]\ttraining's binary_logloss: 0.000263572\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117232\tvalid_1's f1: 0.941543\n",
      "[380]\ttraining's binary_logloss: 0.000261618\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117253\tvalid_1's f1: 0.941628\n",
      "[381]\ttraining's binary_logloss: 0.000259667\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117261\tvalid_1's f1: 0.941809\n",
      "[382]\ttraining's binary_logloss: 0.000257732\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117257\tvalid_1's f1: 0.941628\n",
      "[383]\ttraining's binary_logloss: 0.000255711\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117255\tvalid_1's f1: 0.941798\n",
      "[384]\ttraining's binary_logloss: 0.000254024\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117262\tvalid_1's f1: 0.941787\n",
      "[385]\ttraining's binary_logloss: 0.000252167\ttraining's f1: 1\tvalid_1's binary_logloss: 0.011726\tvalid_1's f1: 0.941925\n",
      "[386]\ttraining's binary_logloss: 0.000250057\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117212\tvalid_1's f1: 0.942138\n",
      "[387]\ttraining's binary_logloss: 0.000247996\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117238\tvalid_1's f1: 0.942138\n",
      "[388]\ttraining's binary_logloss: 0.000246154\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117244\tvalid_1's f1: 0.942149\n",
      "[389]\ttraining's binary_logloss: 0.000244349\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117241\tvalid_1's f1: 0.942287\n",
      "[390]\ttraining's binary_logloss: 0.000242386\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117238\tvalid_1's f1: 0.942149\n",
      "[391]\ttraining's binary_logloss: 0.000240626\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117306\tvalid_1's f1: 0.942149\n",
      "[392]\ttraining's binary_logloss: 0.000238693\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117286\tvalid_1's f1: 0.942372\n",
      "[393]\ttraining's binary_logloss: 0.000236871\ttraining's f1: 1\tvalid_1's binary_logloss: 0.011733\tvalid_1's f1: 0.942426\n",
      "[394]\ttraining's binary_logloss: 0.000234961\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117347\tvalid_1's f1: 0.942468\n",
      "[395]\ttraining's binary_logloss: 0.000233165\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117326\tvalid_1's f1: 0.94267\n",
      "[396]\ttraining's binary_logloss: 0.00023123\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117303\tvalid_1's f1: 0.942585\n",
      "[397]\ttraining's binary_logloss: 0.000229457\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117279\tvalid_1's f1: 0.942511\n",
      "[398]\ttraining's binary_logloss: 0.000227451\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117307\tvalid_1's f1: 0.94266\n",
      "[399]\ttraining's binary_logloss: 0.000225745\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117336\tvalid_1's f1: 0.942766\n",
      "[400]\ttraining's binary_logloss: 0.00022417\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117351\tvalid_1's f1: 0.942852\n",
      "[401]\ttraining's binary_logloss: 0.000222514\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117392\tvalid_1's f1: 0.942649\n",
      "[402]\ttraining's binary_logloss: 0.000221203\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117387\tvalid_1's f1: 0.942585\n",
      "[403]\ttraining's binary_logloss: 0.000219743\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117439\tvalid_1's f1: 0.94251\n",
      "[404]\ttraining's binary_logloss: 0.000217992\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117446\tvalid_1's f1: 0.942446\n",
      "[405]\ttraining's binary_logloss: 0.000216523\ttraining's f1: 1\tvalid_1's binary_logloss: 0.011747\tvalid_1's f1: 0.942713\n",
      "[406]\ttraining's binary_logloss: 0.000214528\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117423\tvalid_1's f1: 0.942894\n",
      "[407]\ttraining's binary_logloss: 0.000213091\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117416\tvalid_1's f1: 0.94282\n",
      "[408]\ttraining's binary_logloss: 0.00021143\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117442\tvalid_1's f1: 0.942681\n",
      "[409]\ttraining's binary_logloss: 0.000210256\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117452\tvalid_1's f1: 0.942681\n",
      "[410]\ttraining's binary_logloss: 0.000208952\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117507\tvalid_1's f1: 0.942905\n",
      "[411]\ttraining's binary_logloss: 0.000207377\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117511\tvalid_1's f1: 0.942766\n",
      "[412]\ttraining's binary_logloss: 0.000206039\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117513\tvalid_1's f1: 0.942852\n",
      "[413]\ttraining's binary_logloss: 0.000204545\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117546\tvalid_1's f1: 0.942873\n",
      "[414]\ttraining's binary_logloss: 0.000203208\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117617\tvalid_1's f1: 0.94266\n",
      "[415]\ttraining's binary_logloss: 0.000201863\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117639\tvalid_1's f1: 0.942713\n",
      "[416]\ttraining's binary_logloss: 0.000200377\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117673\tvalid_1's f1: 0.94266\n",
      "[417]\ttraining's binary_logloss: 0.000198638\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117649\tvalid_1's f1: 0.942745\n",
      "[418]\ttraining's binary_logloss: 0.000197349\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117701\tvalid_1's f1: 0.942841\n",
      "[419]\ttraining's binary_logloss: 0.000195989\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117716\tvalid_1's f1: 0.942969\n",
      "[420]\ttraining's binary_logloss: 0.000194779\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117731\tvalid_1's f1: 0.943108\n",
      "[421]\ttraining's binary_logloss: 0.000193715\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117798\tvalid_1's f1: 0.943065\n",
      "[422]\ttraining's binary_logloss: 0.00019221\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117802\tvalid_1's f1: 0.94298\n",
      "[423]\ttraining's binary_logloss: 0.000190913\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117818\tvalid_1's f1: 0.943193\n",
      "[424]\ttraining's binary_logloss: 0.000189796\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117823\tvalid_1's f1: 0.943012\n",
      "[425]\ttraining's binary_logloss: 0.000188535\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117856\tvalid_1's f1: 0.943001\n",
      "[426]\ttraining's binary_logloss: 0.000187302\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117892\tvalid_1's f1: 0.942958\n",
      "[427]\ttraining's binary_logloss: 0.000186088\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117934\tvalid_1's f1: 0.942916\n",
      "[428]\ttraining's binary_logloss: 0.000184751\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117911\tvalid_1's f1: 0.942916\n",
      "[429]\ttraining's binary_logloss: 0.000183618\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117942\tvalid_1's f1: 0.942958\n",
      "[430]\ttraining's binary_logloss: 0.000182616\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117949\tvalid_1's f1: 0.942958\n",
      "[431]\ttraining's binary_logloss: 0.000181516\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0117956\tvalid_1's f1: 0.94283\n",
      "[432]\ttraining's binary_logloss: 0.000180367\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118004\tvalid_1's f1: 0.942745\n",
      "[433]\ttraining's binary_logloss: 0.00017916\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118022\tvalid_1's f1: 0.942969\n",
      "[434]\ttraining's binary_logloss: 0.000177903\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118005\tvalid_1's f1: 0.942916\n",
      "[435]\ttraining's binary_logloss: 0.000176821\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118036\tvalid_1's f1: 0.942937\n",
      "[436]\ttraining's binary_logloss: 0.000175696\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118028\tvalid_1's f1: 0.942937\n",
      "[437]\ttraining's binary_logloss: 0.000174574\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118028\tvalid_1's f1: 0.942873\n",
      "[438]\ttraining's binary_logloss: 0.000173391\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118021\tvalid_1's f1: 0.942873\n",
      "[439]\ttraining's binary_logloss: 0.000172261\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118087\tvalid_1's f1: 0.94282\n",
      "[440]\ttraining's binary_logloss: 0.000171163\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118112\tvalid_1's f1: 0.942723\n",
      "[441]\ttraining's binary_logloss: 0.000170235\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118133\tvalid_1's f1: 0.942777\n",
      "[442]\ttraining's binary_logloss: 0.000169194\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118143\tvalid_1's f1: 0.942916\n",
      "[443]\ttraining's binary_logloss: 0.000168205\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118196\tvalid_1's f1: 0.942884\n",
      "[444]\ttraining's binary_logloss: 0.000167278\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118196\tvalid_1's f1: 0.943065\n",
      "[445]\ttraining's binary_logloss: 0.000165948\ttraining's f1: 1\tvalid_1's binary_logloss: 0.0118226\tvalid_1's f1: 0.943001\n"
     ]
    }
   ],
   "source": [
    "clf = lig_model.fit(X_train,y_train\n",
    "                    ,eval_set=[(X_train, y_train),(X_valid,y_valid)],\n",
    "                            eval_metric=cus_f1,\n",
    "                            early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta score_train: 0.9999607807250336\n",
      "recall_score_train: 1.0\n",
      "precision_score_train: 0.9998039343833737\n",
      "========================================================\n",
      "fbeta score: 0.9094962968707588\n",
      "recall_score: 0.9276250741546371\n",
      "precision_score: 0.8435533177486063\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    375390\n",
      "         1.0       0.84      0.93      0.88      5057\n",
      "\n",
      "    accuracy                           1.00    380447\n",
      "   macro avg       0.92      0.96      0.94    380447\n",
      "weighted avg       1.00      1.00      1.00    380447\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "results['ad'] = {}\n",
    "\n",
    "pre_train = clf.predict(X_train)\n",
    "pre_test = clf.predict(X_valid)\n",
    "\n",
    "results['ad']['fbeta_train'] = fbeta_score(y_train, pre_train, beta=2)\n",
    "results['ad']['recall_train'] = recall_score(y_train, pre_train)\n",
    "results['ad']['precision_train'] = precision_score(y_train, pre_train)\n",
    "\n",
    "results['ad']['fbeta_test'] = fbeta_score(y_valid, pre_test, beta=2)\n",
    "results['ad']['recall_test'] = recall_score(y_valid, pre_test)\n",
    "results['ad']['precision_test'] = precision_score(y_valid, pre_test)\n",
    "\n",
    "print(\"fbeta score_train:\", results['ad']['fbeta_train'])\n",
    "print('recall_score_train:', results['ad']['recall_train'])\n",
    "print('precision_score_train:', results['ad']['precision_train'])\n",
    "\n",
    "print('========================================================')\n",
    "print(\"fbeta score:\", results['ad']['fbeta_test'])\n",
    "print('recall_score:', results['ad']['recall_test'])\n",
    "print('precision_score:', results['ad']['precision_test'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_valid, pre_test))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_valid, pre_test)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use trianed model predict assign sample and adjust to required csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypre 是預測的類別，而 yh 是原始分數或機率\n",
    "ypre = clf.predict(test.drop(['cano','bacno','txkey'],axis=1)) \n",
    "yh = clf.predict(test.drop(['cano','bacno','txkey'],axis=1),raw_score=True) \n",
    "# 強制令超過1的值為1\n",
    "yh = (yh > 2) * 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypre = pd.DataFrame(ypre,index=test.index) \n",
    "ypre = pd.concat([ypre,test['txkey']],axis=1) \n",
    "# summit key 對應到預測種類\n",
    "b = submit.merge(ypre)\n",
    "yh = pd.DataFrame(yh,index=test.index) \n",
    "yh = pd.concat([yh,test['txkey']],axis=1) \n",
    "# summit key 對應到預測機率\n",
    "c = submit.merge(yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>fraud_ind</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592489</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592488</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421660</th>\n",
       "      <td>1187507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421661</th>\n",
       "      <td>1182598</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421662</th>\n",
       "      <td>898724</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421663</th>\n",
       "      <td>971467</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421664</th>\n",
       "      <td>101230</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421665 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txkey  fraud_ind    0\n",
       "0        592489          0  0.0\n",
       "1        592452          0  0.0\n",
       "2        590212          0  0.0\n",
       "3        590209          0  0.0\n",
       "4        592488          0  0.0\n",
       "...         ...        ...  ...\n",
       "421660  1187507          0  0.0\n",
       "421661  1182598          0  0.0\n",
       "421662   898724          0  0.0\n",
       "421663   971467          0  0.0\n",
       "421664   101230          0  0.0\n",
       "\n",
       "[421665 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7375.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>fraud_ind</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592489</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590209</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592488</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421660</th>\n",
       "      <td>1187507</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421661</th>\n",
       "      <td>1182598</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421662</th>\n",
       "      <td>898724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421663</th>\n",
       "      <td>971467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421664</th>\n",
       "      <td>101230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421665 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txkey  fraud_ind  0\n",
       "0        592489          0  0\n",
       "1        592452          0  0\n",
       "2        590212          0  0\n",
       "3        590209          0  0\n",
       "4        592488          0  0\n",
       "...         ...        ... ..\n",
       "421660  1187507          0  0\n",
       "421661  1182598          0  0\n",
       "421662   898724          0  0\n",
       "421663   971467          0  0\n",
       "421664   101230          0  0\n",
       "\n",
       "[421665 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4915"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frequency_cano</th>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loctm_str</th>\n",
       "      <td>2138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds</th>\n",
       "      <td>2117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_seconds</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_amount</th>\n",
       "      <td>1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_amount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_taiwan</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_trad_ave</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trad_hour</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "frequency_cano  2441\n",
       "loctm_str       2138\n",
       "seconds         2117\n",
       "total_seconds   2013\n",
       "std_amount      1952\n",
       "...              ...\n",
       "mean_amount        0\n",
       "month              0\n",
       "is_taiwan          0\n",
       "acc_trad_ave       0\n",
       "trad_hour          0\n",
       "\n",
       "[89 rows x 1 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = submit.merge(ypre)\n",
    "b['fraud_ind'] = b[0]\n",
    "b.drop(0,axis=1,inplace=True)\n",
    "b.to_csv('test14.csv')\n",
    "c = submit.merge(yh)\n",
    "c['fraud_ind'] = c[0]\n",
    "c.drop(0,axis=1,inplace=True)\n",
    "c.to_csv('test15.csv')\n",
    "\n",
    "# 透過變數分類強度給予變數分數\n",
    "imp = clf.feature_importances_\n",
    "imp_col = X_train.columns.tolist()\n",
    "importance = pd.DataFrame(imp,index=imp_col)\n",
    "importance.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.sort_values(0,ascending=False).to_csv(\"feature importance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.3_py_3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
